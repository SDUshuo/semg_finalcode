nohup: ignoring input
++++++++++++
Number Parameters: TCN 44804
/home/yanshuo/YS/FinalCode/PyTorchImplementation/CWT/LMF.py:42: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.
  xavier_normal(self.image_factor)
/home/yanshuo/YS/FinalCode/PyTorchImplementation/CWT/LMF.py:43: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.
  xavier_normal(self.time_factor)
/home/yanshuo/YS/FinalCode/PyTorchImplementation/CWT/LMF.py:44: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.
  xavier_normal(self.fusion_weights)
Multi-Scale Temporal Relation Network Module in use ['3-frame relation', '2-frame relation']
Number Parameters: DB1_finalemode 203624
22572
(22572, 12, 10, 7)
/home/yanshuo/anaconda3/envs/diversify/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
train Loss: 1.43587222 Acc: 0.62068051
val Loss: 1.12858758 Acc: 0.69736844
Epoch 1 of 120 took 2.567s
train Loss: 1.13140932 Acc: 0.67893851
val Loss: 0.99722357 Acc: 0.7412281
Epoch 2 of 120 took 1.655s
train Loss: 0.98898765 Acc: 0.71296299
val Loss: 0.88612268 Acc: 0.7368421
Epoch 3 of 120 took 1.657s
train Loss: 0.87013471 Acc: 0.74632287
val Loss: 0.89593635 Acc: 0.75877196
Epoch 4 of 120 took 1.696s
train Loss: 0.78300301 Acc: 0.77423358
val Loss: 0.84247334 Acc: 0.76754385
Epoch 5 of 120 took 1.657s
train Loss: 0.71176840 Acc: 0.79009396
val Loss: 0.66418842 Acc: 0.80263156
Epoch 6 of 120 took 1.657s
train Loss: 0.67277136 Acc: 0.80037218
val Loss: 0.62563190 Acc: 0.79824561
Epoch 7 of 120 took 1.658s
train Loss: 0.64183289 Acc: 0.80847955
val Loss: 0.62658802 Acc: 0.80263156
Epoch 8 of 120 took 1.697s
train Loss: 0.61095014 Acc: 0.81689703
val Loss: 0.64140285 Acc: 0.82456142
Epoch 9 of 120 took 1.652s
train Loss: 0.58752198 Acc: 0.82411838
val Loss: 0.74440343 Acc: 0.80701756
Epoch 10 of 120 took 1.652s
train Loss: 0.56120122 Acc: 0.83328903
val Loss: 0.56377628 Acc: 0.84210527
Epoch 11 of 120 took 1.658s
train Loss: 0.55408555 Acc: 0.83289033
val Loss: 0.64342874 Acc: 0.81578946
Epoch 12 of 120 took 1.697s
train Loss: 0.52085616 Acc: 0.84303564
val Loss: 0.55299115 Acc: 0.83771932
Epoch 13 of 120 took 1.657s
train Loss: 0.51805534 Acc: 0.84471911
val Loss: 0.54066748 Acc: 0.84649122
Epoch 14 of 120 took 1.658s
train Loss: 0.50631670 Acc: 0.84817475
val Loss: 0.44790749 Acc: 0.84649122
Epoch 15 of 120 took 1.657s
train Loss: 0.48467883 Acc: 0.85211766
val Loss: 0.50875259 Acc: 0.85087723
Epoch 16 of 120 took 1.698s
train Loss: 0.47736897 Acc: 0.85388976
val Loss: 0.48697663 Acc: 0.85964912
Epoch 17 of 120 took 1.652s
train Loss: 0.46283448 Acc: 0.85920608
val Loss: 0.45986776 Acc: 0.86842108
Epoch 18 of 120 took 1.651s
train Loss: 0.44645904 Acc: 0.86359209
val Loss: 0.43902440 Acc: 0.86403507
Epoch 19 of 120 took 1.658s
train Loss: 0.43862639 Acc: 0.86660463
val Loss: 0.45577879 Acc: 0.87719297
Epoch 20 of 120 took 1.651s
train Loss: 0.43166980 Acc: 0.87063622
val Loss: 0.43205174 Acc: 0.85964912
Epoch 21 of 120 took 1.704s
train Loss: 0.42206617 Acc: 0.87010455
val Loss: 0.47794641 Acc: 0.86842108
Epoch 22 of 120 took 1.653s
train Loss: 0.40998525 Acc: 0.87754744
val Loss: 0.43934886 Acc: 0.88596493
Epoch 23 of 120 took 1.651s
train Loss: 0.40168337 Acc: 0.87577534
val Loss: 0.44633032 Acc: 0.85964912
Epoch 24 of 120 took 1.652s
train Loss: 0.39477344 Acc: 0.87962967
val Loss: 0.45309034 Acc: 0.86403507
Epoch 25 of 120 took 1.696s
train Loss: 0.38374116 Acc: 0.8822878
val Loss: 0.41548871 Acc: 0.88596493
Epoch 26 of 120 took 1.657s
train Loss: 0.37769722 Acc: 0.88250929
val Loss: 0.43753686 Acc: 0.89035088
Epoch 27 of 120 took 1.653s
train Loss: 0.38450587 Acc: 0.88113594
val Loss: 0.43563943 Acc: 0.89473683
Epoch 28 of 120 took 1.698s
train Loss: 0.36623998 Acc: 0.88804716
val Loss: 0.36326314 Acc: 0.88596493
Epoch 29 of 120 took 1.659s
train Loss: 0.36352120 Acc: 0.88724971
val Loss: 0.52361435 Acc: 0.89912283
Epoch 30 of 120 took 1.654s
train Loss: 0.35809124 Acc: 0.88818008
val Loss: 0.38438726 Acc: 0.88596493
Epoch 31 of 120 took 1.653s
train Loss: 0.35714367 Acc: 0.89030659
val Loss: 0.47369554 Acc: 0.85964912
Epoch 32 of 120 took 1.652s
train Loss: 0.36110005 Acc: 0.88769275
val Loss: 0.39254698 Acc: 0.89473683
Epoch 33 of 120 took 1.697s
train Loss: 0.35097827 Acc: 0.89221162
val Loss: 0.45921952 Acc: 0.90350878
Epoch 34 of 120 took 1.652s
train Loss: 0.33560775 Acc: 0.89611024
val Loss: 0.36684135 Acc: 0.89035088
Epoch 00035: reducing learning rate of group 0 to 2.0000e-03.
Epoch 35 of 120 took 1.651s
train Loss: 0.30900889 Acc: 0.9036417
val Loss: 0.29247360 Acc: 0.90789473
Epoch 36 of 120 took 1.657s
train Loss: 0.28334583 Acc: 0.91267943
val Loss: 0.33176516 Acc: 0.91666669
Epoch 37 of 120 took 1.699s
train Loss: 0.27781427 Acc: 0.91294527
val Loss: 0.31580476 Acc: 0.92105263
Epoch 38 of 120 took 1.651s
train Loss: 0.27583611 Acc: 0.91250223
val Loss: 0.31749966 Acc: 0.92105263
Epoch 39 of 120 took 1.651s
train Loss: 0.27348542 Acc: 0.91569203
val Loss: 0.30506481 Acc: 0.92982459
Epoch 40 of 120 took 1.652s
train Loss: 0.27209379 Acc: 0.91427433
val Loss: 0.29436781 Acc: 0.92982459
Epoch 41 of 120 took 1.697s
train Loss: 0.26895594 Acc: 0.91622365
val Loss: 0.29284466 Acc: 0.92982459
Epoch 00042: reducing learning rate of group 0 to 4.0000e-04.
Epoch 42 of 120 took 1.652s
train Loss: 0.26152904 Acc: 0.91897041
val Loss: 0.27675090 Acc: 0.92982459
Epoch 43 of 120 took 1.656s
train Loss: 0.25893327 Acc: 0.91954637
val Loss: 0.28858829 Acc: 0.93421054
Epoch 44 of 120 took 1.651s
train Loss: 0.25876515 Acc: 0.91839451
val Loss: 0.28503580 Acc: 0.92982459
Epoch 45 of 120 took 1.651s
train Loss: 0.25380227 Acc: 0.92043239
val Loss: 0.26227375 Acc: 0.92982459
Epoch 46 of 120 took 1.705s
train Loss: 0.25306458 Acc: 0.92193872
val Loss: 0.27821910 Acc: 0.93859649
Epoch 47 of 120 took 1.653s
train Loss: 0.25049802 Acc: 0.92185009
val Loss: 0.27425073 Acc: 0.93421054
Epoch 48 of 120 took 1.651s
train Loss: 0.24644908 Acc: 0.92211592
val Loss: 0.27353579 Acc: 0.92543858
Epoch 49 of 120 took 1.652s
train Loss: 0.25396741 Acc: 0.92083114
val Loss: 0.27908200 Acc: 0.93421054
Epoch 50 of 120 took 1.697s
train Loss: 0.25245470 Acc: 0.92105263
val Loss: 0.26111423 Acc: 0.93421054
Epoch 51 of 120 took 1.657s
train Loss: 0.25006740 Acc: 0.92043239
val Loss: 0.25982951 Acc: 0.93421054
Epoch 52 of 120 took 1.657s
train Loss: 0.24825836 Acc: 0.9232235
val Loss: 0.26984838 Acc: 0.93421054
Epoch 53 of 120 took 1.650s
train Loss: 0.24951428 Acc: 0.92158425
val Loss: 0.25957253 Acc: 0.93859649
Epoch 54 of 120 took 1.703s
train Loss: 0.24991279 Acc: 0.92193872
val Loss: 0.28204929 Acc: 0.93421054
Epoch 55 of 120 took 1.650s
train Loss: 0.24766460 Acc: 0.92242604
val Loss: 0.27332171 Acc: 0.93421054
Epoch 56 of 120 took 1.650s
train Loss: 0.25292566 Acc: 0.92083114
val Loss: 0.27421032 Acc: 0.93421054
Epoch 57 of 120 took 1.651s
train Loss: 0.24458143 Acc: 0.92233741
val Loss: 0.26934620 Acc: 0.93859649
Epoch 58 of 120 took 1.698s
train Loss: 0.24275377 Acc: 0.9239766
val Loss: 0.26180794 Acc: 0.93421054
Epoch 59 of 120 took 1.650s
train Loss: 0.24321388 Acc: 0.92441964
val Loss: 0.26847691 Acc: 0.93859649
Epoch 00060: reducing learning rate of group 0 to 8.0000e-05.
Epoch 60 of 120 took 1.649s
train Loss: 0.24522182 Acc: 0.92255896
val Loss: 0.26579603 Acc: 0.93859649
Epoch 61 of 120 took 1.650s
train Loss: 0.24352126 Acc: 0.92291337
val Loss: 0.26147185 Acc: 0.93859649
Epoch 62 of 120 took 1.698s
train Loss: 0.24638847 Acc: 0.92410952
val Loss: 0.26351226 Acc: 0.93859649
Epoch 63 of 120 took 1.650s
train Loss: 0.24131826 Acc: 0.92366648
val Loss: 0.26455971 Acc: 0.93859649
Epoch 64 of 120 took 1.649s
train Loss: 0.24465243 Acc: 0.9232235
val Loss: 0.25862590 Acc: 0.94736844
Epoch 65 of 120 took 1.656s
train Loss: 0.23957894 Acc: 0.92309058
val Loss: 0.26072358 Acc: 0.93859649
Epoch 66 of 120 took 1.650s
train Loss: 0.24580919 Acc: 0.9237994
val Loss: 0.26469646 Acc: 0.94736844
Epoch 67 of 120 took 1.696s
train Loss: 0.24192709 Acc: 0.92393231
val Loss: 0.26762592 Acc: 0.93859649
Epoch 68 of 120 took 1.652s
train Loss: 0.24484385 Acc: 0.92269182
val Loss: 0.26549315 Acc: 0.93859649
Epoch 69 of 120 took 1.652s
train Loss: 0.24025057 Acc: 0.92375511
val Loss: 0.26034339 Acc: 0.93421054
Epoch 70 of 120 took 1.650s
train Loss: 0.24303827 Acc: 0.92486268
val Loss: 0.26306792 Acc: 0.92982459
Epoch 00071: reducing learning rate of group 0 to 1.6000e-05.
Epoch 71 of 120 took 1.697s
train Loss: 0.24274790 Acc: 0.92317915
val Loss: 0.26207076 Acc: 0.93859649
Epoch 72 of 120 took 1.651s
train Loss: 0.23953848 Acc: 0.92393231
val Loss: 0.27026040 Acc: 0.93859649
Epoch 73 of 120 took 1.650s
train Loss: 0.24589355 Acc: 0.92185009
val Loss: 0.27256836 Acc: 0.93859649
Epoch 74 of 120 took 1.650s
train Loss: 0.23766105 Acc: 0.9235779
val Loss: 0.26060718 Acc: 0.93859649
Epoch 75 of 120 took 1.697s
train Loss: 0.24626266 Acc: 0.9223817
val Loss: 0.26055588 Acc: 0.93859649
Epoch 76 of 120 took 1.652s

Training complete in 2m 7s
Best val loss: 0.258626
ACCURACY TEST_0 FINAL : 85.624 %
TOP-3 ACCURACY TEST_0 FINAL : 95.575 %
22600
(22600, 12, 10, 7)
train Loss: 1.66830614 Acc: 0.59699112
val Loss: 1.01407262 Acc: 0.69736844
Epoch 1 of 120 took 1.794s
train Loss: 1.00756779 Acc: 0.694646
val Loss: 0.74452584 Acc: 0.75438595
Epoch 2 of 120 took 1.663s
train Loss: 0.80994671 Acc: 0.75774336
val Loss: 0.59679913 Acc: 0.83333331
Epoch 3 of 120 took 1.711s
train Loss: 0.70291220 Acc: 0.79106194
val Loss: 0.50489945 Acc: 0.83333331
Epoch 4 of 120 took 1.662s
train Loss: 0.62880370 Acc: 0.80920351
val Loss: 0.40898801 Acc: 0.85087723
Epoch 5 of 120 took 1.664s
train Loss: 0.58603114 Acc: 0.82300884
val Loss: 0.41311334 Acc: 0.85087723
Epoch 6 of 120 took 1.702s
train Loss: 0.55324414 Acc: 0.83172566
val Loss: 0.40189094 Acc: 0.88596493
Epoch 7 of 120 took 1.662s
train Loss: 0.53592541 Acc: 0.8393805
val Loss: 0.40805850 Acc: 0.85526317
Epoch 8 of 120 took 1.655s
train Loss: 0.49908237 Acc: 0.84942478
val Loss: 0.35847896 Acc: 0.88596493
Epoch 9 of 120 took 1.663s
train Loss: 0.48706245 Acc: 0.85207963
val Loss: 0.37087109 Acc: 0.87719297
Epoch 10 of 120 took 1.656s
train Loss: 0.46727433 Acc: 0.85628319
val Loss: 0.36806265 Acc: 0.88157898
Epoch 11 of 120 took 1.699s
train Loss: 0.45464431 Acc: 0.86172563
val Loss: 0.31652902 Acc: 0.89035088
Epoch 12 of 120 took 1.663s
train Loss: 0.42917052 Acc: 0.86553097
val Loss: 0.25165683 Acc: 0.90350878
Epoch 13 of 120 took 1.663s
train Loss: 0.42064939 Acc: 0.87053096
val Loss: 0.21818954 Acc: 0.92105263
Epoch 14 of 120 took 1.666s
train Loss: 0.41169562 Acc: 0.87079644
val Loss: 0.26303964 Acc: 0.91666669
Epoch 15 of 120 took 1.704s
train Loss: 0.40425155 Acc: 0.87446898
val Loss: 0.21891911 Acc: 0.91666669
Epoch 16 of 120 took 1.659s
train Loss: 0.39237612 Acc: 0.87805307
val Loss: 0.25196877 Acc: 0.91228068
Epoch 17 of 120 took 1.658s
train Loss: 0.37624597 Acc: 0.87973452
val Loss: 0.28738423 Acc: 0.90350878
Epoch 18 of 120 took 1.657s
train Loss: 0.38656267 Acc: 0.8814159
val Loss: 0.24211745 Acc: 0.90789473
Epoch 19 of 120 took 1.704s
train Loss: 0.37632591 Acc: 0.88274336
val Loss: 0.34965827 Acc: 0.88157898
Epoch 00020: reducing learning rate of group 0 to 2.0000e-03.
Epoch 20 of 120 took 1.660s
train Loss: 0.33957352 Acc: 0.89384955
val Loss: 0.17512759 Acc: 0.96052635
Epoch 21 of 120 took 1.664s
train Loss: 0.31705681 Acc: 0.90022123
val Loss: 0.15860427 Acc: 0.95175439
Epoch 22 of 120 took 1.711s
train Loss: 0.30718630 Acc: 0.90008849
val Loss: 0.17285316 Acc: 0.95175439
Epoch 23 of 120 took 1.659s
train Loss: 0.30668031 Acc: 0.90296459
val Loss: 0.15865413 Acc: 0.95614034
Epoch 24 of 120 took 1.658s
train Loss: 0.30374630 Acc: 0.90606195
val Loss: 0.15461237 Acc: 0.94736844
Epoch 25 of 120 took 1.665s
train Loss: 0.29515116 Acc: 0.90592921
val Loss: 0.16167183 Acc: 0.95614034
Epoch 26 of 120 took 1.659s
train Loss: 0.29292428 Acc: 0.90592921
val Loss: 0.14924347 Acc: 0.95175439
Epoch 27 of 120 took 1.712s
train Loss: 0.28899504 Acc: 0.90792036
val Loss: 0.17300508 Acc: 0.93859649
Epoch 28 of 120 took 1.660s
train Loss: 0.28959944 Acc: 0.90907079
val Loss: 0.15753689 Acc: 0.95614034
Epoch 29 of 120 took 1.658s
train Loss: 0.28320050 Acc: 0.90946901
val Loss: 0.16797420 Acc: 0.93859649
Epoch 30 of 120 took 1.659s
train Loss: 0.28021407 Acc: 0.91039819
val Loss: 0.14875095 Acc: 0.94736844
Epoch 31 of 120 took 1.711s
train Loss: 0.27823373 Acc: 0.9109292
val Loss: 0.15414934 Acc: 0.95614034
Epoch 32 of 120 took 1.660s
train Loss: 0.27431051 Acc: 0.91066372
val Loss: 0.16383609 Acc: 0.95614034
Epoch 33 of 120 took 1.661s
train Loss: 0.27601555 Acc: 0.91106194
val Loss: 0.17849006 Acc: 0.93421054
Epoch 34 of 120 took 1.659s
train Loss: 0.27113707 Acc: 0.91292036
val Loss: 0.15406249 Acc: 0.94736844
Epoch 35 of 120 took 1.659s
train Loss: 0.27544929 Acc: 0.91022122
val Loss: 0.16045089 Acc: 0.95614034
Epoch 36 of 120 took 1.705s
train Loss: 0.27307638 Acc: 0.91331857
val Loss: 0.15390102 Acc: 0.94736844
Epoch 00037: reducing learning rate of group 0 to 4.0000e-04.
Epoch 37 of 120 took 1.660s
train Loss: 0.26164476 Acc: 0.91646016
val Loss: 0.13951813 Acc: 0.95614034
Epoch 38 of 120 took 1.666s
train Loss: 0.25284058 Acc: 0.91911501
val Loss: 0.13543304 Acc: 0.95614034
Epoch 39 of 120 took 1.711s
train Loss: 0.25621820 Acc: 0.91747785
val Loss: 0.13691704 Acc: 0.96052635
Epoch 40 of 120 took 1.659s
train Loss: 0.26047491 Acc: 0.91889381
val Loss: 0.13784514 Acc: 0.95614034
Epoch 41 of 120 took 1.658s
train Loss: 0.25325832 Acc: 0.91849554
val Loss: 0.13770925 Acc: 0.95614034
Epoch 42 of 120 took 1.659s
train Loss: 0.25527834 Acc: 0.91889381
val Loss: 0.14154024 Acc: 0.95614034
Epoch 43 of 120 took 1.706s
train Loss: 0.25835047 Acc: 0.91893804
val Loss: 0.13676796 Acc: 0.95614034
Epoch 44 of 120 took 1.658s
train Loss: 0.25727078 Acc: 0.91716814
val Loss: 0.13535934 Acc: 0.95614034
Epoch 45 of 120 took 1.664s
train Loss: 0.25109476 Acc: 0.91964602
val Loss: 0.13646922 Acc: 0.95614034
Epoch 46 of 120 took 1.658s
train Loss: 0.25211159 Acc: 0.91823006
val Loss: 0.14029891 Acc: 0.95614034
Epoch 47 of 120 took 1.661s
train Loss: 0.24979023 Acc: 0.91862828
val Loss: 0.13507670 Acc: 0.96052635
Epoch 48 of 120 took 1.708s
train Loss: 0.24995957 Acc: 0.92070794
val Loss: 0.13283005 Acc: 0.95614034
Epoch 49 of 120 took 1.664s
train Loss: 0.24964949 Acc: 0.91823006
val Loss: 0.14221326 Acc: 0.95614034
Epoch 50 of 120 took 1.661s
train Loss: 0.25198387 Acc: 0.91761059
val Loss: 0.13341690 Acc: 0.95614034
Epoch 51 of 120 took 1.660s
train Loss: 0.24717803 Acc: 0.92110616
val Loss: 0.14042569 Acc: 0.95614034
Epoch 52 of 120 took 1.705s
train Loss: 0.24740176 Acc: 0.92101771
val Loss: 0.13645694 Acc: 0.95614034
Epoch 53 of 120 took 1.660s
train Loss: 0.24881724 Acc: 0.92150438
val Loss: 0.13452199 Acc: 0.95614034
Epoch 54 of 120 took 1.659s
train Loss: 0.24959216 Acc: 0.91915929
val Loss: 0.13416770 Acc: 0.95614034
Epoch 00055: reducing learning rate of group 0 to 8.0000e-05.
Epoch 55 of 120 took 1.659s
train Loss: 0.24604447 Acc: 0.92035395
val Loss: 0.13767212 Acc: 0.95614034
Epoch 56 of 120 took 1.660s
train Loss: 0.24611959 Acc: 0.92097342
val Loss: 0.13530949 Acc: 0.95614034
Epoch 57 of 120 took 1.704s
train Loss: 0.24808266 Acc: 0.92159289
val Loss: 0.13331021 Acc: 0.95614034
Epoch 58 of 120 took 1.660s
train Loss: 0.24134983 Acc: 0.92256635
val Loss: 0.13447525 Acc: 0.96052635
Epoch 59 of 120 took 1.660s
train Loss: 0.24735666 Acc: 0.92115045
val Loss: 0.13236854 Acc: 0.95614034
Epoch 60 of 120 took 1.665s
train Loss: 0.24917877 Acc: 0.9188053
val Loss: 0.13088708 Acc: 0.95614034
Epoch 61 of 120 took 1.711s
train Loss: 0.24425896 Acc: 0.92221236
val Loss: 0.13378590 Acc: 0.95614034
Epoch 62 of 120 took 1.659s
train Loss: 0.24041390 Acc: 0.92190266
val Loss: 0.13404579 Acc: 0.95614034
Epoch 63 of 120 took 1.660s
train Loss: 0.24076509 Acc: 0.92243361
val Loss: 0.13242904 Acc: 0.96052635
Epoch 64 of 120 took 1.661s
train Loss: 0.24327912 Acc: 0.92331856
val Loss: 0.13674219 Acc: 0.95614034
Epoch 65 of 120 took 1.705s
train Loss: 0.24448818 Acc: 0.92146015
val Loss: 0.13120793 Acc: 0.96052635
Epoch 66 of 120 took 1.659s
train Loss: 0.24083016 Acc: 0.92150438
val Loss: 0.13717306 Acc: 0.95614034
Epoch 00067: reducing learning rate of group 0 to 1.6000e-05.
Epoch 67 of 120 took 1.659s
train Loss: 0.24231950 Acc: 0.92176992
val Loss: 0.13273286 Acc: 0.96052635
Epoch 68 of 120 took 1.659s
train Loss: 0.24263524 Acc: 0.92243361
val Loss: 0.13433640 Acc: 0.96052635
Epoch 69 of 120 took 1.660s
train Loss: 0.24392199 Acc: 0.92079645
val Loss: 0.13524967 Acc: 0.96052635
Epoch 70 of 120 took 1.706s
train Loss: 0.24324760 Acc: 0.9212389
val Loss: 0.13772008 Acc: 0.95614034
Epoch 71 of 120 took 1.661s
train Loss: 0.24200639 Acc: 0.9223451
val Loss: 0.13473494 Acc: 0.95614034
Epoch 72 of 120 took 1.659s

Training complete in 2m 0s
Best val loss: 0.130887
ACCURACY TEST_0 FINAL : 84.389 %
TOP-3 ACCURACY TEST_0 FINAL : 93.951 %
22575
(22575, 12, 10, 7)
train Loss: 1.45894077 Acc: 0.67202663
val Loss: 0.86051881 Acc: 0.7368421
Epoch 1 of 120 took 1.844s
train Loss: 0.91256685 Acc: 0.74112958
val Loss: 0.58299503 Acc: 0.84649122
Epoch 2 of 120 took 1.668s
train Loss: 0.73327074 Acc: 0.79189372
val Loss: 0.49061146 Acc: 0.86403507
Epoch 3 of 120 took 1.669s
train Loss: 0.63714458 Acc: 0.8171429
val Loss: 0.39951514 Acc: 0.89912283
Epoch 4 of 120 took 1.670s
train Loss: 0.59171251 Acc: 0.83131784
val Loss: 0.36871810 Acc: 0.89035088
Epoch 5 of 120 took 1.668s
train Loss: 0.55073689 Acc: 0.84225917
val Loss: 0.33066175 Acc: 0.91666669
Epoch 6 of 120 took 1.716s
train Loss: 0.51885050 Acc: 0.85187155
val Loss: 0.30097419 Acc: 0.91666669
Epoch 7 of 120 took 1.668s
train Loss: 0.49228678 Acc: 0.85842752
val Loss: 0.26828810 Acc: 0.90789473
Epoch 8 of 120 took 1.668s
train Loss: 0.46786604 Acc: 0.86485052
val Loss: 0.28527774 Acc: 0.91228068
Epoch 9 of 120 took 1.704s
train Loss: 0.46206457 Acc: 0.86684388
val Loss: 0.24973003 Acc: 0.93859649
Epoch 10 of 120 took 1.670s
train Loss: 0.43294773 Acc: 0.87650061
val Loss: 0.21111348 Acc: 0.94298244
Epoch 11 of 120 took 1.667s
train Loss: 0.42762524 Acc: 0.87805098
val Loss: 0.33879137 Acc: 0.90789473
Epoch 12 of 120 took 1.662s
train Loss: 0.42121658 Acc: 0.87822819
val Loss: 0.21685889 Acc: 0.92982459
Epoch 13 of 120 took 1.661s
train Loss: 0.39823534 Acc: 0.88553715
val Loss: 0.21041400 Acc: 0.92982459
Epoch 14 of 120 took 1.712s
train Loss: 0.38514199 Acc: 0.8871761
val Loss: 0.21063460 Acc: 0.94736844
Epoch 15 of 120 took 1.662s
train Loss: 0.38014519 Acc: 0.89014399
val Loss: 0.20712207 Acc: 0.94736844
Epoch 16 of 120 took 1.666s
train Loss: 0.36963587 Acc: 0.89328909
val Loss: 0.16301475 Acc: 0.95175439
Epoch 17 of 120 took 1.670s
train Loss: 0.36607074 Acc: 0.89568108
val Loss: 0.17097073 Acc: 0.9649123
Epoch 18 of 120 took 1.707s
train Loss: 0.35845732 Acc: 0.89678854
val Loss: 0.16426920 Acc: 0.9649123
Epoch 19 of 120 took 1.661s
train Loss: 0.34759608 Acc: 0.89847177
val Loss: 0.17183691 Acc: 0.95614034
Epoch 20 of 120 took 1.662s
train Loss: 0.34767377 Acc: 0.89754158
val Loss: 0.16705434 Acc: 0.94298244
Epoch 21 of 120 took 1.661s
train Loss: 0.35878294 Acc: 0.89510524
val Loss: 0.20566896 Acc: 0.94736844
Epoch 22 of 120 took 1.707s
train Loss: 0.34824119 Acc: 0.89771873
val Loss: 0.17202930 Acc: 0.94298244
Epoch 00023: reducing learning rate of group 0 to 2.0000e-03.
Epoch 23 of 120 took 1.661s
train Loss: 0.30751056 Acc: 0.90764123
val Loss: 0.13187853 Acc: 0.9649123
Epoch 24 of 120 took 1.666s
train Loss: 0.28717812 Acc: 0.91441864
val Loss: 0.12951386 Acc: 0.96052635
Epoch 25 of 120 took 1.713s
train Loss: 0.28174271 Acc: 0.91707647
val Loss: 0.12309813 Acc: 0.96052635
Epoch 26 of 120 took 1.668s
train Loss: 0.28496858 Acc: 0.91548175
val Loss: 0.12915422 Acc: 0.9649123
Epoch 27 of 120 took 1.664s
train Loss: 0.27550733 Acc: 0.9165892
val Loss: 0.12751407 Acc: 0.96929824
Epoch 28 of 120 took 1.663s
train Loss: 0.27434791 Acc: 0.91831678
val Loss: 0.11009407 Acc: 0.96929824
Epoch 29 of 120 took 1.713s
train Loss: 0.27064845 Acc: 0.91884834
val Loss: 0.11744568 Acc: 0.9649123
Epoch 30 of 120 took 1.662s
train Loss: 0.26118743 Acc: 0.91955709
val Loss: 0.11060028 Acc: 0.96929824
Epoch 31 of 120 took 1.662s
train Loss: 0.26492361 Acc: 0.92070878
val Loss: 0.11061986 Acc: 0.96929824
Epoch 32 of 120 took 1.661s
train Loss: 0.26186086 Acc: 0.92097455
val Loss: 0.09997426 Acc: 0.97368419
Epoch 33 of 120 took 1.710s
train Loss: 0.25679995 Acc: 0.92177188
val Loss: 0.10856415 Acc: 0.96929824
Epoch 34 of 120 took 1.662s
train Loss: 0.26043196 Acc: 0.92132896
val Loss: 0.10815219 Acc: 0.9649123
Epoch 35 of 120 took 1.660s
train Loss: 0.25412778 Acc: 0.924474
val Loss: 0.13109089 Acc: 0.9649123
Epoch 36 of 120 took 1.662s
train Loss: 0.25782271 Acc: 0.92372096
val Loss: 0.14738980 Acc: 0.95614034
Epoch 37 of 120 took 1.709s
train Loss: 0.25177221 Acc: 0.92217058
val Loss: 0.12655327 Acc: 0.96052635
Epoch 38 of 120 took 1.661s
train Loss: 0.24347202 Acc: 0.9261573
val Loss: 0.12744386 Acc: 0.9649123
Epoch 00039: reducing learning rate of group 0 to 4.0000e-04.
Epoch 39 of 120 took 1.662s
train Loss: 0.24442069 Acc: 0.92562574
val Loss: 0.12657267 Acc: 0.9649123
Epoch 40 of 120 took 1.662s
train Loss: 0.24105854 Acc: 0.92819494
val Loss: 0.11108913 Acc: 0.96929824
Epoch 41 of 120 took 1.706s
train Loss: 0.23733614 Acc: 0.92823923
val Loss: 0.10674101 Acc: 0.97368419
Epoch 42 of 120 took 1.662s
train Loss: 0.23731632 Acc: 0.92735332
val Loss: 0.10622411 Acc: 0.96929824
Epoch 43 of 120 took 1.661s
train Loss: 0.23807037 Acc: 0.92815065
val Loss: 0.10570132 Acc: 0.9649123
Epoch 44 of 120 took 1.663s

Training complete in 1m 14s
Best val loss: 0.099974
ACCURACY TEST_0 FINAL : 88.727 %
TOP-3 ACCURACY TEST_0 FINAL : 97.076 %
22719
(22719, 12, 10, 7)
train Loss: 1.60889180 Acc: 0.61089838
val Loss: 1.13853448 Acc: 0.65938866
Epoch 1 of 120 took 1.933s
train Loss: 1.12188939 Acc: 0.67969543
val Loss: 0.90039456 Acc: 0.74235809
Epoch 2 of 120 took 1.630s
train Loss: 0.94113352 Acc: 0.73440731
val Loss: 0.75301394 Acc: 0.77729261
Epoch 3 of 120 took 1.667s
train Loss: 0.83413933 Acc: 0.76292974
val Loss: 0.67866034 Acc: 0.79039305
Epoch 4 of 120 took 1.668s
train Loss: 0.76137254 Acc: 0.78053612
val Loss: 0.58579664 Acc: 0.83842796
Epoch 5 of 120 took 1.668s
train Loss: 0.70938370 Acc: 0.79545754
val Loss: 0.60232571 Acc: 0.81659389
Epoch 6 of 120 took 1.662s
train Loss: 0.67676605 Acc: 0.80183989
val Loss: 0.55404277 Acc: 0.86026204
Epoch 7 of 120 took 1.669s
train Loss: 0.65666178 Acc: 0.80861837
val Loss: 0.50776217 Acc: 0.86026204
Epoch 8 of 120 took 1.715s
train Loss: 0.63562244 Acc: 0.8153528
val Loss: 0.54810870 Acc: 0.83842796
Epoch 9 of 120 took 1.663s
train Loss: 0.60160831 Acc: 0.82340771
val Loss: 0.50457742 Acc: 0.84279478
Epoch 10 of 120 took 1.669s
train Loss: 0.58070346 Acc: 0.82912982
val Loss: 0.52487031 Acc: 0.85152841
Epoch 11 of 120 took 1.664s
train Loss: 0.57282318 Acc: 0.8291738
val Loss: 0.49617477 Acc: 0.85589522
Epoch 12 of 120 took 1.716s
train Loss: 0.54560576 Acc: 0.83489591
val Loss: 0.52123779 Acc: 0.85589522
Epoch 13 of 120 took 1.663s
train Loss: 0.54207171 Acc: 0.83577621
val Loss: 0.47307032 Acc: 0.86026204
Epoch 14 of 120 took 1.668s
train Loss: 0.52835726 Acc: 0.84017783
val Loss: 0.55151082 Acc: 0.83842796
Epoch 15 of 120 took 1.663s
train Loss: 0.50945925 Acc: 0.84836483
val Loss: 0.47450435 Acc: 0.85589522
Epoch 16 of 120 took 1.708s
train Loss: 0.50665848 Acc: 0.84862888
val Loss: 0.41453437 Acc: 0.88209611
Epoch 17 of 120 took 1.669s
train Loss: 0.48441606 Acc: 0.85840046
val Loss: 0.40501573 Acc: 0.86462885
Epoch 18 of 120 took 1.669s
train Loss: 0.46832451 Acc: 0.86095339
val Loss: 0.41221575 Acc: 0.88209611
Epoch 19 of 120 took 1.664s
train Loss: 0.46197644 Acc: 0.86148161
val Loss: 0.43008237 Acc: 0.86026204
Epoch 20 of 120 took 1.664s
train Loss: 0.45781373 Acc: 0.86020511
val Loss: 0.41477720 Acc: 0.87336248
Epoch 21 of 120 took 1.710s
train Loss: 0.44339192 Acc: 0.86649942
val Loss: 0.36981322 Acc: 0.89082968
Epoch 22 of 120 took 1.669s
train Loss: 0.44208648 Acc: 0.86751175
val Loss: 0.33553975 Acc: 0.89956331
Epoch 23 of 120 took 1.669s
train Loss: 0.43414112 Acc: 0.87090099
val Loss: 0.34469054 Acc: 0.8951965
Epoch 24 of 120 took 1.663s
train Loss: 0.41976987 Acc: 0.8732779
val Loss: 0.39856930 Acc: 0.8777293
Epoch 25 of 120 took 1.709s
train Loss: 0.42047704 Acc: 0.87336588
val Loss: 0.36421730 Acc: 0.88646287
Epoch 26 of 120 took 1.664s
train Loss: 0.41636698 Acc: 0.87530261
val Loss: 0.32391897 Acc: 0.90829694
Epoch 27 of 120 took 1.669s
train Loss: 0.41436615 Acc: 0.87468636
val Loss: 0.35161735 Acc: 0.88646287
Epoch 28 of 120 took 1.711s
train Loss: 0.40435946 Acc: 0.87820768
val Loss: 0.32057033 Acc: 0.8951965
Epoch 29 of 120 took 1.668s
train Loss: 0.40333611 Acc: 0.88010037
val Loss: 0.28793571 Acc: 0.91266376
Epoch 30 of 120 took 1.669s
train Loss: 0.38590836 Acc: 0.88366568
val Loss: 0.27369346 Acc: 0.90829694
Epoch 31 of 120 took 1.668s
train Loss: 0.37865062 Acc: 0.88516217
val Loss: 0.34408989 Acc: 0.90829694
Epoch 32 of 120 took 1.707s
train Loss: 0.38321750 Acc: 0.88436991
val Loss: 0.31492408 Acc: 0.89956331
Epoch 33 of 120 took 1.664s
train Loss: 0.37679154 Acc: 0.88670278
val Loss: 0.28078933 Acc: 0.91703057
Epoch 34 of 120 took 1.663s
train Loss: 0.36108396 Acc: 0.88947576
val Loss: 0.29981431 Acc: 0.90393013
Epoch 35 of 120 took 1.664s
train Loss: 0.36028968 Acc: 0.89154452
val Loss: 0.28713303 Acc: 0.92139739
Epoch 36 of 120 took 1.662s
train Loss: 0.36566724 Acc: 0.88894761
val Loss: 0.31146984 Acc: 0.90829694
Epoch 00037: reducing learning rate of group 0 to 2.0000e-03.
Epoch 37 of 120 took 1.712s
train Loss: 0.32544452 Acc: 0.89995158
val Loss: 0.26101759 Acc: 0.93449783
Epoch 38 of 120 took 1.669s
train Loss: 0.29564186 Acc: 0.90945905
val Loss: 0.24654642 Acc: 0.93449783
Epoch 39 of 120 took 1.668s
train Loss: 0.30150168 Acc: 0.90778643
val Loss: 0.23013991 Acc: 0.94323146
Epoch 40 of 120 took 1.670s
train Loss: 0.29050798 Acc: 0.9098112
val Loss: 0.21808834 Acc: 0.94323146
Epoch 41 of 120 took 1.669s
train Loss: 0.28912710 Acc: 0.91016328
val Loss: 0.21329292 Acc: 0.93449783
Epoch 42 of 120 took 1.669s
train Loss: 0.29095986 Acc: 0.91240811
val Loss: 0.23120159 Acc: 0.93449783
Epoch 43 of 120 took 1.662s
train Loss: 0.28576499 Acc: 0.91232008
val Loss: 0.20903365 Acc: 0.93886465
Epoch 44 of 120 took 1.715s
train Loss: 0.28007620 Acc: 0.91623753
val Loss: 0.21310614 Acc: 0.93886465
Epoch 45 of 120 took 1.663s
train Loss: 0.28226928 Acc: 0.91276026
val Loss: 0.21979665 Acc: 0.93449783
Epoch 46 of 120 took 1.662s
train Loss: 0.27696397 Acc: 0.9161495
val Loss: 0.21364031 Acc: 0.93886465
Epoch 47 of 120 took 1.710s
train Loss: 0.28281130 Acc: 0.91117567
val Loss: 0.22800213 Acc: 0.94759828
Epoch 48 of 120 took 1.662s
train Loss: 0.27610327 Acc: 0.91469693
val Loss: 0.23079488 Acc: 0.93886465
Epoch 49 of 120 took 1.664s
train Loss: 0.27317209 Acc: 0.91452086
val Loss: 0.19613163 Acc: 0.94323146
Epoch 50 of 120 took 1.670s
train Loss: 0.26892001 Acc: 0.91817421
val Loss: 0.19772523 Acc: 0.93886465
Epoch 51 of 120 took 1.709s
train Loss: 0.27241018 Acc: 0.91813022
val Loss: 0.20066578 Acc: 0.94323146
Epoch 52 of 120 took 1.663s
train Loss: 0.26671612 Acc: 0.91636956
val Loss: 0.20876827 Acc: 0.93449783
Epoch 53 of 120 took 1.662s
train Loss: 0.26751695 Acc: 0.91971481
val Loss: 0.19437953 Acc: 0.93886465
Epoch 54 of 120 took 1.669s
train Loss: 0.26987975 Acc: 0.91870242
val Loss: 0.20869175 Acc: 0.94323146
Epoch 55 of 120 took 1.663s
train Loss: 0.25667281 Acc: 0.92019898
val Loss: 0.19967223 Acc: 0.93449783
Epoch 56 of 120 took 1.709s
train Loss: 0.26020739 Acc: 0.92028701
val Loss: 0.19397987 Acc: 0.93886465
Epoch 57 of 120 took 1.670s
train Loss: 0.26432940 Acc: 0.92165148
val Loss: 0.18056347 Acc: 0.94759828
Epoch 58 of 120 took 1.668s
train Loss: 0.25997190 Acc: 0.91949469
val Loss: 0.19511751 Acc: 0.94759828
Epoch 59 of 120 took 1.663s
train Loss: 0.26099379 Acc: 0.91993487
val Loss: 0.19424495 Acc: 0.94323146
Epoch 60 of 120 took 1.663s
train Loss: 0.25245826 Acc: 0.92169553
val Loss: 0.20670763 Acc: 0.93886465
Epoch 61 of 120 took 1.708s
train Loss: 0.26057972 Acc: 0.91769004
val Loss: 0.19078137 Acc: 0.94759828
Epoch 62 of 120 took 1.663s
train Loss: 0.25591264 Acc: 0.91958272
val Loss: 0.18721350 Acc: 0.95196509
Epoch 63 of 120 took 1.663s
train Loss: 0.25707389 Acc: 0.92231172
val Loss: 0.19586793 Acc: 0.93013102
Epoch 00064: reducing learning rate of group 0 to 4.0000e-04.
Epoch 64 of 120 took 1.663s
train Loss: 0.24905404 Acc: 0.92151946
val Loss: 0.18790030 Acc: 0.93449783
Epoch 65 of 120 took 1.710s
train Loss: 0.24531342 Acc: 0.92283994
val Loss: 0.18368519 Acc: 0.94323146
Epoch 66 of 120 took 1.663s
train Loss: 0.24484183 Acc: 0.92416042
val Loss: 0.18505356 Acc: 0.94323146
Epoch 67 of 120 took 1.663s
train Loss: 0.24321614 Acc: 0.92570096
val Loss: 0.18184367 Acc: 0.94323146
Epoch 68 of 120 took 1.664s
train Loss: 0.24061651 Acc: 0.9266693
val Loss: 0.18569064 Acc: 0.94323146
Epoch 69 of 120 took 1.663s

Training complete in 1m 56s
Best val loss: 0.180563
ACCURACY TEST_0 FINAL : 80.620 %
TOP-3 ACCURACY TEST_0 FINAL : 91.385 %
22541
(22541, 12, 10, 7)
train Loss: 2.16719501 Acc: 0.55214942
val Loss: 1.64100536 Acc: 0.53744489
Epoch 1 of 120 took 1.838s
train Loss: 1.43543830 Acc: 0.61439157
val Loss: 1.34390003 Acc: 0.60352421
Epoch 2 of 120 took 1.669s
train Loss: 1.24120124 Acc: 0.64748681
val Loss: 1.12607054 Acc: 0.65638763
Epoch 3 of 120 took 1.666s
train Loss: 1.09341881 Acc: 0.68209046
val Loss: 1.00587161 Acc: 0.70484579
Epoch 4 of 120 took 1.665s
train Loss: 0.99861831 Acc: 0.70795441
val Loss: 0.93038645 Acc: 0.74008811
Epoch 5 of 120 took 1.713s
train Loss: 0.93432554 Acc: 0.72476822
val Loss: 0.90774650 Acc: 0.76651978
Epoch 6 of 120 took 1.666s
train Loss: 0.86401431 Acc: 0.74171513
val Loss: 0.86481855 Acc: 0.7709251
Epoch 7 of 120 took 1.666s
train Loss: 0.82647228 Acc: 0.75267291
val Loss: 0.87937585 Acc: 0.75770921
Epoch 8 of 120 took 1.660s
train Loss: 0.79404299 Acc: 0.75915003
val Loss: 0.78960474 Acc: 0.77973562
Epoch 9 of 120 took 1.712s
train Loss: 0.74728981 Acc: 0.76744598
val Loss: 0.72708273 Acc: 0.78414094
Epoch 10 of 120 took 1.665s
train Loss: 0.71617900 Acc: 0.77671802
val Loss: 0.69284851 Acc: 0.79735678
Epoch 11 of 120 took 1.667s
train Loss: 0.69071845 Acc: 0.7841711
val Loss: 0.65329215 Acc: 0.8017621
Epoch 12 of 120 took 1.712s
train Loss: 0.67362948 Acc: 0.789406
val Loss: 0.70139948 Acc: 0.79295152
Epoch 13 of 120 took 1.661s
train Loss: 0.65159767 Acc: 0.79526198
val Loss: 0.68046962 Acc: 0.77973562
Epoch 14 of 120 took 1.659s
train Loss: 0.62115895 Acc: 0.80307001
val Loss: 0.60660394 Acc: 0.8325991
Epoch 15 of 120 took 1.666s
train Loss: 0.60587054 Acc: 0.80724019
val Loss: 0.60765526 Acc: 0.77973562
Epoch 16 of 120 took 1.661s
train Loss: 0.59739740 Acc: 0.8118096
val Loss: 0.61415517 Acc: 0.79735678
Epoch 17 of 120 took 1.707s
train Loss: 0.57345989 Acc: 0.81642342
val Loss: 0.58586095 Acc: 0.8193832
Epoch 18 of 120 took 1.666s
train Loss: 0.55845699 Acc: 0.8240096
val Loss: 0.61857121 Acc: 0.8193832
Epoch 19 of 120 took 1.659s
train Loss: 0.55181123 Acc: 0.82436454
val Loss: 0.58335101 Acc: 0.8193832
Epoch 20 of 120 took 1.667s
train Loss: 0.53698598 Acc: 0.82724816
val Loss: 0.53419779 Acc: 0.82819378
Epoch 21 of 120 took 1.711s
train Loss: 0.53083372 Acc: 0.82990998
val Loss: 0.54884212 Acc: 0.82378852
Epoch 22 of 120 took 1.662s
train Loss: 0.53989164 Acc: 0.82822412
val Loss: 0.64385287 Acc: 0.8017621
Epoch 23 of 120 took 1.661s
train Loss: 0.51259823 Acc: 0.83319288
val Loss: 0.52594520 Acc: 0.82819378
Epoch 24 of 120 took 1.665s
train Loss: 0.49805316 Acc: 0.83940375
val Loss: 0.51650759 Acc: 0.8325991
Epoch 25 of 120 took 1.714s
train Loss: 0.48948443 Acc: 0.83966994
val Loss: 0.51236292 Acc: 0.84581494
Epoch 26 of 120 took 1.667s
train Loss: 0.49113521 Acc: 0.84064597
val Loss: 0.51280166 Acc: 0.84140968
Epoch 27 of 120 took 1.661s
train Loss: 0.48098650 Acc: 0.84539288
val Loss: 0.54028917 Acc: 0.83700436
Epoch 28 of 120 took 1.660s
train Loss: 0.46867257 Acc: 0.84716743
val Loss: 0.43130244 Acc: 0.85903078
Epoch 29 of 120 took 1.713s
train Loss: 0.46586177 Acc: 0.85089397
val Loss: 0.41619576 Acc: 0.87224668
Epoch 30 of 120 took 1.667s
train Loss: 0.45821879 Acc: 0.8533783
val Loss: 0.44613606 Acc: 0.85462552
Epoch 31 of 120 took 1.661s
train Loss: 0.45685284 Acc: 0.85470921
val Loss: 0.46617398 Acc: 0.8502202
Epoch 32 of 120 took 1.660s
train Loss: 0.45583290 Acc: 0.85191429
val Loss: 0.45642412 Acc: 0.84581494
Epoch 33 of 120 took 1.707s
train Loss: 0.42410110 Acc: 0.86256158
val Loss: 0.40243082 Acc: 0.87665194
Epoch 34 of 120 took 1.665s
train Loss: 0.43882018 Acc: 0.85958922
val Loss: 0.44774264 Acc: 0.85903078
Epoch 35 of 120 took 1.661s
train Loss: 0.42664772 Acc: 0.86043215
val Loss: 0.48149455 Acc: 0.84581494
Epoch 36 of 120 took 1.659s
train Loss: 0.41903419 Acc: 0.86486846
val Loss: 0.52890114 Acc: 0.85462552
Epoch 37 of 120 took 1.660s
train Loss: 0.42086457 Acc: 0.86202919
val Loss: 0.49985111 Acc: 0.82378852
Epoch 38 of 120 took 1.708s
train Loss: 0.42151221 Acc: 0.86225104
val Loss: 0.43406906 Acc: 0.87665194
Epoch 39 of 120 took 1.660s
train Loss: 0.42112016 Acc: 0.86331576
val Loss: 0.52118458 Acc: 0.84140968
Epoch 00040: reducing learning rate of group 0 to 2.0000e-03.
Epoch 40 of 120 took 1.659s
train Loss: 0.37474187 Acc: 0.87893176
val Loss: 0.43539963 Acc: 0.88105726
Epoch 41 of 120 took 1.662s
train Loss: 0.34609388 Acc: 0.88536447
val Loss: 0.41986342 Acc: 0.88546252
Epoch 42 of 120 took 1.706s
train Loss: 0.34230471 Acc: 0.88589686
val Loss: 0.39064629 Acc: 0.88986778
Epoch 43 of 120 took 1.665s
train Loss: 0.33519419 Acc: 0.88709468
val Loss: 0.38673105 Acc: 0.89867836
Epoch 44 of 120 took 1.666s
train Loss: 0.32909938 Acc: 0.89139795
val Loss: 0.38733729 Acc: 0.8942731
Epoch 45 of 120 took 1.707s
train Loss: 0.33797053 Acc: 0.88886923
val Loss: 0.35134074 Acc: 0.8942731
Epoch 46 of 120 took 1.667s
train Loss: 0.32675411 Acc: 0.89184153
val Loss: 0.36865816 Acc: 0.88986778
Epoch 47 of 120 took 1.663s
train Loss: 0.31789719 Acc: 0.89587867
val Loss: 0.37413013 Acc: 0.91189426
Epoch 48 of 120 took 1.659s
train Loss: 0.31856043 Acc: 0.89432591
val Loss: 0.34659868 Acc: 0.88986778
Epoch 49 of 120 took 1.668s
train Loss: 0.31995968 Acc: 0.89343864
val Loss: 0.36056038 Acc: 0.91189426
Epoch 50 of 120 took 1.660s
train Loss: 0.31744997 Acc: 0.89490265
val Loss: 0.35959393 Acc: 0.89867836
Epoch 51 of 120 took 1.703s
train Loss: 0.31493280 Acc: 0.89729828
val Loss: 0.32648009 Acc: 0.91189426
Epoch 52 of 120 took 1.667s
train Loss: 0.31159447 Acc: 0.89698774
val Loss: 0.35751406 Acc: 0.89867836
Epoch 53 of 120 took 1.660s
train Loss: 0.31101849 Acc: 0.89956081
val Loss: 0.36401560 Acc: 0.8942731
Epoch 54 of 120 took 1.661s
train Loss: 0.31319298 Acc: 0.89676595
val Loss: 0.33319433 Acc: 0.90308368
Epoch 55 of 120 took 1.704s
train Loss: 0.30603705 Acc: 0.89760882
val Loss: 0.33846744 Acc: 0.89867836
Epoch 56 of 120 took 1.660s
train Loss: 0.30799567 Acc: 0.89658844
val Loss: 0.35417521 Acc: 0.90748894
Epoch 57 of 120 took 1.661s
train Loss: 0.30719104 Acc: 0.89907283
val Loss: 0.32513885 Acc: 0.90748894
Epoch 58 of 120 took 1.712s
train Loss: 0.30439162 Acc: 0.89698774
val Loss: 0.32890031 Acc: 0.92070478
Epoch 59 of 120 took 1.661s
train Loss: 0.30581500 Acc: 0.89774191
val Loss: 0.35087727 Acc: 0.8942731
Epoch 60 of 120 took 1.658s
train Loss: 0.29580700 Acc: 0.90213394
val Loss: 0.33325889 Acc: 0.90308368
Epoch 61 of 120 took 1.661s
train Loss: 0.30652793 Acc: 0.89734262
val Loss: 0.31311265 Acc: 0.91189426
Epoch 62 of 120 took 1.717s
train Loss: 0.30229152 Acc: 0.90137976
val Loss: 0.35958146 Acc: 0.90748894
Epoch 63 of 120 took 1.660s
train Loss: 0.29780985 Acc: 0.90155721
val Loss: 0.35825433 Acc: 0.88986778
Epoch 64 of 120 took 1.662s
train Loss: 0.29489779 Acc: 0.90346485
val Loss: 0.36364654 Acc: 0.89867836
Epoch 65 of 120 took 1.661s
train Loss: 0.28902266 Acc: 0.90528375
val Loss: 0.32646256 Acc: 0.89867836
Epoch 66 of 120 took 1.660s
train Loss: 0.28984463 Acc: 0.90342045
val Loss: 0.31319088 Acc: 0.90308368
Epoch 67 of 120 took 1.705s
train Loss: 0.29150061 Acc: 0.90191209
val Loss: 0.33153837 Acc: 0.91189426
Epoch 00068: reducing learning rate of group 0 to 4.0000e-04.
Epoch 68 of 120 took 1.660s
train Loss: 0.28770146 Acc: 0.90395284
val Loss: 0.36257430 Acc: 0.89867836
Epoch 69 of 120 took 1.659s
train Loss: 0.28040457 Acc: 0.90581608
val Loss: 0.31628704 Acc: 0.91189426
Epoch 70 of 120 took 1.659s
train Loss: 0.27595800 Acc: 0.90887719
val Loss: 0.31288728 Acc: 0.90748894
Epoch 71 of 120 took 1.711s
train Loss: 0.27657136 Acc: 0.90883285
val Loss: 0.30511901 Acc: 0.91629952
Epoch 72 of 120 took 1.665s
train Loss: 0.27743366 Acc: 0.90998626
val Loss: 0.33016935 Acc: 0.91629952
Epoch 73 of 120 took 1.661s
train Loss: 0.27487312 Acc: 0.90803427
val Loss: 0.33695713 Acc: 0.90748894
Epoch 74 of 120 took 1.660s
train Loss: 0.27399757 Acc: 0.90980881
val Loss: 0.33971863 Acc: 0.91189426
Epoch 75 of 120 took 1.707s
train Loss: 0.27581134 Acc: 0.90856665
val Loss: 0.33270041 Acc: 0.91629952
Epoch 76 of 120 took 1.659s
train Loss: 0.27205319 Acc: 0.90834481
val Loss: 0.31926466 Acc: 0.91629952
Epoch 77 of 120 took 1.661s
train Loss: 0.27288027 Acc: 0.90887719
val Loss: 0.31326313 Acc: 0.91629952
Epoch 00078: reducing learning rate of group 0 to 8.0000e-05.
Epoch 78 of 120 took 1.660s
train Loss: 0.26719225 Acc: 0.91291428
val Loss: 0.32484036 Acc: 0.91629952
Epoch 79 of 120 took 1.659s
train Loss: 0.26968892 Acc: 0.90932083
val Loss: 0.31445233 Acc: 0.91189426
Epoch 80 of 120 took 1.706s
train Loss: 0.26894874 Acc: 0.91100663
val Loss: 0.32905218 Acc: 0.91629952
Epoch 81 of 120 took 1.661s
train Loss: 0.27183790 Acc: 0.90932083
val Loss: 0.31609513 Acc: 0.90748894
Epoch 82 of 120 took 1.659s
train Loss: 0.26869696 Acc: 0.91140592
val Loss: 0.31987052 Acc: 0.90748894
Epoch 83 of 120 took 1.659s

Training complete in 2m 19s
Best val loss: 0.305119
ACCURACY TEST_0 FINAL : 76.857 %
TOP-3 ACCURACY TEST_0 FINAL : 91.713 %
22598
(22598, 12, 10, 7)
train Loss: 1.85535121 Acc: 0.60377026
val Loss: 1.11202025 Acc: 0.64912283
Epoch 1 of 120 took 1.847s
train Loss: 1.14826148 Acc: 0.67696255
val Loss: 0.90760936 Acc: 0.72368419
Epoch 2 of 120 took 1.671s
train Loss: 0.98124026 Acc: 0.71895742
val Loss: 0.72038216 Acc: 0.77631581
Epoch 3 of 120 took 1.669s
train Loss: 0.87291987 Acc: 0.74931413
val Loss: 0.65764679 Acc: 0.80701756
Epoch 4 of 120 took 1.670s
train Loss: 0.80861885 Acc: 0.76577574
val Loss: 0.62916568 Acc: 0.80263156
Epoch 5 of 120 took 1.714s
train Loss: 0.76379306 Acc: 0.77821046
val Loss: 0.58369312 Acc: 0.82456142
Epoch 6 of 120 took 1.670s
train Loss: 0.70711154 Acc: 0.79082221
val Loss: 0.51997518 Acc: 0.83771932
Epoch 7 of 120 took 1.670s
train Loss: 0.66967137 Acc: 0.80215067
val Loss: 0.49489886 Acc: 0.83771932
Epoch 8 of 120 took 1.669s
train Loss: 0.64221079 Acc: 0.80874413
val Loss: 0.45783303 Acc: 0.86403507
Epoch 9 of 120 took 1.719s
train Loss: 0.63025464 Acc: 0.81321359
val Loss: 0.46973824 Acc: 0.85526317
Epoch 10 of 120 took 1.662s
train Loss: 0.59842249 Acc: 0.82113463
val Loss: 0.43322056 Acc: 0.86403507
Epoch 11 of 120 took 1.669s
train Loss: 0.58078595 Acc: 0.82471901
val Loss: 0.51193626 Acc: 0.83771932
Epoch 12 of 120 took 1.663s
train Loss: 0.55574006 Acc: 0.8316223
val Loss: 0.37081889 Acc: 0.89035088
Epoch 13 of 120 took 1.715s
train Loss: 0.54962254 Acc: 0.83458716
val Loss: 0.44989984 Acc: 0.86842108
Epoch 14 of 120 took 1.664s
train Loss: 0.52214788 Acc: 0.84073812
val Loss: 0.39108651 Acc: 0.89035088
Epoch 15 of 120 took 1.663s
train Loss: 0.52183248 Acc: 0.84268522
val Loss: 0.33528273 Acc: 0.89035088
Epoch 16 of 120 took 1.671s
train Loss: 0.51487325 Acc: 0.84241968
val Loss: 0.41149081 Acc: 0.88157898
Epoch 17 of 120 took 1.664s
train Loss: 0.50514225 Acc: 0.84480929
val Loss: 0.36704733 Acc: 0.89473683
Epoch 18 of 120 took 1.709s
train Loss: 0.48514522 Acc: 0.85020798
val Loss: 0.35555988 Acc: 0.89035088
Epoch 19 of 120 took 1.664s
train Loss: 0.47632027 Acc: 0.85569519
val Loss: 0.34484450 Acc: 0.90350878
Epoch 20 of 120 took 1.664s
train Loss: 0.46754979 Acc: 0.85675728
val Loss: 0.30837496 Acc: 0.90789473
Epoch 21 of 120 took 1.668s
train Loss: 0.45761044 Acc: 0.86007613
val Loss: 0.31848006 Acc: 0.89912283
Epoch 22 of 120 took 1.711s
train Loss: 0.45167607 Acc: 0.8617577
val Loss: 0.30967200 Acc: 0.91666669
Epoch 23 of 120 took 1.663s
train Loss: 0.44726175 Acc: 0.86259848
val Loss: 0.32877536 Acc: 0.91228068
Epoch 24 of 120 took 1.662s
train Loss: 0.43603904 Acc: 0.86737764
val Loss: 0.31647801 Acc: 0.90350878
Epoch 25 of 120 took 1.665s
train Loss: 0.42234121 Acc: 0.86892647
val Loss: 0.31967165 Acc: 0.89912283
Epoch 26 of 120 took 1.711s
train Loss: 0.41170400 Acc: 0.87436944
val Loss: 0.34231163 Acc: 0.91228068
Epoch 00027: reducing learning rate of group 0 to 2.0000e-03.
Epoch 27 of 120 took 1.664s
train Loss: 0.38496137 Acc: 0.87786531
val Loss: 0.27284629 Acc: 0.91666669
Epoch 28 of 120 took 1.668s
train Loss: 0.36257896 Acc: 0.88445884
val Loss: 0.27548427 Acc: 0.91666669
Epoch 29 of 120 took 1.664s
train Loss: 0.35987611 Acc: 0.88795471
val Loss: 0.26961989 Acc: 0.92105263
Epoch 30 of 120 took 1.669s
train Loss: 0.34845543 Acc: 0.89003456
val Loss: 0.26490518 Acc: 0.92543858
Epoch 31 of 120 took 1.715s
train Loss: 0.35124290 Acc: 0.88901675
val Loss: 0.23398816 Acc: 0.92543858
Epoch 32 of 120 took 1.671s
train Loss: 0.34595382 Acc: 0.89162761
val Loss: 0.25854381 Acc: 0.92105263
Epoch 33 of 120 took 1.664s
train Loss: 0.34296960 Acc: 0.89069831
val Loss: 0.25284237 Acc: 0.91228068
Epoch 34 of 120 took 1.663s
train Loss: 0.34240460 Acc: 0.89215863
val Loss: 0.26561482 Acc: 0.92105263
Epoch 35 of 120 took 1.711s
train Loss: 0.34404637 Acc: 0.89096385
val Loss: 0.25585187 Acc: 0.93421054
Epoch 36 of 120 took 1.664s
train Loss: 0.34129585 Acc: 0.89145058
val Loss: 0.26546110 Acc: 0.92982459
Epoch 37 of 120 took 1.664s
train Loss: 0.34184685 Acc: 0.89207011
val Loss: 0.24328124 Acc: 0.92982459
Epoch 00038: reducing learning rate of group 0 to 4.0000e-04.
Epoch 38 of 120 took 1.663s
train Loss: 0.32873122 Acc: 0.89521199
val Loss: 0.24197529 Acc: 0.92982459
Epoch 39 of 120 took 1.712s
train Loss: 0.32903291 Acc: 0.89463669
val Loss: 0.24876508 Acc: 0.93421054
Epoch 40 of 120 took 1.664s
train Loss: 0.32470720 Acc: 0.89715904
val Loss: 0.25634508 Acc: 0.92982459
Epoch 41 of 120 took 1.662s
train Loss: 0.32856661 Acc: 0.89600849
val Loss: 0.25310411 Acc: 0.92982459
Epoch 42 of 120 took 1.663s
train Loss: 0.32327985 Acc: 0.89600849
val Loss: 0.24698057 Acc: 0.93421054
Epoch 43 of 120 took 1.710s

Training complete in 1m 12s
Best val loss: 0.233988
ACCURACY TEST_0 FINAL : 78.774 %
TOP-3 ACCURACY TEST_0 FINAL : 89.967 %
22661
(22661, 12, 10, 7)
train Loss: 1.81517973 Acc: 0.60994661
val Loss: 1.13232381 Acc: 0.64035088
Epoch 1 of 120 took 1.819s
train Loss: 1.09279169 Acc: 0.6848771
val Loss: 0.87236157 Acc: 0.7631579
Epoch 2 of 120 took 1.657s
train Loss: 0.89698865 Acc: 0.72829974
val Loss: 0.72134036 Acc: 0.80701756
Epoch 3 of 120 took 1.670s
train Loss: 0.77645380 Acc: 0.75945455
val Loss: 0.66232795 Acc: 0.81140351
Epoch 4 of 120 took 1.670s
train Loss: 0.69473191 Acc: 0.78796172
val Loss: 0.62076320 Acc: 0.82017547
Epoch 5 of 120 took 1.670s
train Loss: 0.61939342 Acc: 0.80914348
val Loss: 0.57212541 Acc: 0.83333331
Epoch 6 of 120 took 1.670s
train Loss: 0.58062321 Acc: 0.82017565
val Loss: 0.54095411 Acc: 0.84649122
Epoch 7 of 120 took 1.717s
train Loss: 0.54273247 Acc: 0.83328187
val Loss: 0.54166324 Acc: 0.85087723
Epoch 8 of 120 took 1.664s
train Loss: 0.52478470 Acc: 0.84078372
val Loss: 0.52612505 Acc: 0.85087723
Epoch 9 of 120 took 1.670s
train Loss: 0.49708224 Acc: 0.84696174
val Loss: 0.51393750 Acc: 0.85087723
Epoch 10 of 120 took 1.714s
train Loss: 0.47748356 Acc: 0.8534928
val Loss: 0.45773316 Acc: 0.88157898
Epoch 11 of 120 took 1.669s
train Loss: 0.45326534 Acc: 0.85975903
val Loss: 0.44524458 Acc: 0.84210527
Epoch 12 of 120 took 1.668s
train Loss: 0.43707478 Acc: 0.86562818
val Loss: 0.37591928 Acc: 0.89035088
Epoch 13 of 120 took 1.669s
train Loss: 0.42557022 Acc: 0.86968803
val Loss: 0.40226307 Acc: 0.89035088
Epoch 14 of 120 took 1.664s
train Loss: 0.41662120 Acc: 0.87299764
val Loss: 0.38061801 Acc: 0.89035088
Epoch 15 of 120 took 1.663s
train Loss: 0.39431069 Acc: 0.87877852
val Loss: 0.38721051 Acc: 0.89035088
Epoch 16 of 120 took 1.710s
train Loss: 0.39248855 Acc: 0.87908745
val Loss: 0.35413414 Acc: 0.87719297
Epoch 17 of 120 took 1.669s
train Loss: 0.38500562 Acc: 0.8789109
val Loss: 0.34475042 Acc: 0.88157898
Epoch 18 of 120 took 1.670s
train Loss: 0.37358154 Acc: 0.88402981
val Loss: 0.33900784 Acc: 0.89912283
Epoch 19 of 120 took 1.669s
train Loss: 0.36980235 Acc: 0.88557434
val Loss: 0.32610027 Acc: 0.89473683
Epoch 20 of 120 took 1.717s
train Loss: 0.35806289 Acc: 0.89060503
val Loss: 0.33600305 Acc: 0.88596493
Epoch 21 of 120 took 1.666s
train Loss: 0.35165862 Acc: 0.88998723
val Loss: 0.33034078 Acc: 0.89912283
Epoch 22 of 120 took 1.663s
train Loss: 0.33954366 Acc: 0.89634174
val Loss: 0.26191736 Acc: 0.92105263
Epoch 23 of 120 took 1.670s
train Loss: 0.32638851 Acc: 0.89691544
val Loss: 0.28712781 Acc: 0.90789473
Epoch 24 of 120 took 1.709s
train Loss: 0.33120048 Acc: 0.89788622
val Loss: 0.34137803 Acc: 0.87719297
Epoch 25 of 120 took 1.663s
train Loss: 0.31954558 Acc: 0.90181369
val Loss: 0.27268542 Acc: 0.92982459
Epoch 26 of 120 took 1.664s
train Loss: 0.32146135 Acc: 0.89916599
val Loss: 0.28039875 Acc: 0.90789473
Epoch 27 of 120 took 1.664s
train Loss: 0.30666903 Acc: 0.90605003
val Loss: 0.31318622 Acc: 0.92543858
Epoch 28 of 120 took 1.664s
train Loss: 0.30910532 Acc: 0.90375537
val Loss: 0.34208648 Acc: 0.90350878
Epoch 00029: reducing learning rate of group 0 to 2.0000e-03.
Epoch 29 of 120 took 1.709s
train Loss: 0.28706416 Acc: 0.91359603
val Loss: 0.24864305 Acc: 0.93421054
Epoch 30 of 120 took 1.670s
train Loss: 0.27402972 Acc: 0.91456687
val Loss: 0.25154448 Acc: 0.93859649
Epoch 31 of 120 took 1.664s
train Loss: 0.25822925 Acc: 0.9180972
val Loss: 0.23992525 Acc: 0.92982459
Epoch 32 of 120 took 1.671s
train Loss: 0.25615728 Acc: 0.9195534
val Loss: 0.22994624 Acc: 0.93421054
Epoch 33 of 120 took 1.719s
train Loss: 0.25727374 Acc: 0.92092139
val Loss: 0.22691058 Acc: 0.93859649
Epoch 34 of 120 took 1.670s
train Loss: 0.25538798 Acc: 0.92021537
val Loss: 0.22047953 Acc: 0.93859649
Epoch 35 of 120 took 1.672s
train Loss: 0.25247024 Acc: 0.92158335
val Loss: 0.23867516 Acc: 0.92982459
Epoch 36 of 120 took 1.711s
train Loss: 0.25447262 Acc: 0.91959757
val Loss: 0.22351981 Acc: 0.93859649
Epoch 37 of 120 took 1.666s
train Loss: 0.25098152 Acc: 0.92175984
val Loss: 0.21715806 Acc: 0.93859649
Epoch 38 of 120 took 1.671s
train Loss: 0.24694369 Acc: 0.92255419
val Loss: 0.21602073 Acc: 0.93421054
Epoch 39 of 120 took 1.716s
train Loss: 0.25125437 Acc: 0.92114204
val Loss: 0.22529547 Acc: 0.92982459
Epoch 40 of 120 took 1.664s
train Loss: 0.24406366 Acc: 0.92427516
val Loss: 0.22568318 Acc: 0.92982459
Epoch 41 of 120 took 1.664s
train Loss: 0.24280773 Acc: 0.92387801
val Loss: 0.20562411 Acc: 0.93859649
Epoch 42 of 120 took 1.671s
train Loss: 0.23945318 Acc: 0.92458409
val Loss: 0.19907104 Acc: 0.94298244
Epoch 43 of 120 took 1.714s
train Loss: 0.24296199 Acc: 0.92193639
val Loss: 0.20917573 Acc: 0.94736844
Epoch 44 of 120 took 1.664s
train Loss: 0.23808710 Acc: 0.92498124
val Loss: 0.22139169 Acc: 0.94736844
Epoch 45 of 120 took 1.665s
train Loss: 0.23677297 Acc: 0.9264816
val Loss: 0.22872642 Acc: 0.93859649
Epoch 46 of 120 took 1.665s
train Loss: 0.23300371 Acc: 0.92723179
val Loss: 0.21708445 Acc: 0.94298244
Epoch 47 of 120 took 1.664s
train Loss: 0.23437055 Acc: 0.92612857
val Loss: 0.24205067 Acc: 0.93421054
Epoch 48 of 120 took 1.709s
train Loss: 0.23061526 Acc: 0.92758483
val Loss: 0.21395246 Acc: 0.92982459
Epoch 00049: reducing learning rate of group 0 to 4.0000e-04.
Epoch 49 of 120 took 1.663s
train Loss: 0.22768656 Acc: 0.92917347
val Loss: 0.20297673 Acc: 0.94298244
Epoch 50 of 120 took 1.664s
train Loss: 0.22766363 Acc: 0.92952651
val Loss: 0.20586976 Acc: 0.93859649
Epoch 51 of 120 took 1.664s
train Loss: 0.22453527 Acc: 0.9294824
val Loss: 0.20070874 Acc: 0.94298244
Epoch 52 of 120 took 1.710s
train Loss: 0.22351769 Acc: 0.93133575
val Loss: 0.20562209 Acc: 0.93859649
Epoch 53 of 120 took 1.665s
train Loss: 0.22015526 Acc: 0.92952651
val Loss: 0.20550631 Acc: 0.93859649
Epoch 54 of 120 took 1.663s

Training complete in 1m 31s
Best val loss: 0.199071
ACCURACY TEST_0 FINAL : 85.325 %
TOP-3 ACCURACY TEST_0 FINAL : 95.827 %
22570
(22570, 12, 10, 7)
train Loss: 1.52236194 Acc: 0.66889679
val Loss: 1.01821303 Acc: 0.71806163
Epoch 1 of 120 took 1.842s
train Loss: 0.96155888 Acc: 0.72809041
val Loss: 0.84623047 Acc: 0.78414094
Epoch 2 of 120 took 1.669s
train Loss: 0.81142334 Acc: 0.77080196
val Loss: 0.79024832 Acc: 0.79735678
Epoch 3 of 120 took 1.669s
train Loss: 0.71597897 Acc: 0.79893667
val Loss: 0.60620057 Acc: 0.8634361
Epoch 4 of 120 took 1.667s
train Loss: 0.63778412 Acc: 0.8180328
val Loss: 0.53719987 Acc: 0.8634361
Epoch 5 of 120 took 1.712s
train Loss: 0.60539864 Acc: 0.82591939
val Loss: 0.51656157 Acc: 0.86784136
Epoch 6 of 120 took 1.667s
train Loss: 0.57023798 Acc: 0.83695173
val Loss: 0.47933123 Acc: 0.8634361
Epoch 7 of 120 took 1.667s
train Loss: 0.54403703 Acc: 0.84009749
val Loss: 0.44359330 Acc: 0.87665194
Epoch 8 of 120 took 1.668s
train Loss: 0.53453500 Acc: 0.8428002
val Loss: 0.44978677 Acc: 0.87665194
Epoch 9 of 120 took 1.662s
train Loss: 0.51041306 Acc: 0.85073107
val Loss: 0.41237313 Acc: 0.8942731
Epoch 10 of 120 took 1.711s
train Loss: 0.48162554 Acc: 0.85733277
val Loss: 0.41078912 Acc: 0.88546252
Epoch 11 of 120 took 1.667s
train Loss: 0.47209016 Acc: 0.85994685
val Loss: 0.37923917 Acc: 0.8942731
Epoch 12 of 120 took 1.670s
train Loss: 0.44930527 Acc: 0.86420029
val Loss: 0.37035897 Acc: 0.89867836
Epoch 13 of 120 took 1.668s
train Loss: 0.44753133 Acc: 0.86668146
val Loss: 0.36426295 Acc: 0.88986778
Epoch 14 of 120 took 1.716s
train Loss: 0.43637856 Acc: 0.86911833
val Loss: 0.33209135 Acc: 0.90308368
Epoch 15 of 120 took 1.667s
train Loss: 0.41531711 Acc: 0.87704921
val Loss: 0.35058227 Acc: 0.8942731
Epoch 16 of 120 took 1.661s
train Loss: 0.41721912 Acc: 0.87319452
val Loss: 0.32220187 Acc: 0.91189426
Epoch 17 of 120 took 1.666s
train Loss: 0.40781101 Acc: 0.87749225
val Loss: 0.30287392 Acc: 0.90308368
Epoch 18 of 120 took 1.668s
train Loss: 0.40522081 Acc: 0.87797964
val Loss: 0.33895826 Acc: 0.90748894
Epoch 19 of 120 took 1.709s
train Loss: 0.38677777 Acc: 0.88267612
val Loss: 0.32661919 Acc: 0.8942731
Epoch 20 of 120 took 1.662s
train Loss: 0.38625040 Acc: 0.88542312
val Loss: 0.31935079 Acc: 0.89867836
Epoch 21 of 120 took 1.661s
train Loss: 0.37342589 Acc: 0.88551176
val Loss: 0.30448016 Acc: 0.88986778
Epoch 22 of 120 took 1.660s
train Loss: 0.36919105 Acc: 0.88591051
val Loss: 0.36170049 Acc: 0.88986778
Epoch 23 of 120 took 1.706s
train Loss: 0.37541763 Acc: 0.88644218
val Loss: 0.31189130 Acc: 0.88986778
Epoch 00024: reducing learning rate of group 0 to 2.0000e-03.
Epoch 24 of 120 took 1.662s
train Loss: 0.34092550 Acc: 0.89596808
val Loss: 0.30329573 Acc: 0.8942731
Epoch 25 of 120 took 1.662s
train Loss: 0.32926705 Acc: 0.89769608
val Loss: 0.28692829 Acc: 0.90308368
Epoch 26 of 120 took 1.668s
train Loss: 0.33203712 Acc: 0.8965441
val Loss: 0.28918759 Acc: 0.89867836
Epoch 27 of 120 took 1.707s
train Loss: 0.32575584 Acc: 0.8994683
val Loss: 0.27691883 Acc: 0.89867836
Epoch 28 of 120 took 1.668s
train Loss: 0.32000824 Acc: 0.90070891
val Loss: 0.28199637 Acc: 0.89867836
Epoch 29 of 120 took 1.661s
train Loss: 0.31713951 Acc: 0.90221536
val Loss: 0.28176686 Acc: 0.90308368
Epoch 30 of 120 took 1.663s
train Loss: 0.31987283 Acc: 0.90053171
val Loss: 0.28014281 Acc: 0.90748894
Epoch 31 of 120 took 1.707s
train Loss: 0.31731227 Acc: 0.90141779
val Loss: 0.28572762 Acc: 0.90308368
Epoch 32 of 120 took 1.661s
train Loss: 0.31627344 Acc: 0.90146214
val Loss: 0.29263187 Acc: 0.89867836
Epoch 33 of 120 took 1.662s
train Loss: 0.30927111 Acc: 0.90381038
val Loss: 0.28026781 Acc: 0.90308368
Epoch 00034: reducing learning rate of group 0 to 4.0000e-04.
Epoch 34 of 120 took 1.661s
train Loss: 0.30414705 Acc: 0.90567124
val Loss: 0.27713165 Acc: 0.89867836
Epoch 35 of 120 took 1.661s
train Loss: 0.30869345 Acc: 0.90270269
val Loss: 0.27705828 Acc: 0.90308368
Epoch 36 of 120 took 1.710s
train Loss: 0.30301175 Acc: 0.90682322
val Loss: 0.27856541 Acc: 0.89867836
Epoch 37 of 120 took 1.663s
train Loss: 0.30691485 Acc: 0.90558267
val Loss: 0.28166337 Acc: 0.90308368
Epoch 38 of 120 took 1.662s
train Loss: 0.30240755 Acc: 0.90474081
val Loss: 0.28261945 Acc: 0.89867836
Epoch 39 of 120 took 1.661s

Training complete in 1m 5s
Best val loss: 0.276919
ACCURACY TEST_0 FINAL : 86.938 %
TOP-3 ACCURACY TEST_0 FINAL : 95.311 %
22634
(22634, 12, 10, 7)
train Loss: 1.68155129 Acc: 0.59940797
val Loss: 1.35741597 Acc: 0.57017547
Epoch 1 of 120 took 1.849s
train Loss: 1.15942495 Acc: 0.65494388
val Loss: 1.10987138 Acc: 0.61842108
Epoch 2 of 120 took 1.669s
train Loss: 0.98305451 Acc: 0.702483
val Loss: 0.94624623 Acc: 0.66666669
Epoch 3 of 120 took 1.667s
train Loss: 0.82889873 Acc: 0.73765135
val Loss: 0.81141196 Acc: 0.71929824
Epoch 4 of 120 took 1.667s
train Loss: 0.73911590 Acc: 0.77074313
val Loss: 0.66686557 Acc: 0.73245615
Epoch 5 of 120 took 1.713s
train Loss: 0.69190842 Acc: 0.78373247
val Loss: 0.65287741 Acc: 0.75438595
Epoch 6 of 120 took 1.667s
train Loss: 0.63119129 Acc: 0.80136079
val Loss: 0.65806218 Acc: 0.7631579
Epoch 7 of 120 took 1.662s
train Loss: 0.59468758 Acc: 0.81006449
val Loss: 0.59837455 Acc: 0.7850877
Epoch 8 of 120 took 1.668s
train Loss: 0.56966692 Acc: 0.82159585
val Loss: 0.54341590 Acc: 0.81578946
Epoch 9 of 120 took 1.713s
train Loss: 0.54553163 Acc: 0.82694179
val Loss: 0.61082606 Acc: 0.81140351
Epoch 10 of 120 took 1.662s
train Loss: 0.51927009 Acc: 0.83736855
val Loss: 0.57080834 Acc: 0.83333331
Epoch 11 of 120 took 1.660s
train Loss: 0.51147231 Acc: 0.84116817
val Loss: 0.55736274 Acc: 0.81578946
Epoch 12 of 120 took 1.662s
train Loss: 0.49852086 Acc: 0.84324467
val Loss: 0.48986235 Acc: 0.82894737
Epoch 13 of 120 took 1.714s
train Loss: 0.48121392 Acc: 0.84629321
val Loss: 0.49914611 Acc: 0.83333331
Epoch 14 of 120 took 1.662s
train Loss: 0.47188359 Acc: 0.85075551
val Loss: 0.53238980 Acc: 0.81578946
Epoch 15 of 120 took 1.664s
train Loss: 0.44806689 Acc: 0.85755944
val Loss: 0.44366448 Acc: 0.83771932
Epoch 16 of 120 took 1.668s
train Loss: 0.45926868 Acc: 0.85716182
val Loss: 0.42558188 Acc: 0.85964912
Epoch 17 of 120 took 1.711s
train Loss: 0.44424302 Acc: 0.85914999
val Loss: 0.53310592 Acc: 0.82456142
Epoch 18 of 120 took 1.661s
train Loss: 0.43332517 Acc: 0.8633914
val Loss: 0.49953816 Acc: 0.82894737
Epoch 19 of 120 took 1.660s
train Loss: 0.41685250 Acc: 0.86520278
val Loss: 0.46923855 Acc: 0.85087723
Epoch 20 of 120 took 1.663s
train Loss: 0.41532179 Acc: 0.86811876
val Loss: 0.36229184 Acc: 0.87719297
Epoch 21 of 120 took 1.710s
train Loss: 0.40164529 Acc: 0.86970931
val Loss: 0.41770438 Acc: 0.85526317
Epoch 22 of 120 took 1.661s
train Loss: 0.40229928 Acc: 0.86984187
val Loss: 0.40133709 Acc: 0.86403507
Epoch 23 of 120 took 1.663s
train Loss: 0.39473139 Acc: 0.87421578
val Loss: 0.35114676 Acc: 0.87280703
Epoch 24 of 120 took 1.672s
train Loss: 0.38606257 Acc: 0.87624812
val Loss: 0.35967083 Acc: 0.88157898
Epoch 25 of 120 took 1.711s
train Loss: 0.38344580 Acc: 0.87567377
val Loss: 0.38383578 Acc: 0.85964912
Epoch 26 of 120 took 1.669s
train Loss: 0.38174048 Acc: 0.8777945
val Loss: 0.37673623 Acc: 0.87280703
Epoch 27 of 120 took 1.671s
train Loss: 0.36554370 Acc: 0.88358223
val Loss: 0.36420381 Acc: 0.88157898
Epoch 28 of 120 took 1.671s
train Loss: 0.37499249 Acc: 0.87911993
val Loss: 0.37918316 Acc: 0.86842108
Epoch 29 of 120 took 1.714s
train Loss: 0.36667594 Acc: 0.88124061
val Loss: 0.33617434 Acc: 0.90350878
Epoch 30 of 120 took 1.677s
train Loss: 0.35500378 Acc: 0.88570297
val Loss: 0.37039844 Acc: 0.88596493
Epoch 31 of 120 took 1.671s
train Loss: 0.35238774 Acc: 0.88813293
val Loss: 0.34258912 Acc: 0.88157898
Epoch 32 of 120 took 1.672s
train Loss: 0.34392197 Acc: 0.88888401
val Loss: 0.34664918 Acc: 0.90350878
Epoch 33 of 120 took 1.714s
train Loss: 0.34521925 Acc: 0.8893258
val Loss: 0.37686252 Acc: 0.87280703
Epoch 34 of 120 took 1.672s
train Loss: 0.34301645 Acc: 0.89003271
val Loss: 0.34178272 Acc: 0.89473683
Epoch 35 of 120 took 1.671s
train Loss: 0.33476829 Acc: 0.89436245
val Loss: 0.32286708 Acc: 0.89035088
Epoch 36 of 120 took 1.677s
train Loss: 0.33363453 Acc: 0.89224178
val Loss: 0.31460368 Acc: 0.89912283
Epoch 37 of 120 took 1.720s
train Loss: 0.33174381 Acc: 0.89453918
val Loss: 0.28116140 Acc: 0.92543858
Epoch 38 of 120 took 1.678s
train Loss: 0.32247895 Acc: 0.89701337
val Loss: 0.33258979 Acc: 0.88596493
Epoch 39 of 120 took 1.671s
train Loss: 0.32616165 Acc: 0.895953
val Loss: 0.28562545 Acc: 0.91228068
Epoch 40 of 120 took 1.717s
train Loss: 0.32380473 Acc: 0.89599717
val Loss: 0.28538577 Acc: 0.91228068
Epoch 41 of 120 took 1.671s
train Loss: 0.31934303 Acc: 0.89749932
val Loss: 0.28278676 Acc: 0.88596493
Epoch 42 of 120 took 1.663s
train Loss: 0.31490507 Acc: 0.89891315
val Loss: 0.29070925 Acc: 0.90350878
Epoch 43 of 120 took 1.662s
train Loss: 0.31589826 Acc: 0.89935499
val Loss: 0.26020981 Acc: 0.91666669
Epoch 44 of 120 took 1.713s
train Loss: 0.31163211 Acc: 0.90182912
val Loss: 0.29314064 Acc: 0.89912283
Epoch 45 of 120 took 1.662s
train Loss: 0.30631166 Acc: 0.90302199
val Loss: 0.28985470 Acc: 0.91666669
Epoch 46 of 120 took 1.661s
train Loss: 0.30423886 Acc: 0.90253603
val Loss: 0.30614756 Acc: 0.92105263
Epoch 47 of 120 took 1.662s
train Loss: 0.31001586 Acc: 0.90010607
val Loss: 0.28670623 Acc: 0.89473683
Epoch 48 of 120 took 1.707s
train Loss: 0.30153888 Acc: 0.90408236
val Loss: 0.26477801 Acc: 0.90789473
Epoch 49 of 120 took 1.663s
train Loss: 0.29526304 Acc: 0.9048776
val Loss: 0.29251217 Acc: 0.90789473
Epoch 00050: reducing learning rate of group 0 to 2.0000e-03.
Epoch 50 of 120 took 1.662s
train Loss: 0.27360705 Acc: 0.9113723
val Loss: 0.24604663 Acc: 0.91228068
Epoch 51 of 120 took 1.668s
train Loss: 0.25949628 Acc: 0.91530442
val Loss: 0.23498314 Acc: 0.92105263
Epoch 52 of 120 took 1.666s
train Loss: 0.25461264 Acc: 0.91901565
val Loss: 0.22763307 Acc: 0.92982459
Epoch 53 of 120 took 1.715s
train Loss: 0.24628622 Acc: 0.91852969
val Loss: 0.22570259 Acc: 0.92543858
Epoch 54 of 120 took 1.666s
train Loss: 0.25021663 Acc: 0.91901565
val Loss: 0.22716060 Acc: 0.91666669
Epoch 55 of 120 took 1.662s
train Loss: 0.24772823 Acc: 0.91795528
val Loss: 0.23956925 Acc: 0.90789473
Epoch 56 of 120 took 1.661s
train Loss: 0.24507360 Acc: 0.92016435
val Loss: 0.21967187 Acc: 0.90789473
Epoch 57 of 120 took 1.713s
train Loss: 0.24712283 Acc: 0.92012018
val Loss: 0.24057580 Acc: 0.91228068
Epoch 58 of 120 took 1.663s
train Loss: 0.24952886 Acc: 0.91994345
val Loss: 0.23087608 Acc: 0.91666669
Epoch 59 of 120 took 1.661s
train Loss: 0.23988917 Acc: 0.9229036
val Loss: 0.22789832 Acc: 0.90789473
Epoch 60 of 120 took 1.662s
train Loss: 0.23893887 Acc: 0.92246181
val Loss: 0.22888578 Acc: 0.90789473
Epoch 61 of 120 took 1.708s
train Loss: 0.23385665 Acc: 0.92378724
val Loss: 0.22301824 Acc: 0.92543858
Epoch 62 of 120 took 1.661s
train Loss: 0.23769111 Acc: 0.92299199
val Loss: 0.22923741 Acc: 0.91228068
Epoch 00063: reducing learning rate of group 0 to 4.0000e-04.
Epoch 63 of 120 took 1.660s
train Loss: 0.23233787 Acc: 0.92347795
val Loss: 0.21116389 Acc: 0.92543858
Epoch 64 of 120 took 1.668s
train Loss: 0.23068833 Acc: 0.92674738
val Loss: 0.20879178 Acc: 0.92982459
Epoch 65 of 120 took 1.667s
train Loss: 0.23254099 Acc: 0.92259437
val Loss: 0.20873642 Acc: 0.92982459
Epoch 66 of 120 took 1.713s
train Loss: 0.22878521 Acc: 0.92537779
val Loss: 0.21249050 Acc: 0.92543858
Epoch 67 of 120 took 1.661s
train Loss: 0.22984017 Acc: 0.92758685
val Loss: 0.21134806 Acc: 0.92105263
Epoch 68 of 120 took 1.663s
train Loss: 0.23144991 Acc: 0.9249801
val Loss: 0.21062316 Acc: 0.92543858
Epoch 69 of 120 took 1.661s
train Loss: 0.22705079 Acc: 0.92475921
val Loss: 0.21628586 Acc: 0.91666669
Epoch 70 of 120 took 1.708s
train Loss: 0.23014709 Acc: 0.92515683
val Loss: 0.20980782 Acc: 0.92543858
Epoch 71 of 120 took 1.660s
train Loss: 0.23060105 Acc: 0.92502433
val Loss: 0.20794763 Acc: 0.92543858
Epoch 72 of 120 took 1.666s
train Loss: 0.22965488 Acc: 0.92617303
val Loss: 0.20410004 Acc: 0.92543858
Epoch 73 of 120 took 1.666s
train Loss: 0.23063178 Acc: 0.92683578
val Loss: 0.20730182 Acc: 0.92105263
Epoch 74 of 120 took 1.662s
train Loss: 0.22904385 Acc: 0.9250685
val Loss: 0.20721408 Acc: 0.92105263
Epoch 75 of 120 took 1.706s
train Loss: 0.22356486 Acc: 0.92657065
val Loss: 0.21239398 Acc: 0.92543858
Epoch 76 of 120 took 1.660s
train Loss: 0.22822866 Acc: 0.92612886
val Loss: 0.21225224 Acc: 0.92543858
Epoch 77 of 120 took 1.662s
train Loss: 0.22979302 Acc: 0.92489177
val Loss: 0.20690451 Acc: 0.92543858
Epoch 78 of 120 took 1.661s
train Loss: 0.22776826 Acc: 0.9249801
val Loss: 0.20714864 Acc: 0.92105263
Epoch 00079: reducing learning rate of group 0 to 8.0000e-05.
Epoch 79 of 120 took 1.709s
train Loss: 0.22811383 Acc: 0.92595214
val Loss: 0.21327858 Acc: 0.92982459
Epoch 80 of 120 took 1.661s
train Loss: 0.22044710 Acc: 0.92794031
val Loss: 0.21227519 Acc: 0.92105263
Epoch 81 of 120 took 1.661s
train Loss: 0.22461704 Acc: 0.9281612
val Loss: 0.20921371 Acc: 0.92543858
Epoch 82 of 120 took 1.661s
train Loss: 0.22236076 Acc: 0.92847043
val Loss: 0.20919066 Acc: 0.92543858
Epoch 83 of 120 took 1.704s
train Loss: 0.22702242 Acc: 0.92604047
val Loss: 0.21454291 Acc: 0.92543858
Epoch 84 of 120 took 1.661s

Training complete in 2m 21s
Best val loss: 0.204100
ACCURACY TEST_0 FINAL : 84.377 %
TOP-3 ACCURACY TEST_0 FINAL : 95.053 %
22621
(22621, 12, 10, 7)
train Loss: 1.76151606 Acc: 0.63096237
val Loss: 1.07589377 Acc: 0.65350878
Epoch 1 of 120 took 1.812s
train Loss: 1.07887225 Acc: 0.69811237
val Loss: 0.84206336 Acc: 0.77192986
Epoch 2 of 120 took 1.638s
train Loss: 0.91274368 Acc: 0.74324745
val Loss: 0.71459844 Acc: 0.80701756
Epoch 3 of 120 took 1.716s
train Loss: 0.82038731 Acc: 0.76791477
val Loss: 0.64496191 Acc: 0.81140351
Epoch 4 of 120 took 1.670s
train Loss: 0.74948962 Acc: 0.78665841
val Loss: 0.61766160 Acc: 0.82456142
Epoch 5 of 120 took 1.670s
train Loss: 0.70349588 Acc: 0.79771006
val Loss: 0.56008172 Acc: 0.83771932
Epoch 6 of 120 took 1.672s
train Loss: 0.66152794 Acc: 0.80544627
val Loss: 0.55875938 Acc: 0.83771932
Epoch 7 of 120 took 1.716s
train Loss: 0.63144723 Acc: 0.81481808
val Loss: 0.49400540 Acc: 0.85526317
Epoch 8 of 120 took 1.668s
train Loss: 0.59936733 Acc: 0.82445514
val Loss: 0.46408259 Acc: 0.85964912
Epoch 9 of 120 took 1.670s
train Loss: 0.56912308 Acc: 0.83046728
val Loss: 0.44673763 Acc: 0.86403507
Epoch 10 of 120 took 1.669s
train Loss: 0.54245133 Acc: 0.83471107
val Loss: 0.41018024 Acc: 0.85964912
Epoch 11 of 120 took 1.668s
train Loss: 0.54089515 Acc: 0.83842444
val Loss: 0.39482103 Acc: 0.86842108
Epoch 12 of 120 took 1.714s
train Loss: 0.51274332 Acc: 0.84288937
val Loss: 0.42016424 Acc: 0.87280703
Epoch 13 of 120 took 1.662s
train Loss: 0.50018990 Acc: 0.84713322
val Loss: 0.39233199 Acc: 0.88596493
Epoch 14 of 120 took 1.670s
train Loss: 0.48779506 Acc: 0.85071391
val Loss: 0.37525100 Acc: 0.88596493
Epoch 15 of 120 took 1.667s
train Loss: 0.47899797 Acc: 0.85438311
val Loss: 0.36079293 Acc: 0.86842108
Epoch 16 of 120 took 1.716s
train Loss: 0.45186957 Acc: 0.85858274
val Loss: 0.38246459 Acc: 0.86842108
Epoch 17 of 120 took 1.662s
train Loss: 0.44512308 Acc: 0.86194241
val Loss: 0.32837757 Acc: 0.89473683
Epoch 18 of 120 took 1.669s
train Loss: 0.43781780 Acc: 0.86662835
val Loss: 0.32144778 Acc: 0.89035088
Epoch 19 of 120 took 1.669s
train Loss: 0.42484729 Acc: 0.86777771
val Loss: 0.32451437 Acc: 0.89035088
Epoch 20 of 120 took 1.663s
train Loss: 0.42356440 Acc: 0.86901551
val Loss: 0.34721546 Acc: 0.88596493
Epoch 21 of 120 took 1.709s
train Loss: 0.40371294 Acc: 0.87312675
val Loss: 0.35530171 Acc: 0.90350878
Epoch 22 of 120 took 1.661s
train Loss: 0.41264732 Acc: 0.8729499
val Loss: 0.34364221 Acc: 0.88596493
Epoch 23 of 120 took 1.664s
train Loss: 0.40479806 Acc: 0.87356877
val Loss: 0.27276673 Acc: 0.90789473
Epoch 24 of 120 took 1.669s
train Loss: 0.39346297 Acc: 0.87865257
val Loss: 0.26351655 Acc: 0.91666669
Epoch 25 of 120 took 1.712s
train Loss: 0.37941263 Acc: 0.8807745
val Loss: 0.30021858 Acc: 0.91666669
Epoch 26 of 120 took 1.663s
train Loss: 0.38407325 Acc: 0.88320589
val Loss: 0.30650480 Acc: 0.90350878
Epoch 27 of 120 took 1.663s
train Loss: 0.37229917 Acc: 0.88391316
val Loss: 0.32547991 Acc: 0.89473683
Epoch 28 of 120 took 1.664s
train Loss: 0.36790513 Acc: 0.88581407
val Loss: 0.33478078 Acc: 0.88596493
Epoch 29 of 120 took 1.710s
train Loss: 0.36456903 Acc: 0.88727289
val Loss: 0.29493273 Acc: 0.90350878
Epoch 30 of 120 took 1.662s
train Loss: 0.35566530 Acc: 0.88842225
val Loss: 0.28781659 Acc: 0.90789473
Epoch 00031: reducing learning rate of group 0 to 2.0000e-03.
Epoch 31 of 120 took 1.662s
train Loss: 0.32997219 Acc: 0.89483225
val Loss: 0.26768332 Acc: 0.92105263
Epoch 32 of 120 took 1.663s
train Loss: 0.31607842 Acc: 0.9011538
val Loss: 0.25567378 Acc: 0.91228068
Epoch 33 of 120 took 1.715s
train Loss: 0.31387611 Acc: 0.90004861
val Loss: 0.24857434 Acc: 0.91228068
Epoch 34 of 120 took 1.668s
train Loss: 0.30761817 Acc: 0.90239155
val Loss: 0.25490952 Acc: 0.91228068
Epoch 35 of 120 took 1.665s
train Loss: 0.30578492 Acc: 0.90150744
val Loss: 0.24947876 Acc: 0.91228068
Epoch 36 of 120 took 1.663s
train Loss: 0.30321306 Acc: 0.90340835
val Loss: 0.23811493 Acc: 0.91228068
Epoch 37 of 120 took 1.669s
train Loss: 0.30481718 Acc: 0.90230316
val Loss: 0.25454402 Acc: 0.90350878
Epoch 38 of 120 took 1.709s
train Loss: 0.30268923 Acc: 0.90446931
val Loss: 0.23624792 Acc: 0.91228068
Epoch 39 of 120 took 1.667s
train Loss: 0.29972671 Acc: 0.90522081
val Loss: 0.24176010 Acc: 0.91228068
Epoch 40 of 120 took 1.663s
train Loss: 0.30131523 Acc: 0.90561867
val Loss: 0.24700092 Acc: 0.92543858
Epoch 41 of 120 took 1.662s
train Loss: 0.29840670 Acc: 0.90517658
val Loss: 0.24026219 Acc: 0.91666669
Epoch 42 of 120 took 1.709s
train Loss: 0.29757921 Acc: 0.90707749
val Loss: 0.23445152 Acc: 0.92543858
Epoch 43 of 120 took 1.670s
train Loss: 0.29668055 Acc: 0.90526503
val Loss: 0.24474657 Acc: 0.91228068
Epoch 44 of 120 took 1.662s
train Loss: 0.28564585 Acc: 0.90995091
val Loss: 0.23798648 Acc: 0.91228068
Epoch 45 of 120 took 1.665s
train Loss: 0.28896754 Acc: 0.90862471
val Loss: 0.24652136 Acc: 0.90789473
Epoch 46 of 120 took 1.710s
train Loss: 0.29185234 Acc: 0.90769637
val Loss: 0.23641523 Acc: 0.91666669
Epoch 47 of 120 took 1.664s
train Loss: 0.28385999 Acc: 0.90911102
val Loss: 0.22298096 Acc: 0.91666669
Epoch 48 of 120 took 1.668s
train Loss: 0.28850696 Acc: 0.90676802
val Loss: 0.23499368 Acc: 0.90789473
Epoch 49 of 120 took 1.663s
train Loss: 0.29496633 Acc: 0.90822685
val Loss: 0.23248708 Acc: 0.91666669
Epoch 50 of 120 took 1.663s
train Loss: 0.28788965 Acc: 0.91127712
val Loss: 0.23378261 Acc: 0.90789473
Epoch 51 of 120 took 1.709s
train Loss: 0.28307448 Acc: 0.90809423
val Loss: 0.22626107 Acc: 0.90789473
Epoch 52 of 120 took 1.663s
train Loss: 0.28505689 Acc: 0.91030461
val Loss: 0.22717667 Acc: 0.91666669
Epoch 53 of 120 took 1.663s
train Loss: 0.28411642 Acc: 0.90888995
val Loss: 0.21721318 Acc: 0.91666669
Epoch 54 of 120 took 1.667s
train Loss: 0.28301272 Acc: 0.91216123
val Loss: 0.23123043 Acc: 0.91666669
Epoch 55 of 120 took 1.709s
train Loss: 0.27591704 Acc: 0.91499048
val Loss: 0.23083449 Acc: 0.91666669
Epoch 56 of 120 took 1.663s
train Loss: 0.27272909 Acc: 0.91207284
val Loss: 0.22511743 Acc: 0.92105263
Epoch 57 of 120 took 1.662s
train Loss: 0.27493871 Acc: 0.91140974
val Loss: 0.23370842 Acc: 0.91666669
Epoch 58 of 120 took 1.662s
train Loss: 0.27514621 Acc: 0.91423899
val Loss: 0.21544389 Acc: 0.91666669
Epoch 59 of 120 took 1.716s
train Loss: 0.27162207 Acc: 0.91516733
val Loss: 0.20788434 Acc: 0.92105263
Epoch 60 of 120 took 1.669s
train Loss: 0.27821624 Acc: 0.91149819
val Loss: 0.21581724 Acc: 0.92105263
Epoch 61 of 120 took 1.664s
train Loss: 0.26937247 Acc: 0.91344327
val Loss: 0.20202159 Acc: 0.92543858
Epoch 62 of 120 took 1.669s
train Loss: 0.26429894 Acc: 0.91556519
val Loss: 0.20831513 Acc: 0.91228068
Epoch 63 of 120 took 1.664s
train Loss: 0.26728246 Acc: 0.91463685
val Loss: 0.20577250 Acc: 0.92105263
Epoch 64 of 120 took 1.663s
train Loss: 0.26506616 Acc: 0.91463685
val Loss: 0.22603409 Acc: 0.91666669
Epoch 65 of 120 took 1.709s
train Loss: 0.26434571 Acc: 0.9165377
val Loss: 0.20642414 Acc: 0.92105263
Epoch 66 of 120 took 1.663s
train Loss: 0.26661357 Acc: 0.91547674
val Loss: 0.22412891 Acc: 0.91228068
Epoch 67 of 120 took 1.663s
train Loss: 0.26549907 Acc: 0.91728926
val Loss: 0.21653724 Acc: 0.90789473
Epoch 00068: reducing learning rate of group 0 to 4.0000e-04.
Epoch 68 of 120 took 1.663s
train Loss: 0.26117715 Acc: 0.9158746
val Loss: 0.21754789 Acc: 0.90789473
Epoch 69 of 120 took 1.710s
train Loss: 0.25792603 Acc: 0.91773129
val Loss: 0.20331626 Acc: 0.91228068
Epoch 70 of 120 took 1.663s
train Loss: 0.25987477 Acc: 0.91636091
val Loss: 0.20636299 Acc: 0.91228068
Epoch 71 of 120 took 1.663s
train Loss: 0.25523294 Acc: 0.91790813
val Loss: 0.20528476 Acc: 0.91228068
Epoch 72 of 120 took 1.661s
train Loss: 0.25735297 Acc: 0.91910172
val Loss: 0.21148287 Acc: 0.92105263
Epoch 73 of 120 took 1.709s

Training complete in 2m 2s
Best val loss: 0.202022
ACCURACY TEST_0 FINAL : 83.442 %
TOP-3 ACCURACY TEST_0 FINAL : 94.151 %
22553
(22553, 12, 10, 7)
train Loss: 2.13162486 Acc: 0.54826409
val Loss: 1.23970186 Acc: 0.62114537
Epoch 1 of 120 took 1.791s
train Loss: 1.27550998 Acc: 0.62803173
val Loss: 1.02175507 Acc: 0.73568279
Epoch 2 of 120 took 1.664s
train Loss: 1.09081795 Acc: 0.67640668
val Loss: 0.89361393 Acc: 0.76211452
Epoch 3 of 120 took 1.665s
train Loss: 0.95128236 Acc: 0.71884006
val Loss: 0.81936513 Acc: 0.77973562
Epoch 4 of 120 took 1.707s
train Loss: 0.86337607 Acc: 0.74194121
val Loss: 0.75056096 Acc: 0.79735678
Epoch 5 of 120 took 1.664s
train Loss: 0.79669501 Acc: 0.76184988
val Loss: 0.71709814 Acc: 0.79295152
Epoch 6 of 120 took 1.662s
train Loss: 0.73716239 Acc: 0.77834433
val Loss: 0.63283186 Acc: 0.83700436
Epoch 7 of 120 took 1.665s
train Loss: 0.68756565 Acc: 0.78880858
val Loss: 0.63408288 Acc: 0.8017621
Epoch 8 of 120 took 1.705s
train Loss: 0.66144326 Acc: 0.7973662
val Loss: 0.57707972 Acc: 0.83700436
Epoch 9 of 120 took 1.664s
train Loss: 0.61399315 Acc: 0.8095597
val Loss: 0.54501820 Acc: 0.83700436
Epoch 10 of 120 took 1.665s
train Loss: 0.59416933 Acc: 0.81275219
val Loss: 0.51760915 Acc: 0.84140968
Epoch 11 of 120 took 1.664s
train Loss: 0.56716185 Acc: 0.82232964
val Loss: 0.49189288 Acc: 0.8502202
Epoch 12 of 120 took 1.710s
train Loss: 0.55712675 Acc: 0.82490134
val Loss: 0.49882064 Acc: 0.83700436
Epoch 13 of 120 took 1.658s
train Loss: 0.52332095 Acc: 0.83257216
val Loss: 0.46747395 Acc: 0.86784136
Epoch 14 of 120 took 1.664s
train Loss: 0.50719609 Acc: 0.83975524
val Loss: 0.48137994 Acc: 0.84581494
Epoch 15 of 120 took 1.657s
train Loss: 0.49537987 Acc: 0.84259301
val Loss: 0.48573791 Acc: 0.86784136
Epoch 16 of 120 took 1.657s
train Loss: 0.48698632 Acc: 0.84294772
val Loss: 0.46069819 Acc: 0.85903078
Epoch 17 of 120 took 1.707s
train Loss: 0.46940890 Acc: 0.8522591
val Loss: 0.47770080 Acc: 0.87224668
Epoch 18 of 120 took 1.657s
train Loss: 0.46633443 Acc: 0.85123926
val Loss: 0.45277141 Acc: 0.84581494
Epoch 19 of 120 took 1.662s
train Loss: 0.45484611 Acc: 0.85261381
val Loss: 0.39010325 Acc: 0.87224668
Epoch 20 of 120 took 1.663s
train Loss: 0.43209606 Acc: 0.8635658
val Loss: 0.39824315 Acc: 0.85462552
Epoch 21 of 120 took 1.702s
train Loss: 0.42361102 Acc: 0.86094975
val Loss: 0.38949852 Acc: 0.87224668
Epoch 22 of 120 took 1.663s
train Loss: 0.42197433 Acc: 0.86547244
val Loss: 0.39019217 Acc: 0.85903078
Epoch 23 of 120 took 1.656s
train Loss: 0.41169649 Acc: 0.86706865
val Loss: 0.36235487 Acc: 0.8634361
Epoch 24 of 120 took 1.663s
train Loss: 0.40853620 Acc: 0.86919701
val Loss: 0.38471469 Acc: 0.87224668
Epoch 25 of 120 took 1.702s
train Loss: 0.39980267 Acc: 0.87234515
val Loss: 0.31129469 Acc: 0.88546252
Epoch 26 of 120 took 1.664s
train Loss: 0.39834876 Acc: 0.8719461
val Loss: 0.41562545 Acc: 0.84581494
Epoch 27 of 120 took 1.659s
train Loss: 0.37272861 Acc: 0.87917352
val Loss: 0.35842443 Acc: 0.88105726
Epoch 28 of 120 took 1.657s
train Loss: 0.36747360 Acc: 0.88170087
val Loss: 0.33137515 Acc: 0.88546252
Epoch 29 of 120 took 1.660s
train Loss: 0.36333066 Acc: 0.88236594
val Loss: 0.40755268 Acc: 0.87224668
Epoch 30 of 120 took 1.705s
train Loss: 0.36382706 Acc: 0.88125747
val Loss: 0.35850854 Acc: 0.8634361
Epoch 31 of 120 took 1.658s
train Loss: 0.35031373 Acc: 0.88524806
val Loss: 0.35288954 Acc: 0.8634361
Epoch 00032: reducing learning rate of group 0 to 2.0000e-03.
Epoch 32 of 120 took 1.656s
train Loss: 0.32551631 Acc: 0.89407176
val Loss: 0.31033490 Acc: 0.87224668
Epoch 33 of 120 took 1.664s
train Loss: 0.30893861 Acc: 0.8967765
val Loss: 0.34016753 Acc: 0.86784136
Epoch 34 of 120 took 1.704s
train Loss: 0.30186371 Acc: 0.90054536
val Loss: 0.32972154 Acc: 0.8634361
Epoch 35 of 120 took 1.656s
train Loss: 0.29777919 Acc: 0.90032369
val Loss: 0.31026032 Acc: 0.88105726
Epoch 36 of 120 took 1.670s
train Loss: 0.30062543 Acc: 0.90267366
val Loss: 0.33659450 Acc: 0.86784136
Epoch 37 of 120 took 1.658s
train Loss: 0.29268213 Acc: 0.90178686
val Loss: 0.31238853 Acc: 0.88105726
Epoch 38 of 120 took 1.701s
train Loss: 0.28984945 Acc: 0.90409255
val Loss: 0.29674356 Acc: 0.88105726
Epoch 39 of 120 took 1.664s
train Loss: 0.29334842 Acc: 0.90440297
val Loss: 0.31916477 Acc: 0.88105726
Epoch 40 of 120 took 1.656s
train Loss: 0.28942190 Acc: 0.90524542
val Loss: 0.33066962 Acc: 0.88546252
Epoch 41 of 120 took 1.658s
train Loss: 0.28757180 Acc: 0.90604353
val Loss: 0.32194513 Acc: 0.88986778
Epoch 42 of 120 took 1.690s
train Loss: 0.28586818 Acc: 0.90706336
val Loss: 0.29563330 Acc: 0.88546252
Epoch 43 of 120 took 1.649s
train Loss: 0.27820094 Acc: 0.90967941
val Loss: 0.30387142 Acc: 0.88105726
Epoch 44 of 120 took 1.644s
train Loss: 0.28026125 Acc: 0.90639824
val Loss: 0.31836032 Acc: 0.88105726
Epoch 45 of 120 took 1.688s
train Loss: 0.28008149 Acc: 0.91025585
val Loss: 0.32143207 Acc: 0.88546252
Epoch 46 of 120 took 1.643s
train Loss: 0.27792796 Acc: 0.90959072
val Loss: 0.28859790 Acc: 0.8942731
Epoch 47 of 120 took 1.647s
train Loss: 0.27336807 Acc: 0.90954638
val Loss: 0.30412022 Acc: 0.88105726
Epoch 48 of 120 took 1.643s
train Loss: 0.27721759 Acc: 0.91043317
val Loss: 0.33129844 Acc: 0.87665194
Epoch 49 of 120 took 1.642s
train Loss: 0.27697355 Acc: 0.90763974
val Loss: 0.34579840 Acc: 0.88546252
Epoch 50 of 120 took 1.700s
train Loss: 0.27586127 Acc: 0.91074359
val Loss: 0.30672501 Acc: 0.88546252
Epoch 51 of 120 took 1.658s
train Loss: 0.26917766 Acc: 0.91123134
val Loss: 0.30124308 Acc: 0.8942731
Epoch 52 of 120 took 1.657s
train Loss: 0.26301412 Acc: 0.91358131
val Loss: 0.29314756 Acc: 0.88986778
Epoch 00053: reducing learning rate of group 0 to 4.0000e-04.
Epoch 53 of 120 took 1.657s
train Loss: 0.26097949 Acc: 0.91437948
val Loss: 0.29334177 Acc: 0.88986778
Epoch 54 of 120 took 1.704s
train Loss: 0.26353052 Acc: 0.91327095
val Loss: 0.31290595 Acc: 0.8942731
Epoch 55 of 120 took 1.658s
train Loss: 0.25935064 Acc: 0.91406906
val Loss: 0.28421586 Acc: 0.8942731
Epoch 56 of 120 took 1.665s
train Loss: 0.26117741 Acc: 0.91344833
val Loss: 0.28255880 Acc: 0.8942731
Epoch 57 of 120 took 1.709s
train Loss: 0.25708891 Acc: 0.91619742
val Loss: 0.28081447 Acc: 0.8942731
Epoch 58 of 120 took 1.664s
train Loss: 0.25655861 Acc: 0.91650778
val Loss: 0.30877737 Acc: 0.88546252
Epoch 59 of 120 took 1.658s
train Loss: 0.25748404 Acc: 0.91278321
val Loss: 0.28040108 Acc: 0.89867836
Epoch 60 of 120 took 1.665s
train Loss: 0.25772144 Acc: 0.91539925
val Loss: 0.28880996 Acc: 0.88986778
Epoch 61 of 120 took 1.706s
train Loss: 0.25301667 Acc: 0.91748327
val Loss: 0.29200207 Acc: 0.88986778
Epoch 62 of 120 took 1.658s
train Loss: 0.25725611 Acc: 0.91389173
val Loss: 0.27797761 Acc: 0.88546252
Epoch 63 of 120 took 1.665s
train Loss: 0.25867142 Acc: 0.91486716
val Loss: 0.26622359 Acc: 0.8942731
Epoch 64 of 120 took 1.708s
train Loss: 0.25570502 Acc: 0.91486716
val Loss: 0.27851163 Acc: 0.8942731
Epoch 65 of 120 took 1.658s
train Loss: 0.25279049 Acc: 0.91726154
val Loss: 0.24993416 Acc: 0.90308368
Epoch 66 of 120 took 1.664s
train Loss: 0.25032123 Acc: 0.91624171
val Loss: 0.27700034 Acc: 0.88986778
Epoch 67 of 120 took 1.658s
train Loss: 0.26172083 Acc: 0.91508889
val Loss: 0.27944421 Acc: 0.88986778
Epoch 68 of 120 took 1.657s
train Loss: 0.25534319 Acc: 0.91624171
val Loss: 0.26763532 Acc: 0.89867836
Epoch 69 of 120 took 1.706s
train Loss: 0.25661004 Acc: 0.915887
val Loss: 0.29383512 Acc: 0.88986778
Epoch 70 of 120 took 1.658s
train Loss: 0.24765307 Acc: 0.91659647
val Loss: 0.29210198 Acc: 0.88546252
Epoch 71 of 120 took 1.657s
train Loss: 0.25668858 Acc: 0.9133153
val Loss: 0.27471613 Acc: 0.88546252
Epoch 00072: reducing learning rate of group 0 to 8.0000e-05.
Epoch 72 of 120 took 1.658s
train Loss: 0.24639159 Acc: 0.91703987
val Loss: 0.29309644 Acc: 0.88986778
Epoch 73 of 120 took 1.704s
train Loss: 0.25403122 Acc: 0.9171285
val Loss: 0.25952723 Acc: 0.89867836
Epoch 74 of 120 took 1.658s
train Loss: 0.24667182 Acc: 0.91615307
val Loss: 0.27585160 Acc: 0.8942731
Epoch 75 of 120 took 1.659s
train Loss: 0.25264679 Acc: 0.91557664
val Loss: 0.26679163 Acc: 0.90308368
Epoch 76 of 120 took 1.656s
train Loss: 0.25026598 Acc: 0.91770494
val Loss: 0.28025525 Acc: 0.88986778
Epoch 77 of 120 took 1.702s

Training complete in 2m 9s
Best val loss: 0.249934
ACCURACY TEST_0 FINAL : 83.024 %
TOP-3 ACCURACY TEST_0 FINAL : 93.741 %
22527
(22527, 12, 10, 7)
train Loss: 1.63958602 Acc: 0.6232965
val Loss: 0.97644944 Acc: 0.71365637
Epoch 1 of 120 took 1.856s
train Loss: 1.04598364 Acc: 0.69578725
val Loss: 0.80879902 Acc: 0.75770921
Epoch 2 of 120 took 1.600s
train Loss: 0.87812577 Acc: 0.74035603
val Loss: 0.75362434 Acc: 0.77533036
Epoch 3 of 120 took 1.635s
train Loss: 0.78283202 Acc: 0.76481551
val Loss: 0.67859749 Acc: 0.78414094
Epoch 4 of 120 took 1.680s
train Loss: 0.72038745 Acc: 0.78199494
val Loss: 0.64652034 Acc: 0.8017621
Epoch 5 of 120 took 1.647s
train Loss: 0.67252724 Acc: 0.79770941
val Loss: 0.57427502 Acc: 0.82378852
Epoch 6 of 120 took 1.644s
train Loss: 0.62349093 Acc: 0.80956185
val Loss: 0.53645780 Acc: 0.82378852
Epoch 7 of 120 took 1.636s
train Loss: 0.59074391 Acc: 0.81999379
val Loss: 0.52106694 Acc: 0.84140968
Epoch 8 of 120 took 1.682s
train Loss: 0.58442142 Acc: 0.82163626
val Loss: 0.49030097 Acc: 0.85462552
Epoch 9 of 120 took 1.637s
train Loss: 0.54095234 Acc: 0.83193499
val Loss: 0.48179872 Acc: 0.84581494
Epoch 10 of 120 took 1.637s
train Loss: 0.53032843 Acc: 0.83397698
val Loss: 0.49472477 Acc: 0.83700436
Epoch 11 of 120 took 1.630s
train Loss: 0.51088952 Acc: 0.84139031
val Loss: 0.44631648 Acc: 0.85462552
Epoch 12 of 120 took 1.685s
train Loss: 0.48837739 Acc: 0.84738314
val Loss: 0.44073995 Acc: 0.87665194
Epoch 13 of 120 took 1.638s
train Loss: 0.47604304 Acc: 0.85084563
val Loss: 0.40762340 Acc: 0.88986778
Epoch 14 of 120 took 1.638s
train Loss: 0.45692494 Acc: 0.85768187
val Loss: 0.40923417 Acc: 0.88986778
Epoch 15 of 120 took 1.631s
train Loss: 0.45051130 Acc: 0.85581744
val Loss: 0.39161171 Acc: 0.87224668
Epoch 16 of 120 took 1.683s
train Loss: 0.44781085 Acc: 0.86078924
val Loss: 0.39843808 Acc: 0.85903078
Epoch 17 of 120 took 1.632s
train Loss: 0.43849091 Acc: 0.86114436
val Loss: 0.37919718 Acc: 0.86784136
Epoch 18 of 120 took 1.636s
train Loss: 0.41810507 Acc: 0.8665157
val Loss: 0.36871167 Acc: 0.88986778
Epoch 19 of 120 took 1.638s
train Loss: 0.41508677 Acc: 0.86700404
val Loss: 0.39416625 Acc: 0.88105726
Epoch 20 of 120 took 1.678s
train Loss: 0.40239565 Acc: 0.87202024
val Loss: 0.37039164 Acc: 0.8942731
Epoch 21 of 120 took 1.630s
train Loss: 0.39116923 Acc: 0.87481689
val Loss: 0.35440967 Acc: 0.89867836
Epoch 22 of 120 took 1.636s
train Loss: 0.38884944 Acc: 0.87486124
val Loss: 0.34042025 Acc: 0.91189426
Epoch 23 of 120 took 1.682s
train Loss: 0.38918314 Acc: 0.87619299
val Loss: 0.33149536 Acc: 0.90748894
Epoch 24 of 120 took 1.636s
train Loss: 0.36620344 Acc: 0.88156432
val Loss: 0.33849436 Acc: 0.88546252
Epoch 25 of 120 took 1.631s
train Loss: 0.36872564 Acc: 0.88325119
val Loss: 0.28597355 Acc: 0.9251101
Epoch 26 of 120 took 1.638s
train Loss: 0.36305368 Acc: 0.88422781
val Loss: 0.29504293 Acc: 0.91189426
Epoch 27 of 120 took 1.631s
train Loss: 0.35273197 Acc: 0.88729078
val Loss: 0.29946079 Acc: 0.91189426
Epoch 28 of 120 took 1.630s
train Loss: 0.35377052 Acc: 0.88458294
val Loss: 0.28436406 Acc: 0.91629952
Epoch 29 of 120 took 1.682s
train Loss: 0.33655427 Acc: 0.89337236
val Loss: 0.28383752 Acc: 0.92070478
Epoch 30 of 120 took 1.638s
train Loss: 0.33772479 Acc: 0.89079767
val Loss: 0.29411265 Acc: 0.9251101
Epoch 31 of 120 took 1.634s
train Loss: 0.32628903 Acc: 0.89350557
val Loss: 0.28049517 Acc: 0.91629952
Epoch 32 of 120 took 1.637s
train Loss: 0.32899157 Acc: 0.89390504
val Loss: 0.31006974 Acc: 0.92070478
Epoch 33 of 120 took 1.676s
train Loss: 0.32144710 Acc: 0.89608026
val Loss: 0.27881276 Acc: 0.91189426
Epoch 34 of 120 took 1.640s
train Loss: 0.33303275 Acc: 0.89306164
val Loss: 0.29432944 Acc: 0.91629952
Epoch 35 of 120 took 1.632s
train Loss: 0.31986192 Acc: 0.8973676
val Loss: 0.27239271 Acc: 0.9251101
Epoch 36 of 120 took 1.638s
train Loss: 0.31891189 Acc: 0.89559191
val Loss: 0.25496915 Acc: 0.91189426
Epoch 37 of 120 took 1.685s
train Loss: 0.31966447 Acc: 0.89488167
val Loss: 0.29155890 Acc: 0.90308368
Epoch 38 of 120 took 1.632s
train Loss: 0.31057130 Acc: 0.89812225
val Loss: 0.31921235 Acc: 0.91189426
Epoch 39 of 120 took 1.631s
train Loss: 0.30462768 Acc: 0.90256137
val Loss: 0.26893914 Acc: 0.91189426
Epoch 40 of 120 took 1.629s
train Loss: 0.29376389 Acc: 0.90469211
val Loss: 0.25916064 Acc: 0.91189426
Epoch 41 of 120 took 1.679s
train Loss: 0.30464291 Acc: 0.90154034
val Loss: 0.28032911 Acc: 0.90748894
Epoch 42 of 120 took 1.631s
train Loss: 0.29137711 Acc: 0.90642339
val Loss: 0.24853636 Acc: 0.93392068
Epoch 43 of 120 took 1.636s
train Loss: 0.29521065 Acc: 0.90473652
val Loss: 0.27644616 Acc: 0.90748894
Epoch 44 of 120 took 1.677s
train Loss: 0.28490951 Acc: 0.9058907
val Loss: 0.23712999 Acc: 0.91629952
Epoch 45 of 120 took 1.637s
train Loss: 0.28270810 Acc: 0.90828782
val Loss: 0.23463846 Acc: 0.93392068
Epoch 46 of 120 took 1.636s
train Loss: 0.30805341 Acc: 0.90158474
val Loss: 0.24966221 Acc: 0.92070478
Epoch 47 of 120 took 1.632s
train Loss: 0.28461244 Acc: 0.90882051
val Loss: 0.24191250 Acc: 0.92951536
Epoch 48 of 120 took 1.632s
train Loss: 0.26687647 Acc: 0.91210544
val Loss: 0.28976592 Acc: 0.89867836
Epoch 49 of 120 took 1.676s
train Loss: 0.27922753 Acc: 0.90913123
val Loss: 0.24793152 Acc: 0.91629952
Epoch 50 of 120 took 1.631s
train Loss: 0.27517922 Acc: 0.91064054
val Loss: 0.23714408 Acc: 0.92951536
Epoch 51 of 120 took 1.630s
train Loss: 0.27348029 Acc: 0.91166157
val Loss: 0.21710432 Acc: 0.92070478
Epoch 52 of 120 took 1.635s
train Loss: 0.26403645 Acc: 0.91281569
val Loss: 0.24163264 Acc: 0.92070478
Epoch 53 of 120 took 1.679s
train Loss: 0.26049256 Acc: 0.91383672
val Loss: 0.22563133 Acc: 0.9251101
Epoch 54 of 120 took 1.629s
train Loss: 0.26112870 Acc: 0.91583431
val Loss: 0.21888994 Acc: 0.94273126
Epoch 55 of 120 took 1.633s
train Loss: 0.26147372 Acc: 0.91396987
val Loss: 0.19727389 Acc: 0.93832594
Epoch 56 of 120 took 1.637s
train Loss: 0.27006759 Acc: 0.91161716
val Loss: 0.22598182 Acc: 0.92070478
Epoch 57 of 120 took 1.631s
train Loss: 0.26025787 Acc: 0.9149909
val Loss: 0.21439895 Acc: 0.9251101
Epoch 58 of 120 took 1.676s
train Loss: 0.25261516 Acc: 0.92080611
val Loss: 0.24956162 Acc: 0.91629952
Epoch 59 of 120 took 1.632s
train Loss: 0.25118406 Acc: 0.91960758
val Loss: 0.19270292 Acc: 0.93832594
Epoch 60 of 120 took 1.637s
train Loss: 0.25090540 Acc: 0.9178319
val Loss: 0.22090153 Acc: 0.92951536
Epoch 61 of 120 took 1.676s
train Loss: 0.26087108 Acc: 0.91396987
val Loss: 0.23881915 Acc: 0.92070478
Epoch 62 of 120 took 1.633s
train Loss: 0.25096848 Acc: 0.92058414
val Loss: 0.27316621 Acc: 0.92070478
Epoch 63 of 120 took 1.631s
train Loss: 0.25209458 Acc: 0.91774315
val Loss: 0.23981706 Acc: 0.92951536
Epoch 64 of 120 took 1.630s
train Loss: 0.23905803 Acc: 0.9220047
val Loss: 0.23859575 Acc: 0.91629952
Epoch 65 of 120 took 1.678s
train Loss: 0.23583588 Acc: 0.92391348
val Loss: 0.23131522 Acc: 0.92070478
Epoch 00066: reducing learning rate of group 0 to 2.0000e-03.
Epoch 66 of 120 took 1.631s
train Loss: 0.21587940 Acc: 0.92915165
val Loss: 0.18976853 Acc: 0.93392068
Epoch 67 of 120 took 1.638s
train Loss: 0.20386930 Acc: 0.93199271
val Loss: 0.19107854 Acc: 0.94713652
Epoch 68 of 120 took 1.679s
train Loss: 0.19582104 Acc: 0.93496692
val Loss: 0.18904337 Acc: 0.93392068
Epoch 69 of 120 took 1.638s
train Loss: 0.19700112 Acc: 0.93470055
val Loss: 0.18623718 Acc: 0.93392068
Epoch 70 of 120 took 1.637s
train Loss: 0.19499599 Acc: 0.93527764
val Loss: 0.16971907 Acc: 0.94713652
Epoch 71 of 120 took 1.637s
train Loss: 0.19443195 Acc: 0.9360767
val Loss: 0.17579502 Acc: 0.94273126
Epoch 72 of 120 took 1.677s
train Loss: 0.19439562 Acc: 0.93683136
val Loss: 0.17923719 Acc: 0.93832594
Epoch 73 of 120 took 1.631s
train Loss: 0.18704810 Acc: 0.93674254
val Loss: 0.16699775 Acc: 0.94273126
Epoch 74 of 120 took 1.637s
train Loss: 0.19773796 Acc: 0.93470055
val Loss: 0.16080164 Acc: 0.94713652
Epoch 75 of 120 took 1.685s
train Loss: 0.18566026 Acc: 0.93736404
val Loss: 0.16250587 Acc: 0.95154178
Epoch 76 of 120 took 1.632s
train Loss: 0.19169521 Acc: 0.93669814
val Loss: 0.17028207 Acc: 0.93392068
Epoch 77 of 120 took 1.633s
train Loss: 0.18492453 Acc: 0.94007188
val Loss: 0.16622658 Acc: 0.94273126
Epoch 78 of 120 took 1.631s
train Loss: 0.18758947 Acc: 0.93763036
val Loss: 0.17118522 Acc: 0.93832594
Epoch 79 of 120 took 1.631s
train Loss: 0.18929929 Acc: 0.93758601
val Loss: 0.17041940 Acc: 0.94273126
Epoch 80 of 120 took 1.678s
train Loss: 0.18278824 Acc: 0.94073778
val Loss: 0.16970286 Acc: 0.94713652
Epoch 00081: reducing learning rate of group 0 to 4.0000e-04.
Epoch 81 of 120 took 1.632s
train Loss: 0.18032349 Acc: 0.94140363
val Loss: 0.15785259 Acc: 0.94713652
Epoch 82 of 120 took 1.640s
train Loss: 0.18510906 Acc: 0.93856257
val Loss: 0.15527041 Acc: 0.94713652
Epoch 83 of 120 took 1.680s
train Loss: 0.18005932 Acc: 0.93980557
val Loss: 0.15668853 Acc: 0.94713652
Epoch 84 of 120 took 1.631s
train Loss: 0.18122492 Acc: 0.94042701
val Loss: 0.15690642 Acc: 0.94713652
Epoch 85 of 120 took 1.630s
train Loss: 0.17725328 Acc: 0.94020504
val Loss: 0.15812040 Acc: 0.94713652
Epoch 86 of 120 took 1.633s
train Loss: 0.17759384 Acc: 0.94016069
val Loss: 0.15871129 Acc: 0.94713652
Epoch 87 of 120 took 1.678s
train Loss: 0.17311491 Acc: 0.94269097
val Loss: 0.16056038 Acc: 0.94713652
Epoch 88 of 120 took 1.630s
train Loss: 0.17556911 Acc: 0.94171435
val Loss: 0.15621556 Acc: 0.94713652
Epoch 00089: reducing learning rate of group 0 to 8.0000e-05.
Epoch 89 of 120 took 1.631s
train Loss: 0.17934369 Acc: 0.93998313
val Loss: 0.15863027 Acc: 0.94713652
Epoch 90 of 120 took 1.631s
train Loss: 0.17839162 Acc: 0.94078213
val Loss: 0.15736243 Acc: 0.94713652
Epoch 91 of 120 took 1.678s
train Loss: 0.17783789 Acc: 0.94091535
val Loss: 0.15634338 Acc: 0.94713652
Epoch 92 of 120 took 1.631s
train Loss: 0.17071689 Acc: 0.94251341
val Loss: 0.15718234 Acc: 0.94713652
Epoch 93 of 120 took 1.629s
train Loss: 0.17757502 Acc: 0.94056022
val Loss: 0.15601259 Acc: 0.94713652
Epoch 94 of 120 took 1.632s

Training complete in 2m 35s
Best val loss: 0.155270
ACCURACY TEST_0 FINAL : 84.207 %
TOP-3 ACCURACY TEST_0 FINAL : 94.284 %
22533
(22533, 12, 10, 7)
train Loss: 1.92170215 Acc: 0.66125238
val Loss: 1.26161738 Acc: 0.66079295
Epoch 1 of 120 took 1.788s
train Loss: 1.05404721 Acc: 0.7132206
val Loss: 1.03498959 Acc: 0.73568279
Epoch 2 of 120 took 1.666s
train Loss: 0.88153269 Acc: 0.75551414
val Loss: 0.87019025 Acc: 0.7709251
Epoch 3 of 120 took 1.665s
train Loss: 0.75873523 Acc: 0.78973061
val Loss: 0.76768763 Acc: 0.76211452
Epoch 4 of 120 took 1.665s
train Loss: 0.67546259 Acc: 0.81129897
val Loss: 0.69753324 Acc: 0.77973562
Epoch 5 of 120 took 1.711s
train Loss: 0.61919407 Acc: 0.8248347
val Loss: 0.59177703 Acc: 0.81497794
Epoch 6 of 120 took 1.663s
train Loss: 0.57045301 Acc: 0.83446503
val Loss: 0.55659266 Acc: 0.83700436
Epoch 7 of 120 took 1.665s
train Loss: 0.54153618 Acc: 0.84271955
val Loss: 0.51528934 Acc: 0.8502202
Epoch 8 of 120 took 1.667s
train Loss: 0.50917653 Acc: 0.85234988
val Loss: 0.49243794 Acc: 0.85903078
Epoch 9 of 120 took 1.667s
train Loss: 0.48723793 Acc: 0.85829669
val Loss: 0.45483533 Acc: 0.87665194
Epoch 10 of 120 took 1.715s
train Loss: 0.46639707 Acc: 0.86206895
val Loss: 0.46307975 Acc: 0.85903078
Epoch 11 of 120 took 1.658s
train Loss: 0.44461999 Acc: 0.86757201
val Loss: 0.44021788 Acc: 0.87224668
Epoch 12 of 120 took 1.666s
train Loss: 0.42606818 Acc: 0.87343007
val Loss: 0.44708438 Acc: 0.87224668
Epoch 13 of 120 took 1.660s
train Loss: 0.41465478 Acc: 0.87755734
val Loss: 0.41202143 Acc: 0.87665194
Epoch 14 of 120 took 1.713s
train Loss: 0.40717712 Acc: 0.8780455
val Loss: 0.40280014 Acc: 0.87224668
Epoch 15 of 120 took 1.667s
train Loss: 0.39017345 Acc: 0.88266098
val Loss: 0.38293571 Acc: 0.88986778
Epoch 16 of 120 took 1.666s
train Loss: 0.37238341 Acc: 0.88740957
val Loss: 0.35137573 Acc: 0.88105726
Epoch 17 of 120 took 1.667s
train Loss: 0.37557389 Acc: 0.88541251
val Loss: 0.36469835 Acc: 0.87224668
Epoch 18 of 120 took 1.704s
train Loss: 0.36271833 Acc: 0.88909596
val Loss: 0.37142578 Acc: 0.87224668
Epoch 19 of 120 took 1.660s
train Loss: 0.34385452 Acc: 0.89566416
val Loss: 0.32921701 Acc: 0.8942731
Epoch 20 of 120 took 1.665s
train Loss: 0.33969316 Acc: 0.89650732
val Loss: 0.32564480 Acc: 0.89867836
Epoch 21 of 120 took 1.667s
train Loss: 0.33472729 Acc: 0.89735055
val Loss: 0.41554530 Acc: 0.87665194
Epoch 22 of 120 took 1.708s
train Loss: 0.33407537 Acc: 0.89903694
val Loss: 0.31248270 Acc: 0.90748894
Epoch 23 of 120 took 1.665s
train Loss: 0.32618468 Acc: 0.89930326
val Loss: 0.35467623 Acc: 0.88546252
Epoch 24 of 120 took 1.660s
train Loss: 0.31908170 Acc: 0.90218788
val Loss: 0.27194573 Acc: 0.91189426
Epoch 25 of 120 took 1.664s
train Loss: 0.31140236 Acc: 0.90476191
val Loss: 0.30394279 Acc: 0.89867836
Epoch 26 of 120 took 1.704s
train Loss: 0.29801956 Acc: 0.90706962
val Loss: 0.27524332 Acc: 0.90308368
Epoch 27 of 120 took 1.660s
train Loss: 0.29772455 Acc: 0.90875602
val Loss: 0.24700677 Acc: 0.9251101
Epoch 28 of 120 took 1.666s
train Loss: 0.28794528 Acc: 0.90773529
val Loss: 0.26611043 Acc: 0.92070478
Epoch 29 of 120 took 1.659s
train Loss: 0.28602818 Acc: 0.90964365
val Loss: 0.26247361 Acc: 0.89867836
Epoch 30 of 120 took 1.707s
train Loss: 0.28121427 Acc: 0.9114188
val Loss: 0.23953006 Acc: 0.9251101
Epoch 31 of 120 took 1.666s
train Loss: 0.28035399 Acc: 0.91155195
val Loss: 0.24199206 Acc: 0.92951536
Epoch 32 of 120 took 1.660s
train Loss: 0.27425828 Acc: 0.91527981
val Loss: 0.24606875 Acc: 0.9251101
Epoch 33 of 120 took 1.663s
train Loss: 0.27313362 Acc: 0.91541296
val Loss: 0.23385243 Acc: 0.90748894
Epoch 34 of 120 took 1.713s
train Loss: 0.26775336 Acc: 0.91612303
val Loss: 0.24861299 Acc: 0.91629952
Epoch 35 of 120 took 1.660s
train Loss: 0.25670443 Acc: 0.91834199
val Loss: 0.26676897 Acc: 0.92070478
Epoch 36 of 120 took 1.662s
train Loss: 0.25411620 Acc: 0.91976213
val Loss: 0.23492907 Acc: 0.92070478
Epoch 37 of 120 took 1.660s
train Loss: 0.30763858 Acc: 0.90511692
val Loss: 0.30882141 Acc: 0.90748894
Epoch 38 of 120 took 1.703s
train Loss: 0.30040571 Acc: 0.90653706
val Loss: 0.31794227 Acc: 0.90748894
Epoch 39 of 120 took 1.662s
train Loss: 0.27997840 Acc: 0.91243953
val Loss: 0.27075288 Acc: 0.91629952
Epoch 00040: reducing learning rate of group 0 to 2.0000e-03.
Epoch 40 of 120 took 1.658s
train Loss: 0.24806862 Acc: 0.9206053
val Loss: 0.24663555 Acc: 0.89867836
Epoch 41 of 120 took 1.657s
train Loss: 0.23861974 Acc: 0.92384499
val Loss: 0.20610739 Acc: 0.9251101
Epoch 42 of 120 took 1.663s
train Loss: 0.23055648 Acc: 0.92522079
val Loss: 0.20306070 Acc: 0.9251101
Epoch 43 of 120 took 1.711s
train Loss: 0.22784240 Acc: 0.92655218
val Loss: 0.19795531 Acc: 0.93392068
Epoch 44 of 120 took 1.663s
train Loss: 0.22437760 Acc: 0.92819417
val Loss: 0.19045802 Acc: 0.94273126
Epoch 45 of 120 took 1.666s
train Loss: 0.22402423 Acc: 0.93036878
val Loss: 0.20018096 Acc: 0.93392068
Epoch 46 of 120 took 1.658s
train Loss: 0.22349296 Acc: 0.92872673
val Loss: 0.21201377 Acc: 0.92951536
Epoch 47 of 120 took 1.704s
train Loss: 0.21401622 Acc: 0.93134511
val Loss: 0.19325352 Acc: 0.93832594
Epoch 48 of 120 took 1.658s
train Loss: 0.21712967 Acc: 0.93090135
val Loss: 0.17838067 Acc: 0.93832594
Epoch 49 of 120 took 1.663s
train Loss: 0.20802067 Acc: 0.9328984
val Loss: 0.17937441 Acc: 0.93832594
Epoch 50 of 120 took 1.658s
train Loss: 0.21164450 Acc: 0.93360847
val Loss: 0.19173732 Acc: 0.94273126
Epoch 51 of 120 took 1.701s
train Loss: 0.21076280 Acc: 0.93063504
val Loss: 0.19155012 Acc: 0.93832594
Epoch 52 of 120 took 1.657s
train Loss: 0.20633015 Acc: 0.9327209
val Loss: 0.20989233 Acc: 0.9251101
Epoch 53 of 120 took 1.658s
train Loss: 0.20635429 Acc: 0.93325347
val Loss: 0.16802477 Acc: 0.94273126
Epoch 54 of 120 took 1.664s
train Loss: 0.21051651 Acc: 0.93196642
val Loss: 0.19467711 Acc: 0.9251101
Epoch 55 of 120 took 1.705s
train Loss: 0.20749645 Acc: 0.9325434
val Loss: 0.17310775 Acc: 0.93832594
Epoch 56 of 120 took 1.658s
train Loss: 0.20772038 Acc: 0.9346292
val Loss: 0.18553749 Acc: 0.93392068
Epoch 57 of 120 took 1.659s
train Loss: 0.20206970 Acc: 0.93502861
val Loss: 0.18199371 Acc: 0.94273126
Epoch 58 of 120 took 1.658s
train Loss: 0.20053987 Acc: 0.93569428
val Loss: 0.18700419 Acc: 0.93392068
Epoch 59 of 120 took 1.702s
train Loss: 0.20587811 Acc: 0.93551677
val Loss: 0.19450049 Acc: 0.92951536
Epoch 00060: reducing learning rate of group 0 to 4.0000e-04.
Epoch 60 of 120 took 1.658s
train Loss: 0.20071827 Acc: 0.93662626
val Loss: 0.17620560 Acc: 0.93392068
Epoch 61 of 120 took 1.659s
train Loss: 0.19645190 Acc: 0.9382683
val Loss: 0.18409116 Acc: 0.93392068
Epoch 62 of 120 took 1.658s
train Loss: 0.19377797 Acc: 0.93778014
val Loss: 0.17168469 Acc: 0.93392068
Epoch 63 of 120 took 1.703s
train Loss: 0.19680637 Acc: 0.93671501
val Loss: 0.18923558 Acc: 0.93392068
Epoch 64 of 120 took 1.658s
train Loss: 0.19467087 Acc: 0.93755823
val Loss: 0.18026710 Acc: 0.93392068
Epoch 65 of 120 took 1.657s

Training complete in 1m 49s
Best val loss: 0.168025
ACCURACY TEST_0 FINAL : 86.608 %
TOP-3 ACCURACY TEST_0 FINAL : 95.881 %
22593
(22593, 12, 10, 7)
train Loss: 1.86391481 Acc: 0.60930377
val Loss: 1.33761811 Acc: 0.62280703
Epoch 1 of 120 took 1.843s
train Loss: 1.19671065 Acc: 0.66201925
val Loss: 1.17831422 Acc: 0.67543858
Epoch 2 of 120 took 1.646s
train Loss: 1.03499900 Acc: 0.70676762
val Loss: 1.07271750 Acc: 0.70175439
Epoch 3 of 120 took 1.666s
train Loss: 0.94084326 Acc: 0.73257208
val Loss: 1.00449365 Acc: 0.70614034
Epoch 4 of 120 took 1.670s
train Loss: 0.87162652 Acc: 0.75492412
val Loss: 0.96419490 Acc: 0.70614034
Epoch 5 of 120 took 1.666s
train Loss: 0.79851628 Acc: 0.76984024
val Loss: 0.91740499 Acc: 0.71052635
Epoch 6 of 120 took 1.715s
train Loss: 0.74629005 Acc: 0.78130394
val Loss: 0.82688730 Acc: 0.75
Epoch 7 of 120 took 1.668s
train Loss: 0.70058422 Acc: 0.79219228
val Loss: 0.79698114 Acc: 0.75438595
Epoch 8 of 120 took 1.669s
train Loss: 0.66827812 Acc: 0.80108887
val Loss: 0.77322973 Acc: 0.7631579
Epoch 9 of 120 took 1.669s
train Loss: 0.64567438 Acc: 0.80768383
val Loss: 0.70877720 Acc: 0.7850877
Epoch 10 of 120 took 1.714s
train Loss: 0.61317872 Acc: 0.8173328
val Loss: 0.68486605 Acc: 0.79385966
Epoch 11 of 120 took 1.670s
train Loss: 0.58801409 Acc: 0.82299829
val Loss: 0.67727757 Acc: 0.7850877
Epoch 12 of 120 took 1.667s
train Loss: 0.57395210 Acc: 0.82808834
val Loss: 0.65497991 Acc: 0.80701756
Epoch 13 of 120 took 1.669s
train Loss: 0.54785346 Acc: 0.83406365
val Loss: 0.59808949 Acc: 0.81140351
Epoch 14 of 120 took 1.713s
train Loss: 0.53332617 Acc: 0.83809149
val Loss: 0.64989364 Acc: 0.81578946
Epoch 15 of 120 took 1.661s
train Loss: 0.52666390 Acc: 0.84344709
val Loss: 0.56984773 Acc: 0.82894737
Epoch 16 of 120 took 1.669s
train Loss: 0.50599657 Acc: 0.84388971
val Loss: 0.56297618 Acc: 0.82894737
Epoch 17 of 120 took 1.670s
train Loss: 0.49334010 Acc: 0.85243219
val Loss: 0.48988384 Acc: 0.84649122
Epoch 18 of 120 took 1.714s
train Loss: 0.47717898 Acc: 0.85460103
val Loss: 0.52673185 Acc: 0.83771932
Epoch 19 of 120 took 1.660s
train Loss: 0.47441853 Acc: 0.85398138
val Loss: 0.44955491 Acc: 0.88596493
Epoch 20 of 120 took 1.667s
train Loss: 0.45407659 Acc: 0.86137301
val Loss: 0.46456521 Acc: 0.87719297
Epoch 21 of 120 took 1.663s
train Loss: 0.44616872 Acc: 0.86128449
val Loss: 0.44695394 Acc: 0.88596493
Epoch 22 of 120 took 1.668s
train Loss: 0.44647919 Acc: 0.86159432
val Loss: 0.51599981 Acc: 0.85964912
Epoch 23 of 120 took 1.711s
train Loss: 0.43132079 Acc: 0.8669942
val Loss: 0.42686757 Acc: 0.87280703
Epoch 24 of 120 took 1.666s
train Loss: 0.41723726 Acc: 0.87146461
val Loss: 0.44222447 Acc: 0.87719297
Epoch 25 of 120 took 1.662s
train Loss: 0.42642095 Acc: 0.87053514
val Loss: 0.46002696 Acc: 0.85526317
Epoch 26 of 120 took 1.663s
train Loss: 0.41368226 Acc: 0.87474
val Loss: 0.43231228 Acc: 0.88596493
Epoch 27 of 120 took 1.661s
train Loss: 0.41217595 Acc: 0.87283677
val Loss: 0.40508635 Acc: 0.87719297
Epoch 28 of 120 took 1.711s
train Loss: 0.39000179 Acc: 0.88000709
val Loss: 0.40446824 Acc: 0.88157898
Epoch 29 of 120 took 1.668s
train Loss: 0.39038934 Acc: 0.87797105
val Loss: 0.40399007 Acc: 0.90350878
Epoch 30 of 120 took 1.668s
train Loss: 0.39367239 Acc: 0.88000709
val Loss: 0.53299894 Acc: 0.85087723
Epoch 31 of 120 took 1.660s
train Loss: 0.38636120 Acc: 0.88191032
val Loss: 0.37643374 Acc: 0.88596493
Epoch 32 of 120 took 1.714s
train Loss: 0.37227143 Acc: 0.88584965
val Loss: 0.38475271 Acc: 0.90350878
Epoch 33 of 120 took 1.663s
train Loss: 0.37143564 Acc: 0.88607091
val Loss: 0.40821179 Acc: 0.90350878
Epoch 34 of 120 took 1.661s
train Loss: 0.36916104 Acc: 0.89001018
val Loss: 0.37892495 Acc: 0.88157898
Epoch 35 of 120 took 1.662s
train Loss: 0.36225752 Acc: 0.88978893
val Loss: 0.37241836 Acc: 0.89912283
Epoch 36 of 120 took 1.711s
train Loss: 0.35480625 Acc: 0.89107251
val Loss: 0.35528808 Acc: 0.90789473
Epoch 37 of 120 took 1.666s
train Loss: 0.35148007 Acc: 0.89319706
val Loss: 0.38999257 Acc: 0.90789473
Epoch 38 of 120 took 1.661s
train Loss: 0.34096276 Acc: 0.89563143
val Loss: 0.33214957 Acc: 0.90789473
Epoch 39 of 120 took 1.665s
train Loss: 0.35145331 Acc: 0.89310849
val Loss: 0.32331026 Acc: 0.90789473
Epoch 40 of 120 took 1.666s
train Loss: 0.33671765 Acc: 0.89271015
val Loss: 0.33706683 Acc: 0.91228068
Epoch 41 of 120 took 1.705s
train Loss: 0.33537973 Acc: 0.89726907
val Loss: 0.33918620 Acc: 0.89473683
Epoch 42 of 120 took 1.661s
train Loss: 0.34877664 Acc: 0.89532161
val Loss: 0.34598206 Acc: 0.91228068
Epoch 43 of 120 took 1.658s
train Loss: 0.33821878 Acc: 0.89682651
val Loss: 0.35805345 Acc: 0.91228068
Epoch 44 of 120 took 1.658s
train Loss: 0.32800539 Acc: 0.89965922
val Loss: 0.34192975 Acc: 0.92543858
Epoch 45 of 120 took 1.706s
train Loss: 0.32386568 Acc: 0.90050018
val Loss: 0.36958827 Acc: 0.90350878
Epoch 00046: reducing learning rate of group 0 to 2.0000e-03.
Epoch 46 of 120 took 1.661s
train Loss: 0.30019354 Acc: 0.90629846
val Loss: 0.32335322 Acc: 0.92105263
Epoch 47 of 120 took 1.661s
train Loss: 0.29577295 Acc: 0.90846723
val Loss: 0.31396825 Acc: 0.92543858
Epoch 48 of 120 took 1.664s
train Loss: 0.28506303 Acc: 0.91085738
val Loss: 0.29605327 Acc: 0.94298244
Epoch 49 of 120 took 1.712s
train Loss: 0.28036337 Acc: 0.9113
val Loss: 0.28983444 Acc: 0.92982459
Epoch 50 of 120 took 1.664s
train Loss: 0.27803163 Acc: 0.91231799
val Loss: 0.30015307 Acc: 0.94736844
Epoch 51 of 120 took 1.660s
train Loss: 0.28131509 Acc: 0.91262782
val Loss: 0.30258457 Acc: 0.93859649
Epoch 52 of 120 took 1.659s
train Loss: 0.27214456 Acc: 0.91621304
val Loss: 0.30890088 Acc: 0.90789473
Epoch 53 of 120 took 1.679s
train Loss: 0.27691595 Acc: 0.91360158
val Loss: 0.27768827 Acc: 0.92543858
Epoch 54 of 120 took 1.712s
train Loss: 0.27480511 Acc: 0.91382289
val Loss: 0.29606524 Acc: 0.93421054
Epoch 55 of 120 took 1.658s
train Loss: 0.26895354 Acc: 0.91669989
val Loss: 0.28382448 Acc: 0.93859649
Epoch 56 of 120 took 1.662s
train Loss: 0.27578340 Acc: 0.91346878
val Loss: 0.29352027 Acc: 0.93859649
Epoch 57 of 120 took 1.708s
train Loss: 0.27147536 Acc: 0.91448683
val Loss: 0.27295377 Acc: 0.94298244
Epoch 58 of 120 took 1.666s
train Loss: 0.26921570 Acc: 0.9154163
val Loss: 0.29673452 Acc: 0.93859649
Epoch 59 of 120 took 1.662s
train Loss: 0.26766674 Acc: 0.91546059
val Loss: 0.28413107 Acc: 0.94736844
Epoch 60 of 120 took 1.659s
train Loss: 0.26828382 Acc: 0.91674417
val Loss: 0.27023217 Acc: 0.92982459
Epoch 61 of 120 took 1.664s
train Loss: 0.26327324 Acc: 0.91824907
val Loss: 0.29066533 Acc: 0.94736844
Epoch 62 of 120 took 1.704s
train Loss: 0.27076830 Acc: 0.91590321
val Loss: 0.28723236 Acc: 0.92982459
Epoch 63 of 120 took 1.659s
train Loss: 0.26619552 Acc: 0.91696548
val Loss: 0.27699506 Acc: 0.94736844
Epoch 64 of 120 took 1.659s
train Loss: 0.26365167 Acc: 0.91700971
val Loss: 0.27524609 Acc: 0.94298244
Epoch 65 of 120 took 1.707s
train Loss: 0.26419826 Acc: 0.91780645
val Loss: 0.26281417 Acc: 0.94298244
Epoch 66 of 120 took 1.666s
train Loss: 0.26585209 Acc: 0.91608024
val Loss: 0.26822038 Acc: 0.93859649
Epoch 67 of 120 took 1.660s
train Loss: 0.26039303 Acc: 0.91833758
val Loss: 0.27915927 Acc: 0.94298244
Epoch 68 of 120 took 1.659s
train Loss: 0.25730349 Acc: 0.9197982
val Loss: 0.27311814 Acc: 0.94298244
Epoch 69 of 120 took 1.703s
train Loss: 0.25692310 Acc: 0.91833758
val Loss: 0.26752571 Acc: 0.93859649
Epoch 70 of 120 took 1.658s
train Loss: 0.25647027 Acc: 0.91873592
val Loss: 0.26060598 Acc: 0.94736844
Epoch 71 of 120 took 1.665s
train Loss: 0.25078647 Acc: 0.92148012
val Loss: 0.25657658 Acc: 0.94298244
Epoch 72 of 120 took 1.665s
train Loss: 0.26064985 Acc: 0.91878021
val Loss: 0.28297933 Acc: 0.92543858
Epoch 73 of 120 took 1.706s
train Loss: 0.25741075 Acc: 0.92015231
val Loss: 0.27053046 Acc: 0.94298244
Epoch 74 of 120 took 1.660s
train Loss: 0.25963925 Acc: 0.92077196
val Loss: 0.27008695 Acc: 0.94298244
Epoch 75 of 120 took 1.660s
train Loss: 0.25562267 Acc: 0.91758513
val Loss: 0.27701122 Acc: 0.93859649
Epoch 76 of 120 took 1.658s
train Loss: 0.25121287 Acc: 0.92232108
val Loss: 0.28683439 Acc: 0.93859649
Epoch 77 of 120 took 1.706s
train Loss: 0.25578405 Acc: 0.9196654
val Loss: 0.25908334 Acc: 0.93421054
Epoch 00078: reducing learning rate of group 0 to 4.0000e-04.
Epoch 78 of 120 took 1.660s
train Loss: 0.24822886 Acc: 0.92134732
val Loss: 0.26052602 Acc: 0.94298244
Epoch 79 of 120 took 1.659s
train Loss: 0.24957165 Acc: 0.92050636
val Loss: 0.26634890 Acc: 0.94298244
Epoch 80 of 120 took 1.659s
train Loss: 0.24511860 Acc: 0.92271948
val Loss: 0.26140165 Acc: 0.94298244
Epoch 81 of 120 took 1.705s
train Loss: 0.24228263 Acc: 0.92236537
val Loss: 0.25649906 Acc: 0.95175439
Epoch 82 of 120 took 1.665s
train Loss: 0.24900297 Acc: 0.92156863
val Loss: 0.26016194 Acc: 0.94298244
Epoch 83 of 120 took 1.660s
train Loss: 0.24953895 Acc: 0.92134732
val Loss: 0.26044725 Acc: 0.95175439
Epoch 84 of 120 took 1.659s
train Loss: 0.24780755 Acc: 0.92046213
val Loss: 0.25660581 Acc: 0.94736844
Epoch 85 of 120 took 1.724s
train Loss: 0.24217822 Acc: 0.92373747
val Loss: 0.25469186 Acc: 0.94736844
Epoch 86 of 120 took 1.665s
train Loss: 0.24566543 Acc: 0.92333913
val Loss: 0.25757976 Acc: 0.95175439
Epoch 87 of 120 took 1.661s
train Loss: 0.24401701 Acc: 0.92364895
val Loss: 0.25696560 Acc: 0.94736844
Epoch 88 of 120 took 1.706s
train Loss: 0.24595761 Acc: 0.92205554
val Loss: 0.25727811 Acc: 0.94298244
Epoch 89 of 120 took 1.660s
train Loss: 0.24592564 Acc: 0.92280799
val Loss: 0.25758506 Acc: 0.94298244
Epoch 90 of 120 took 1.659s
train Loss: 0.24397026 Acc: 0.92294079
val Loss: 0.24646179 Acc: 0.95175439
Epoch 91 of 120 took 1.666s
train Loss: 0.23826521 Acc: 0.92395878
val Loss: 0.25729100 Acc: 0.95175439
Epoch 92 of 120 took 1.707s
train Loss: 0.24196002 Acc: 0.92643744
val Loss: 0.25418669 Acc: 0.94736844
Epoch 93 of 120 took 1.658s
train Loss: 0.24436407 Acc: 0.92183423
val Loss: 0.25305259 Acc: 0.95614034
Epoch 94 of 120 took 1.659s
train Loss: 0.24366207 Acc: 0.92209977
val Loss: 0.25626537 Acc: 0.95175439
Epoch 95 of 120 took 1.661s
train Loss: 0.24013541 Acc: 0.92382598
val Loss: 0.26003630 Acc: 0.94736844
Epoch 96 of 120 took 1.659s
train Loss: 0.24254436 Acc: 0.9242686
val Loss: 0.26508021 Acc: 0.93859649
Epoch 00097: reducing learning rate of group 0 to 8.0000e-05.
Epoch 97 of 120 took 1.706s
train Loss: 0.24133307 Acc: 0.92559648
val Loss: 0.26313691 Acc: 0.94298244
Epoch 98 of 120 took 1.659s
train Loss: 0.23796815 Acc: 0.92572922
val Loss: 0.26371050 Acc: 0.94736844
Epoch 99 of 120 took 1.660s
train Loss: 0.24779507 Acc: 0.92369318
val Loss: 0.26421499 Acc: 0.93859649
Epoch 100 of 120 took 1.659s
train Loss: 0.24006553 Acc: 0.92431289
val Loss: 0.25611609 Acc: 0.95175439
Epoch 101 of 120 took 1.707s
train Loss: 0.24037014 Acc: 0.92524236
val Loss: 0.25557467 Acc: 0.93421054
Epoch 102 of 120 took 1.660s

Training complete in 2m 51s
Best val loss: 0.246462
ACCURACY TEST_0 FINAL : 80.728 %
TOP-3 ACCURACY TEST_0 FINAL : 91.266 %
22801
(22801, 12, 10, 7)
train Loss: 1.96085609 Acc: 0.6002807
val Loss: 1.28319623 Acc: 0.61304343
Epoch 1 of 120 took 1.912s
train Loss: 1.13036365 Acc: 0.67707556
val Loss: 1.05720041 Acc: 0.68260866
Epoch 2 of 120 took 1.674s
train Loss: 0.97111573 Acc: 0.71698612
val Loss: 0.99346557 Acc: 0.71739125
Epoch 3 of 120 took 1.667s
train Loss: 0.89222142 Acc: 0.73746765
val Loss: 0.92943673 Acc: 0.74782604
Epoch 4 of 120 took 1.667s
train Loss: 0.81654762 Acc: 0.75457215
val Loss: 0.85614432 Acc: 0.72608691
Epoch 5 of 120 took 1.669s
train Loss: 0.76478216 Acc: 0.76724708
val Loss: 0.80020449 Acc: 0.74347824
Epoch 6 of 120 took 1.715s
train Loss: 0.72611131 Acc: 0.77693963
val Loss: 0.77376895 Acc: 0.76521736
Epoch 7 of 120 took 1.666s
train Loss: 0.69472906 Acc: 0.78729004
val Loss: 0.74881250 Acc: 0.77391303
Epoch 8 of 120 took 1.667s
train Loss: 0.66050038 Acc: 0.7935617
val Loss: 0.72330322 Acc: 0.76956517
Epoch 9 of 120 took 1.669s
train Loss: 0.64501178 Acc: 0.79777205
val Loss: 0.67948342 Acc: 0.78260869
Epoch 10 of 120 took 1.719s
train Loss: 0.61325337 Acc: 0.80553484
val Loss: 0.64419528 Acc: 0.79565215
Epoch 11 of 120 took 1.672s
train Loss: 0.59692150 Acc: 0.81031537
val Loss: 0.61148004 Acc: 0.79130429
Epoch 12 of 120 took 1.673s
train Loss: 0.58456231 Acc: 0.81632388
val Loss: 0.60339856 Acc: 0.79565215
Epoch 13 of 120 took 1.719s
train Loss: 0.56754979 Acc: 0.81921846
val Loss: 0.59139626 Acc: 0.78695649
Epoch 14 of 120 took 1.673s
train Loss: 0.55939167 Acc: 0.82215697
val Loss: 0.54855284 Acc: 0.80434781
Epoch 15 of 120 took 1.673s
train Loss: 0.54577242 Acc: 0.82584101
val Loss: 0.56366716 Acc: 0.81304342
Epoch 16 of 120 took 1.667s
train Loss: 0.52736340 Acc: 0.83171791
val Loss: 0.48941917 Acc: 0.8434782
Epoch 17 of 120 took 1.671s
train Loss: 0.51161657 Acc: 0.83491951
val Loss: 0.51998194 Acc: 0.81304342
Epoch 18 of 120 took 1.713s
train Loss: 0.50774814 Acc: 0.83816499
val Loss: 0.51442865 Acc: 0.82608694
Epoch 19 of 120 took 1.665s
train Loss: 0.49708645 Acc: 0.83983159
val Loss: 0.48143707 Acc: 0.8347826
Epoch 20 of 120 took 1.671s
train Loss: 0.47968601 Acc: 0.84667343
val Loss: 0.50317056 Acc: 0.81739128
Epoch 21 of 120 took 1.669s
train Loss: 0.47077845 Acc: 0.84548926
val Loss: 0.49075847 Acc: 0.82608694
Epoch 22 of 120 took 1.714s
train Loss: 0.46519647 Acc: 0.84873474
val Loss: 0.49608226 Acc: 0.8434782
Epoch 23 of 120 took 1.666s
train Loss: 0.46291320 Acc: 0.84965575
val Loss: 0.46358682 Acc: 0.86956519
Epoch 24 of 120 took 1.671s
train Loss: 0.45330406 Acc: 0.85369062
val Loss: 0.43172350 Acc: 0.85217386
Epoch 25 of 120 took 1.674s
train Loss: 0.43419062 Acc: 0.85943598
val Loss: 0.42714612 Acc: 0.85217386
Epoch 26 of 120 took 1.674s
train Loss: 0.42571551 Acc: 0.85961145
val Loss: 0.44709120 Acc: 0.8347826
Epoch 27 of 120 took 1.713s
train Loss: 0.42218614 Acc: 0.86136574
val Loss: 0.42012156 Acc: 0.8391304
Epoch 28 of 120 took 1.673s
train Loss: 0.43084349 Acc: 0.86026931
val Loss: 0.42700374 Acc: 0.84782606
Epoch 29 of 120 took 1.666s
train Loss: 0.41355250 Acc: 0.86377794
val Loss: 0.44627953 Acc: 0.85217386
Epoch 30 of 120 took 1.666s
train Loss: 0.41064353 Acc: 0.8664971
val Loss: 0.38737017 Acc: 0.86521733
Epoch 31 of 120 took 1.671s
train Loss: 0.40972083 Acc: 0.86588311
val Loss: 0.43813760 Acc: 0.86956519
Epoch 32 of 120 took 1.713s
train Loss: 0.39047844 Acc: 0.87193543
val Loss: 0.40600812 Acc: 0.87391299
Epoch 33 of 120 took 1.666s
train Loss: 0.39779268 Acc: 0.87013727
val Loss: 0.41667810 Acc: 0.86956519
Epoch 34 of 120 took 1.666s
train Loss: 0.39452105 Acc: 0.87079513
val Loss: 0.39601673 Acc: 0.87826085
Epoch 35 of 120 took 1.666s
train Loss: 0.37982314 Acc: 0.8743915
val Loss: 0.36786573 Acc: 0.85652173
Epoch 36 of 120 took 1.673s
train Loss: 0.39143135 Acc: 0.87140918
val Loss: 0.39077375 Acc: 0.86086953
Epoch 37 of 120 took 1.666s
train Loss: 0.37955446 Acc: 0.8787334
val Loss: 0.38330791 Acc: 0.86086953
Epoch 38 of 120 took 1.712s
train Loss: 0.36364501 Acc: 0.87991756
val Loss: 0.37944863 Acc: 0.88260865
Epoch 39 of 120 took 1.668s
train Loss: 0.36379085 Acc: 0.88215429
val Loss: 0.36749550 Acc: 0.86521733
Epoch 40 of 120 took 1.672s
train Loss: 0.35240769 Acc: 0.88386476
val Loss: 0.35232785 Acc: 0.87826085
Epoch 41 of 120 took 1.675s
train Loss: 0.34108176 Acc: 0.88478577
val Loss: 0.32110151 Acc: 0.89565212
Epoch 42 of 120 took 1.673s
train Loss: 0.34586845 Acc: 0.8870225
val Loss: 0.36985601 Acc: 0.86956519
Epoch 43 of 120 took 1.712s
train Loss: 0.34669114 Acc: 0.88807511
val Loss: 0.34430341 Acc: 0.90434778
Epoch 44 of 120 took 1.666s
train Loss: 0.34279647 Acc: 0.88741726
val Loss: 0.32921973 Acc: 0.89565212
Epoch 45 of 120 took 1.667s
train Loss: 0.33949849 Acc: 0.88890839
val Loss: 0.33034870 Acc: 0.89999998
Epoch 46 of 120 took 1.666s
train Loss: 0.33373435 Acc: 0.89057499
val Loss: 0.35184784 Acc: 0.88260865
Epoch 47 of 120 took 1.712s
train Loss: 0.32611401 Acc: 0.8937766
val Loss: 0.33832676 Acc: 0.88260865
Epoch 00048: reducing learning rate of group 0 to 2.0000e-03.
Epoch 48 of 120 took 1.669s
train Loss: 0.30809718 Acc: 0.89781153
val Loss: 0.31506700 Acc: 0.89130431
Epoch 49 of 120 took 1.718s
train Loss: 0.29237309 Acc: 0.90399545
val Loss: 0.29218760 Acc: 0.89130431
Epoch 50 of 120 took 1.674s
train Loss: 0.28618818 Acc: 0.904127
val Loss: 0.28930288 Acc: 0.89565212
Epoch 51 of 120 took 1.674s
train Loss: 0.28591180 Acc: 0.90276742
val Loss: 0.28737575 Acc: 0.89565212
Epoch 52 of 120 took 1.673s
train Loss: 0.28452744 Acc: 0.904127
val Loss: 0.28092512 Acc: 0.90434778
Epoch 53 of 120 took 1.718s
train Loss: 0.27519176 Acc: 0.90974081
val Loss: 0.28347135 Acc: 0.89565212
Epoch 54 of 120 took 1.668s
train Loss: 0.28250957 Acc: 0.90710938
val Loss: 0.27406744 Acc: 0.91304344
Epoch 55 of 120 took 1.673s
train Loss: 0.28261471 Acc: 0.90759176
val Loss: 0.28081129 Acc: 0.90869564
Epoch 56 of 120 took 1.714s
train Loss: 0.27496422 Acc: 0.90860051
val Loss: 0.28552913 Acc: 0.90869564
Epoch 57 of 120 took 1.668s
train Loss: 0.27813849 Acc: 0.90667075
val Loss: 0.28745251 Acc: 0.89999998
Epoch 58 of 120 took 1.667s
train Loss: 0.27242858 Acc: 0.90860051
val Loss: 0.28125328 Acc: 0.90434778
Epoch 59 of 120 took 1.712s
train Loss: 0.27233688 Acc: 0.91022325
val Loss: 0.28159443 Acc: 0.90434778
Epoch 60 of 120 took 1.667s
train Loss: 0.27129971 Acc: 0.91066182
val Loss: 0.28087888 Acc: 0.90869564
Epoch 00061: reducing learning rate of group 0 to 4.0000e-04.
Epoch 61 of 120 took 1.667s
train Loss: 0.26659879 Acc: 0.91074955
val Loss: 0.27505873 Acc: 0.90869564
Epoch 62 of 120 took 1.662s
train Loss: 0.26971050 Acc: 0.90860051
val Loss: 0.27653367 Acc: 0.90869564
Epoch 63 of 120 took 1.653s
train Loss: 0.26867948 Acc: 0.91180211
val Loss: 0.27222939 Acc: 0.90869564
Epoch 64 of 120 took 1.659s
train Loss: 0.26448991 Acc: 0.91210914
val Loss: 0.27520049 Acc: 0.90869564
Epoch 65 of 120 took 1.698s
train Loss: 0.26543551 Acc: 0.91180211
val Loss: 0.27689463 Acc: 0.90869564
Epoch 66 of 120 took 1.654s
train Loss: 0.26750443 Acc: 0.91053027
val Loss: 0.27543710 Acc: 0.90434778
Epoch 67 of 120 took 1.654s
train Loss: 0.26679507 Acc: 0.91083723
val Loss: 0.27418871 Acc: 0.90869564
Epoch 68 of 120 took 1.653s
train Loss: 0.26415607 Acc: 0.91254771
val Loss: 0.28049799 Acc: 0.90434778
Epoch 69 of 120 took 1.653s
train Loss: 0.26468676 Acc: 0.91245997
val Loss: 0.27872790 Acc: 0.90869564
Epoch 00070: reducing learning rate of group 0 to 8.0000e-05.
Epoch 70 of 120 took 1.652s
train Loss: 0.26387573 Acc: 0.91188985
val Loss: 0.27687861 Acc: 0.90869564
Epoch 71 of 120 took 1.652s
train Loss: 0.26118848 Acc: 0.91386342
val Loss: 0.27838432 Acc: 0.90869564
Epoch 72 of 120 took 1.652s
train Loss: 0.25458389 Acc: 0.91487217
val Loss: 0.27617384 Acc: 0.90434778
Epoch 73 of 120 took 1.696s
train Loss: 0.25613306 Acc: 0.91346872
val Loss: 0.27579200 Acc: 0.90869564
Epoch 74 of 120 took 1.651s
train Loss: 0.26207920 Acc: 0.91259158
val Loss: 0.27584612 Acc: 0.91304344
Epoch 75 of 120 took 1.652s

Training complete in 2m 6s
Best val loss: 0.272229
ACCURACY TEST_0 FINAL : 79.330 %
TOP-3 ACCURACY TEST_0 FINAL : 92.511 %
22552
(22552, 12, 10, 7)
train Loss: 1.46832733 Acc: 0.72104472
val Loss: 0.77871072 Acc: 0.75770921
Epoch 1 of 120 took 1.782s
train Loss: 0.77882768 Acc: 0.77944309
val Loss: 0.59654518 Acc: 0.79735678
Epoch 2 of 120 took 1.658s
train Loss: 0.65961351 Acc: 0.80564922
val Loss: 0.51237797 Acc: 0.81497794
Epoch 3 of 120 took 1.659s
train Loss: 0.59496888 Acc: 0.82422847
val Loss: 0.45618989 Acc: 0.8634361
Epoch 4 of 120 took 1.658s
train Loss: 0.54693098 Acc: 0.83753109
val Loss: 0.48102590 Acc: 0.85462552
Epoch 5 of 120 took 1.697s
train Loss: 0.50921389 Acc: 0.84817314
val Loss: 0.39541508 Acc: 0.85462552
Epoch 6 of 120 took 1.647s
train Loss: 0.48095043 Acc: 0.85464704
val Loss: 0.38708862 Acc: 0.86784136
Epoch 7 of 120 took 1.651s
train Loss: 0.45280549 Acc: 0.86076623
val Loss: 0.34272566 Acc: 0.87665194
Epoch 8 of 120 took 1.649s
train Loss: 0.43490576 Acc: 0.86497873
val Loss: 0.33466126 Acc: 0.88986778
Epoch 9 of 120 took 1.648s
train Loss: 0.41481269 Acc: 0.87464529
val Loss: 0.33032814 Acc: 0.88105726
Epoch 10 of 120 took 1.693s
train Loss: 0.40229931 Acc: 0.8773945
val Loss: 0.29827501 Acc: 0.90308368
Epoch 11 of 120 took 1.649s
train Loss: 0.38891870 Acc: 0.88023239
val Loss: 0.30466185 Acc: 0.89867836
Epoch 12 of 120 took 1.645s
train Loss: 0.38605063 Acc: 0.88036543
val Loss: 0.31500183 Acc: 0.91189426
Epoch 13 of 120 took 1.645s
train Loss: 0.37138540 Acc: 0.88595247
val Loss: 0.30531528 Acc: 0.8942731
Epoch 14 of 120 took 1.689s
train Loss: 0.36017136 Acc: 0.88666195
val Loss: 0.26487274 Acc: 0.90748894
Epoch 15 of 120 took 1.651s
train Loss: 0.35905261 Acc: 0.8875488
val Loss: 0.28143264 Acc: 0.91629952
Epoch 16 of 120 took 1.646s
train Loss: 0.34835985 Acc: 0.89242643
val Loss: 0.25670788 Acc: 0.91629952
Epoch 17 of 120 took 1.652s
train Loss: 0.34318136 Acc: 0.89291418
val Loss: 0.29634321 Acc: 0.90748894
Epoch 18 of 120 took 1.645s
train Loss: 0.33157315 Acc: 0.89765877
val Loss: 0.28284844 Acc: 0.90308368
Epoch 19 of 120 took 1.691s
train Loss: 0.32964505 Acc: 0.89801353
val Loss: 0.27279288 Acc: 0.92070478
Epoch 20 of 120 took 1.645s
train Loss: 0.32478629 Acc: 0.8992551
val Loss: 0.25540836 Acc: 0.92070478
Epoch 21 of 120 took 1.651s
train Loss: 0.31487259 Acc: 0.90129483
val Loss: 0.22996511 Acc: 0.92070478
Epoch 22 of 120 took 1.652s
train Loss: 0.33409901 Acc: 0.89725971
val Loss: 0.23734829 Acc: 0.93392068
Epoch 23 of 120 took 1.691s
train Loss: 0.30702529 Acc: 0.90422136
val Loss: 0.23348831 Acc: 0.92070478
Epoch 24 of 120 took 1.647s
train Loss: 0.30629664 Acc: 0.90479785
val Loss: 0.26297409 Acc: 0.90308368
Epoch 25 of 120 took 1.647s
train Loss: 0.29439438 Acc: 0.90643847
val Loss: 0.24036599 Acc: 0.91629952
Epoch 26 of 120 took 1.647s
train Loss: 0.29255523 Acc: 0.90825653
val Loss: 0.28486327 Acc: 0.91629952
Epoch 27 of 120 took 1.690s
train Loss: 0.29443073 Acc: 0.90754706
val Loss: 0.24475935 Acc: 0.9251101
Epoch 00028: reducing learning rate of group 0 to 2.0000e-03.
Epoch 28 of 120 took 1.646s
train Loss: 0.27789971 Acc: 0.91264635
val Loss: 0.22428020 Acc: 0.92951536
Epoch 29 of 120 took 1.651s
train Loss: 0.26577283 Acc: 0.91623807
val Loss: 0.22170312 Acc: 0.91189426
Epoch 30 of 120 took 1.651s
train Loss: 0.25772678 Acc: 0.91960806
val Loss: 0.22467712 Acc: 0.91629952
Epoch 31 of 120 took 1.691s
train Loss: 0.25871929 Acc: 0.91619372
val Loss: 0.21445535 Acc: 0.92951536
Epoch 32 of 120 took 1.654s
train Loss: 0.25723927 Acc: 0.9182778
val Loss: 0.21210359 Acc: 0.9251101
Epoch 33 of 120 took 1.652s
train Loss: 0.25223914 Acc: 0.92062789
val Loss: 0.21256741 Acc: 0.93832594
Epoch 34 of 120 took 1.647s
train Loss: 0.25306703 Acc: 0.91934198
val Loss: 0.19664166 Acc: 0.93832594
Epoch 35 of 120 took 1.653s
train Loss: 0.24582918 Acc: 0.92271197
val Loss: 0.21492383 Acc: 0.9251101
Epoch 36 of 120 took 1.691s
train Loss: 0.24914357 Acc: 0.92124867
val Loss: 0.20662917 Acc: 0.93392068
Epoch 37 of 120 took 1.644s
train Loss: 0.24702896 Acc: 0.92067224
val Loss: 0.19847892 Acc: 0.93832594
Epoch 38 of 120 took 1.644s
train Loss: 0.24644274 Acc: 0.921027
val Loss: 0.20261631 Acc: 0.93832594
Epoch 39 of 120 took 1.646s
train Loss: 0.24446133 Acc: 0.9224903
val Loss: 0.21401221 Acc: 0.93392068
Epoch 40 of 120 took 1.692s
train Loss: 0.23893592 Acc: 0.92413092
val Loss: 0.19717237 Acc: 0.93392068
Epoch 00041: reducing learning rate of group 0 to 4.0000e-04.
Epoch 41 of 120 took 1.646s
train Loss: 0.24175477 Acc: 0.9233771
val Loss: 0.19304677 Acc: 0.93392068
Epoch 42 of 120 took 1.651s
train Loss: 0.23910762 Acc: 0.92479604
val Loss: 0.19349488 Acc: 0.93392068
Epoch 43 of 120 took 1.647s
train Loss: 0.23594948 Acc: 0.92541683
val Loss: 0.19614876 Acc: 0.93392068
Epoch 44 of 120 took 1.691s
train Loss: 0.24182850 Acc: 0.92457438
val Loss: 0.18980116 Acc: 0.93392068
Epoch 45 of 120 took 1.652s
train Loss: 0.23656653 Acc: 0.92537248
val Loss: 0.20175473 Acc: 0.93392068
Epoch 46 of 120 took 1.647s
train Loss: 0.23677049 Acc: 0.9261263
val Loss: 0.20630953 Acc: 0.93832594
Epoch 47 of 120 took 1.646s
train Loss: 0.23158187 Acc: 0.92701316
val Loss: 0.20425121 Acc: 0.93392068
Epoch 48 of 120 took 1.647s
train Loss: 0.23066088 Acc: 0.92652541
val Loss: 0.19915967 Acc: 0.93832594
Epoch 49 of 120 took 1.692s
train Loss: 0.23684482 Acc: 0.92390925
val Loss: 0.19727826 Acc: 0.93832594
Epoch 50 of 120 took 1.645s
train Loss: 0.23288522 Acc: 0.92652541
val Loss: 0.19872486 Acc: 0.94273126
Epoch 00051: reducing learning rate of group 0 to 8.0000e-05.
Epoch 51 of 120 took 1.644s
train Loss: 0.22611791 Acc: 0.92679143
val Loss: 0.19888830 Acc: 0.94273126
Epoch 52 of 120 took 1.646s
train Loss: 0.23258922 Acc: 0.92364317
val Loss: 0.20206971 Acc: 0.93832594
Epoch 53 of 120 took 1.693s
train Loss: 0.23158740 Acc: 0.92617065
val Loss: 0.20012380 Acc: 0.93832594
Epoch 54 of 120 took 1.644s
train Loss: 0.22684128 Acc: 0.92510647
val Loss: 0.20096622 Acc: 0.93832594
Epoch 55 of 120 took 1.645s
train Loss: 0.23826004 Acc: 0.92382056
val Loss: 0.20032348 Acc: 0.93832594
Epoch 56 of 120 took 1.689s

Training complete in 1m 33s
Best val loss: 0.189801
ACCURACY TEST_0 FINAL : 85.717 %
TOP-3 ACCURACY TEST_0 FINAL : 95.033 %
22864
(22864, 12, 10, 7)
train Loss: 1.36252017 Acc: 0.67468512
val Loss: 0.81693876 Acc: 0.77826083
Epoch 1 of 120 took 1.845s
train Loss: 0.91241641 Acc: 0.73639786
val Loss: 0.67931505 Acc: 0.80869561
Epoch 2 of 120 took 1.619s
train Loss: 0.79318095 Acc: 0.76552659
val Loss: 0.61464718 Acc: 0.82173908
Epoch 3 of 120 took 1.657s
train Loss: 0.71977786 Acc: 0.78918827
val Loss: 0.56559625 Acc: 0.81739128
Epoch 4 of 120 took 1.656s
train Loss: 0.66977702 Acc: 0.80213439
val Loss: 0.49500255 Acc: 0.85217386
Epoch 5 of 120 took 1.701s
train Loss: 0.62797729 Acc: 0.81341851
val Loss: 0.44288781 Acc: 0.87826085
Epoch 6 of 120 took 1.657s
train Loss: 0.58126578 Acc: 0.82645208
val Loss: 0.40429389 Acc: 0.89130431
Epoch 7 of 120 took 1.656s
train Loss: 0.56161252 Acc: 0.83218163
val Loss: 0.40679755 Acc: 0.88260865
Epoch 8 of 120 took 1.650s
train Loss: 0.54370012 Acc: 0.83519948
val Loss: 0.38718233 Acc: 0.88260865
Epoch 9 of 120 took 1.655s
train Loss: 0.52797338 Acc: 0.84280968
val Loss: 0.35877016 Acc: 0.87391299
Epoch 10 of 120 took 1.700s
train Loss: 0.51460023 Acc: 0.84412175
val Loss: 0.37260668 Acc: 0.87391299
Epoch 11 of 120 took 1.651s
train Loss: 0.50049709 Acc: 0.84753329
val Loss: 0.32890267 Acc: 0.89130431
Epoch 12 of 120 took 1.656s
train Loss: 0.48414248 Acc: 0.85256302
val Loss: 0.32400228 Acc: 0.87826085
Epoch 13 of 120 took 1.701s
train Loss: 0.46768632 Acc: 0.85829252
val Loss: 0.33992891 Acc: 0.87391299
Epoch 14 of 120 took 1.650s
train Loss: 0.45794446 Acc: 0.85921103
val Loss: 0.29937800 Acc: 0.88695645
Epoch 15 of 120 took 1.656s
train Loss: 0.44690092 Acc: 0.86166024
val Loss: 0.28981316 Acc: 0.90869564
Epoch 16 of 120 took 1.656s
train Loss: 0.44172674 Acc: 0.86699617
val Loss: 0.31353629 Acc: 0.88260865
Epoch 17 of 120 took 1.695s
train Loss: 0.43416038 Acc: 0.86673373
val Loss: 0.28738153 Acc: 0.90869564
Epoch 18 of 120 took 1.655s
train Loss: 0.42644979 Acc: 0.87189472
val Loss: 0.28150726 Acc: 0.91304344
Epoch 19 of 120 took 1.656s
train Loss: 0.43599977 Acc: 0.86695242
val Loss: 0.27858730 Acc: 0.90869564
Epoch 20 of 120 took 1.658s
train Loss: 0.40564086 Acc: 0.87491256
val Loss: 0.25614641 Acc: 0.91739124
Epoch 21 of 120 took 1.657s
train Loss: 0.39276913 Acc: 0.87723058
val Loss: 0.28402817 Acc: 0.90434778
Epoch 22 of 120 took 1.693s
train Loss: 0.39371223 Acc: 0.88107944
val Loss: 0.25871960 Acc: 0.90869564
Epoch 23 of 120 took 1.649s
train Loss: 0.38880921 Acc: 0.87972361
val Loss: 0.28344771 Acc: 0.91739124
Epoch 24 of 120 took 1.650s
train Loss: 0.38926193 Acc: 0.88059837
val Loss: 0.25106938 Acc: 0.91304344
Epoch 25 of 120 took 1.656s
train Loss: 0.38011010 Acc: 0.88247901
val Loss: 0.24116856 Acc: 0.91739124
Epoch 26 of 120 took 1.656s
train Loss: 0.36527869 Acc: 0.88847101
val Loss: 0.28213673 Acc: 0.91304344
Epoch 27 of 120 took 1.695s
train Loss: 0.36165380 Acc: 0.88886464
val Loss: 0.24740810 Acc: 0.89999998
Epoch 28 of 120 took 1.651s
train Loss: 0.35928299 Acc: 0.88886464
val Loss: 0.22451874 Acc: 0.93913037
Epoch 29 of 120 took 1.657s
train Loss: 0.34539835 Acc: 0.89236355
val Loss: 0.21251814 Acc: 0.94347823
Epoch 30 of 120 took 1.702s
train Loss: 0.34497880 Acc: 0.89319456
val Loss: 0.21424484 Acc: 0.93478256
Epoch 31 of 120 took 1.651s
train Loss: 0.34229892 Acc: 0.89415675
val Loss: 0.22283548 Acc: 0.9217391
Epoch 32 of 120 took 1.649s
train Loss: 0.34257014 Acc: 0.89402556
val Loss: 0.19605736 Acc: 0.93043476
Epoch 33 of 120 took 1.644s
train Loss: 0.33281536 Acc: 0.89682472
val Loss: 0.20102894 Acc: 0.93478256
Epoch 34 of 120 took 1.678s
train Loss: 0.33563118 Acc: 0.89818054
val Loss: 0.19407551 Acc: 0.93043476
Epoch 35 of 120 took 1.638s
train Loss: 0.32408600 Acc: 0.89918649
val Loss: 0.16844088 Acc: 0.94782603
Epoch 36 of 120 took 1.637s
train Loss: 0.32529795 Acc: 0.89944893
val Loss: 0.17138278 Acc: 0.94782603
Epoch 37 of 120 took 1.635s
train Loss: 0.32291757 Acc: 0.89944893
val Loss: 0.18942181 Acc: 0.93913037
Epoch 38 of 120 took 1.676s
train Loss: 0.32724177 Acc: 0.89883661
val Loss: 0.18608220 Acc: 0.9260869
Epoch 39 of 120 took 1.632s
train Loss: 0.32261725 Acc: 0.90027994
val Loss: 0.17726177 Acc: 0.95652169
Epoch 40 of 120 took 1.632s
train Loss: 0.31205683 Acc: 0.90342897
val Loss: 0.19670984 Acc: 0.93043476
Epoch 41 of 120 took 1.631s
train Loss: 0.30693103 Acc: 0.90522218
val Loss: 0.19162823 Acc: 0.94782603
Epoch 00042: reducing learning rate of group 0 to 2.0000e-03.
Epoch 42 of 120 took 1.631s
train Loss: 0.28446190 Acc: 0.91287613
val Loss: 0.14575866 Acc: 0.95652169
Epoch 43 of 120 took 1.638s
train Loss: 0.27586959 Acc: 0.91375089
val Loss: 0.14289666 Acc: 0.95652169
Epoch 44 of 120 took 1.683s
train Loss: 0.27203768 Acc: 0.91484433
val Loss: 0.14839797 Acc: 0.95217389
Epoch 45 of 120 took 1.634s
train Loss: 0.27330669 Acc: 0.9164626
val Loss: 0.14283987 Acc: 0.95652169
Epoch 46 of 120 took 1.640s
train Loss: 0.26974089 Acc: 0.91672498
val Loss: 0.14114409 Acc: 0.95217389
Epoch 47 of 120 took 1.687s
train Loss: 0.26620347 Acc: 0.91707492
val Loss: 0.13263584 Acc: 0.95652169
Epoch 48 of 120 took 1.641s
train Loss: 0.26495161 Acc: 0.91759974
val Loss: 0.13563617 Acc: 0.96086955
Epoch 49 of 120 took 1.634s
train Loss: 0.26183605 Acc: 0.91851819
val Loss: 0.13758290 Acc: 0.95652169
Epoch 50 of 120 took 1.636s
train Loss: 0.26086336 Acc: 0.91895556
val Loss: 0.14453572 Acc: 0.96086955
Epoch 51 of 120 took 1.635s
train Loss: 0.25780053 Acc: 0.91873688
val Loss: 0.13058462 Acc: 0.96086955
Epoch 52 of 120 took 1.640s
train Loss: 0.26033746 Acc: 0.9174248
val Loss: 0.13459290 Acc: 0.96086955
Epoch 53 of 120 took 1.681s
train Loss: 0.25917836 Acc: 0.91860569
val Loss: 0.13471880 Acc: 0.96086955
Epoch 54 of 120 took 1.636s
train Loss: 0.25695106 Acc: 0.92048639
val Loss: 0.13714410 Acc: 0.95217389
Epoch 55 of 120 took 1.635s
train Loss: 0.25558029 Acc: 0.91956788
val Loss: 0.14005689 Acc: 0.95217389
Epoch 56 of 120 took 1.639s
train Loss: 0.25254997 Acc: 0.9221921
val Loss: 0.13441903 Acc: 0.95652169
Epoch 57 of 120 took 1.638s
train Loss: 0.25288376 Acc: 0.91987407
val Loss: 0.12630358 Acc: 0.96086955
Epoch 58 of 120 took 1.645s
train Loss: 0.26127916 Acc: 0.91917425
val Loss: 0.13287838 Acc: 0.96086955
Epoch 59 of 120 took 1.685s
train Loss: 0.25657234 Acc: 0.92022395
val Loss: 0.13361090 Acc: 0.95652169
Epoch 60 of 120 took 1.639s
train Loss: 0.25459390 Acc: 0.92022395
val Loss: 0.13533841 Acc: 0.96086955
Epoch 61 of 120 took 1.638s
train Loss: 0.24536714 Acc: 0.92149234
val Loss: 0.13517367 Acc: 0.96086955
Epoch 62 of 120 took 1.640s
train Loss: 0.25215485 Acc: 0.92101121
val Loss: 0.13049062 Acc: 0.95652169
Epoch 63 of 120 took 1.638s
train Loss: 0.25237508 Acc: 0.92188597
val Loss: 0.13643877 Acc: 0.95652169
Epoch 00064: reducing learning rate of group 0 to 4.0000e-04.
Epoch 64 of 120 took 1.638s
train Loss: 0.24300480 Acc: 0.92346048
val Loss: 0.12990501 Acc: 0.96521735
Epoch 65 of 120 took 1.638s
train Loss: 0.24681605 Acc: 0.92105496
val Loss: 0.13337616 Acc: 0.95652169
Epoch 66 of 120 took 1.638s
train Loss: 0.24425973 Acc: 0.92319804
val Loss: 0.12642722 Acc: 0.95652169
Epoch 67 of 120 took 1.683s
train Loss: 0.24611107 Acc: 0.92262948
val Loss: 0.12643365 Acc: 0.95652169
Epoch 68 of 120 took 1.639s
train Loss: 0.24223403 Acc: 0.92433524
val Loss: 0.12551432 Acc: 0.95652169
Epoch 69 of 120 took 1.646s
train Loss: 0.24587448 Acc: 0.9230231
val Loss: 0.13067733 Acc: 0.96086955
Epoch 70 of 120 took 1.640s
train Loss: 0.23815769 Acc: 0.92451018
val Loss: 0.12322657 Acc: 0.96086955
Epoch 71 of 120 took 1.645s
train Loss: 0.24413728 Acc: 0.92324179
val Loss: 0.12845542 Acc: 0.95652169
Epoch 72 of 120 took 1.683s
train Loss: 0.24207592 Acc: 0.92520994
val Loss: 0.12657258 Acc: 0.96086955
Epoch 73 of 120 took 1.638s
train Loss: 0.24462609 Acc: 0.92280442
val Loss: 0.12745872 Acc: 0.96086955
Epoch 74 of 120 took 1.638s
train Loss: 0.23974232 Acc: 0.92520994
val Loss: 0.13099978 Acc: 0.96086955
Epoch 75 of 120 took 1.639s
train Loss: 0.23941753 Acc: 0.92411655
val Loss: 0.12684297 Acc: 0.96086955
Epoch 76 of 120 took 1.638s
train Loss: 0.24732315 Acc: 0.92315429
val Loss: 0.12672660 Acc: 0.95652169
Epoch 00077: reducing learning rate of group 0 to 8.0000e-05.
Epoch 77 of 120 took 1.639s
train Loss: 0.23740037 Acc: 0.92560357
val Loss: 0.12388774 Acc: 0.95652169
Epoch 78 of 120 took 1.639s
train Loss: 0.23769621 Acc: 0.92573482
val Loss: 0.12466173 Acc: 0.96086955
Epoch 79 of 120 took 1.638s
train Loss: 0.23966114 Acc: 0.9240728
val Loss: 0.12754295 Acc: 0.95652169
Epoch 80 of 120 took 1.683s
train Loss: 0.23492493 Acc: 0.92555988
val Loss: 0.13033874 Acc: 0.95652169
Epoch 81 of 120 took 1.639s
train Loss: 0.23830743 Acc: 0.92569107
val Loss: 0.12557614 Acc: 0.96086955
Epoch 82 of 120 took 1.639s

Training complete in 2m 16s
Best val loss: 0.123227
ACCURACY TEST_0 FINAL : 85.499 %
TOP-3 ACCURACY TEST_0 FINAL : 94.470 %
22770
(22770, 12, 10, 7)
train Loss: 1.81414680 Acc: 0.64330262
val Loss: 1.34681436 Acc: 0.63043475
Epoch 1 of 120 took 1.857s
train Loss: 1.13829407 Acc: 0.68761528
val Loss: 1.04484295 Acc: 0.70434779
Epoch 2 of 120 took 1.605s
train Loss: 0.98964676 Acc: 0.72630656
val Loss: 0.91394646 Acc: 0.7565217
Epoch 3 of 120 took 1.641s
train Loss: 0.88305565 Acc: 0.75261313
val Loss: 0.83455512 Acc: 0.78260869
Epoch 4 of 120 took 1.643s
train Loss: 0.81724476 Acc: 0.76921391
val Loss: 0.79861876 Acc: 0.79130429
Epoch 5 of 120 took 1.645s
train Loss: 0.76887435 Acc: 0.78230131
val Loss: 0.76939208 Acc: 0.79999995
Epoch 6 of 120 took 1.644s
train Loss: 0.72667345 Acc: 0.79117262
val Loss: 0.72159345 Acc: 0.79999995
Epoch 7 of 120 took 1.643s
train Loss: 0.70014590 Acc: 0.79762846
val Loss: 0.73860061 Acc: 0.79999995
Epoch 8 of 120 took 1.637s
train Loss: 0.66413821 Acc: 0.80491877
val Loss: 0.72694928 Acc: 0.80869561
Epoch 9 of 120 took 1.684s
train Loss: 0.63614816 Acc: 0.81018889
val Loss: 0.68315366 Acc: 0.80869561
Epoch 10 of 120 took 1.642s
train Loss: 0.62546428 Acc: 0.81589812
val Loss: 0.65931730 Acc: 0.80434781
Epoch 11 of 120 took 1.643s
train Loss: 0.61963940 Acc: 0.82028985
val Loss: 0.63513611 Acc: 0.82173908
Epoch 12 of 120 took 1.645s
train Loss: 0.58381729 Acc: 0.82714099
val Loss: 0.61293522 Acc: 0.83043474
Epoch 13 of 120 took 1.644s
train Loss: 0.57621235 Acc: 0.83126926
val Loss: 0.64241391 Acc: 0.81304342
Epoch 14 of 120 took 1.637s
train Loss: 0.55736690 Acc: 0.83570492
val Loss: 0.56419764 Acc: 0.84782606
Epoch 15 of 120 took 1.688s
train Loss: 0.54985155 Acc: 0.83636367
val Loss: 0.60090611 Acc: 0.84782606
Epoch 16 of 120 took 1.639s
train Loss: 0.53501553 Acc: 0.84268779
val Loss: 0.58211020 Acc: 0.82608694
Epoch 17 of 120 took 1.637s
train Loss: 0.53222874 Acc: 0.84334654
val Loss: 0.57450373 Acc: 0.85652173
Epoch 18 of 120 took 1.637s
train Loss: 0.51713397 Acc: 0.84940714
val Loss: 0.51446749 Acc: 0.85652173
Epoch 19 of 120 took 1.688s
train Loss: 0.52333622 Acc: 0.84787005
val Loss: 0.57715906 Acc: 0.84782606
Epoch 20 of 120 took 1.637s
train Loss: 0.51109735 Acc: 0.84918755
val Loss: 0.55225473 Acc: 0.85652173
Epoch 21 of 120 took 1.637s
train Loss: 0.50057875 Acc: 0.85305226
val Loss: 0.61501790 Acc: 0.85217386
Epoch 22 of 120 took 1.637s
train Loss: 0.48214729 Acc: 0.85814673
val Loss: 0.52748618 Acc: 0.86521733
Epoch 23 of 120 took 1.638s
train Loss: 0.46883364 Acc: 0.86306548
val Loss: 0.54009035 Acc: 0.86521733
Epoch 24 of 120 took 1.683s
train Loss: 0.46683533 Acc: 0.86183578
val Loss: 0.53381584 Acc: 0.86086953
Epoch 00025: reducing learning rate of group 0 to 2.0000e-03.
Epoch 25 of 120 took 1.630s
train Loss: 0.43919934 Acc: 0.87158543
val Loss: 0.48459395 Acc: 0.87826085
Epoch 26 of 120 took 1.630s
train Loss: 0.42230077 Acc: 0.87321037
val Loss: 0.49096159 Acc: 0.87391299
Epoch 27 of 120 took 1.624s
train Loss: 0.42742958 Acc: 0.87299079
val Loss: 0.49327520 Acc: 0.88260865
Epoch 28 of 120 took 1.669s
train Loss: 0.40919727 Acc: 0.8762846
val Loss: 0.51166369 Acc: 0.87826085
Epoch 29 of 120 took 1.627s
train Loss: 0.41707750 Acc: 0.87540627
val Loss: 0.47917256 Acc: 0.88260865
Epoch 30 of 120 took 1.631s
train Loss: 0.41353389 Acc: 0.87676769
val Loss: 0.48937703 Acc: 0.87826085
Epoch 31 of 120 took 1.672s
train Loss: 0.40831090 Acc: 0.87861222
val Loss: 0.49995232 Acc: 0.87826085
Epoch 32 of 120 took 1.627s
train Loss: 0.40740016 Acc: 0.8793149
val Loss: 0.47258176 Acc: 0.87826085
Epoch 33 of 120 took 1.634s
train Loss: 0.40979934 Acc: 0.87839264
val Loss: 0.47957760 Acc: 0.88260865
Epoch 34 of 120 took 1.674s
train Loss: 0.40376621 Acc: 0.88014936
val Loss: 0.48598349 Acc: 0.87391299
Epoch 35 of 120 took 1.626s
train Loss: 0.40436106 Acc: 0.87940276
val Loss: 0.49294729 Acc: 0.88260865
Epoch 36 of 120 took 1.628s
train Loss: 0.39912574 Acc: 0.88142294
val Loss: 0.49624482 Acc: 0.87826085
Epoch 37 of 120 took 1.625s
train Loss: 0.40138660 Acc: 0.88093984
val Loss: 0.50394198 Acc: 0.87826085
Epoch 38 of 120 took 1.670s
train Loss: 0.40043546 Acc: 0.88313574
val Loss: 0.49092616 Acc: 0.86956519
Epoch 00039: reducing learning rate of group 0 to 4.0000e-04.
Epoch 39 of 120 took 1.626s
train Loss: 0.39360442 Acc: 0.88379449
val Loss: 0.48503762 Acc: 0.87391299
Epoch 40 of 120 took 1.628s
train Loss: 0.39274667 Acc: 0.88458502
val Loss: 0.49227211 Acc: 0.87391299
Epoch 41 of 120 took 1.630s
train Loss: 0.38756433 Acc: 0.88432151
val Loss: 0.47446721 Acc: 0.87391299
Epoch 42 of 120 took 1.630s
train Loss: 0.39292774 Acc: 0.88375056
val Loss: 0.48593473 Acc: 0.87826085
Epoch 43 of 120 took 1.682s
train Loss: 0.38674152 Acc: 0.88199389
val Loss: 0.48703261 Acc: 0.87826085
Epoch 44 of 120 took 1.637s

Training complete in 1m 13s
Best val loss: 0.472582
ACCURACY TEST_0 FINAL : 78.592 %
TOP-3 ACCURACY TEST_0 FINAL : 90.178 %
22681
(22681, 12, 10, 7)
train Loss: 1.61937007 Acc: 0.60402983
val Loss: 1.31671449 Acc: 0.58078605
Epoch 1 of 120 took 1.805s
train Loss: 1.22282258 Acc: 0.65557075
val Loss: 1.09718882 Acc: 0.67248911
Epoch 2 of 120 took 1.652s
train Loss: 1.03791422 Acc: 0.71090341
val Loss: 0.95193908 Acc: 0.72489083
Epoch 3 of 120 took 1.627s
train Loss: 0.93916320 Acc: 0.73334509
val Loss: 0.91471462 Acc: 0.72925764
Epoch 4 of 120 took 1.626s
train Loss: 0.87306932 Acc: 0.75076056
val Loss: 0.84285234 Acc: 0.74235809
Epoch 5 of 120 took 1.626s
train Loss: 0.82467051 Acc: 0.76288527
val Loss: 0.80943866 Acc: 0.7467249
Epoch 6 of 120 took 1.630s
train Loss: 0.80843331 Acc: 0.76553065
val Loss: 0.81141055 Acc: 0.75109172
Epoch 7 of 120 took 1.622s
train Loss: 0.75967160 Acc: 0.77906621
val Loss: 0.77799155 Acc: 0.74235809
Epoch 8 of 120 took 1.629s
train Loss: 0.73648556 Acc: 0.78788412
val Loss: 0.72320617 Acc: 0.75545853
Epoch 9 of 120 took 1.674s
train Loss: 0.71065233 Acc: 0.79171997
val Loss: 0.71120516 Acc: 0.77292579
Epoch 10 of 120 took 1.629s
train Loss: 0.69890270 Acc: 0.79824525
val Loss: 0.69690959 Acc: 0.78602624
Epoch 11 of 120 took 1.630s
train Loss: 0.68000866 Acc: 0.80040562
val Loss: 0.66241601 Acc: 0.78602624
Epoch 12 of 120 took 1.673s
train Loss: 0.65890210 Acc: 0.8078568
val Loss: 0.66428007 Acc: 0.78165942
Epoch 13 of 120 took 1.623s
train Loss: 0.65676119 Acc: 0.8078568
val Loss: 0.62580379 Acc: 0.80349344
Epoch 14 of 120 took 1.629s
train Loss: 0.63917668 Acc: 0.81305939
val Loss: 0.65476184 Acc: 0.78602624
Epoch 15 of 120 took 1.628s
train Loss: 0.62242252 Acc: 0.81539613
val Loss: 0.65181462 Acc: 0.77292579
Epoch 16 of 120 took 1.674s
train Loss: 0.60711390 Acc: 0.82236236
val Loss: 0.60570617 Acc: 0.80349344
Epoch 17 of 120 took 1.635s
train Loss: 0.59788928 Acc: 0.82359684
val Loss: 0.61608466 Acc: 0.80349344
Epoch 18 of 120 took 1.631s
train Loss: 0.58987306 Acc: 0.82685947
val Loss: 0.61739478 Acc: 0.79039305
Epoch 19 of 120 took 1.631s
train Loss: 0.59400419 Acc: 0.82055467
val Loss: 0.61139336 Acc: 0.80786026
Epoch 20 of 120 took 1.673s
train Loss: 0.56647409 Acc: 0.83179754
val Loss: 0.55679477 Acc: 0.82969433
Epoch 21 of 120 took 1.635s
train Loss: 0.56141195 Acc: 0.83439887
val Loss: 0.56783944 Acc: 0.82532752
Epoch 22 of 120 took 1.629s
train Loss: 0.55805662 Acc: 0.8347075
val Loss: 0.55837114 Acc: 0.82532752
Epoch 23 of 120 took 1.629s
train Loss: 0.54792171 Acc: 0.83722061
val Loss: 0.56757032 Acc: 0.8209607
Epoch 24 of 120 took 1.675s
train Loss: 0.54356221 Acc: 0.83827877
val Loss: 0.51970396 Acc: 0.83406115
Epoch 25 of 120 took 1.633s
train Loss: 0.53165256 Acc: 0.84145319
val Loss: 0.57344532 Acc: 0.81659389
Epoch 26 of 120 took 1.629s
train Loss: 0.52887889 Acc: 0.84361362
val Loss: 0.58357481 Acc: 0.81659389
Epoch 27 of 120 took 1.629s
train Loss: 0.52923655 Acc: 0.8448481
val Loss: 0.53952407 Acc: 0.82969433
Epoch 28 of 120 took 1.674s
train Loss: 0.51374902 Acc: 0.84934527
val Loss: 0.52492041 Acc: 0.82969433
Epoch 29 of 120 took 1.629s
train Loss: 0.50211967 Acc: 0.85035932
val Loss: 0.52207378 Acc: 0.82969433
Epoch 30 of 120 took 1.629s
train Loss: 0.50047844 Acc: 0.84987438
val Loss: 0.50946965 Acc: 0.84279478
Epoch 31 of 120 took 1.633s
train Loss: 0.49925259 Acc: 0.85199064
val Loss: 0.51190971 Acc: 0.82532752
Epoch 32 of 120 took 1.628s
train Loss: 0.49478138 Acc: 0.85274017
val Loss: 0.52543747 Acc: 0.83842796
Epoch 33 of 120 took 1.675s
train Loss: 0.48530694 Acc: 0.85357791
val Loss: 0.58254171 Acc: 0.80786026
Epoch 34 of 120 took 1.628s
train Loss: 0.48728409 Acc: 0.85525334
val Loss: 0.49892223 Acc: 0.83842796
Epoch 35 of 120 took 1.635s
train Loss: 0.48474278 Acc: 0.85547376
val Loss: 0.44906616 Acc: 0.84279478
Epoch 36 of 120 took 1.645s
train Loss: 0.49765235 Acc: 0.85097659
val Loss: 0.47333470 Acc: 0.84279478
Epoch 37 of 120 took 1.686s
train Loss: 0.48304526 Acc: 0.85675234
val Loss: 0.48553876 Acc: 0.84279478
Epoch 38 of 120 took 1.640s
train Loss: 0.47216347 Acc: 0.85975045
val Loss: 0.47494940 Acc: 0.83842796
Epoch 39 of 120 took 1.639s
train Loss: 0.46986369 Acc: 0.85997093
val Loss: 0.55491888 Acc: 0.82532752
Epoch 40 of 120 took 1.639s
train Loss: 0.46236360 Acc: 0.86230767
val Loss: 0.44103193 Acc: 0.83842796
Epoch 41 of 120 took 1.689s
train Loss: 0.46044132 Acc: 0.86266041
val Loss: 0.47597534 Acc: 0.86462885
Epoch 42 of 120 took 1.640s
train Loss: 0.45825053 Acc: 0.86239582
val Loss: 0.45556357 Acc: 0.86462885
Epoch 43 of 120 took 1.639s
train Loss: 0.44332984 Acc: 0.86724573
val Loss: 0.43326755 Acc: 0.85152841
Epoch 44 of 120 took 1.642s
train Loss: 0.44532281 Acc: 0.8674221
val Loss: 0.50792317 Acc: 0.83406115
Epoch 45 of 120 took 1.639s
train Loss: 0.46047953 Acc: 0.86367446
val Loss: 0.45398199 Acc: 0.84279478
Epoch 46 of 120 took 1.674s
train Loss: 0.44631061 Acc: 0.86671662
val Loss: 0.47619759 Acc: 0.86026204
Epoch 47 of 120 took 1.620s
train Loss: 0.44228997 Acc: 0.86711347
val Loss: 0.42900633 Acc: 0.86899567
Epoch 48 of 120 took 1.627s
train Loss: 0.43351383 Acc: 0.86896521
val Loss: 0.47096660 Acc: 0.85152841
Epoch 49 of 120 took 1.621s
train Loss: 0.44113842 Acc: 0.86759847
val Loss: 0.44479578 Acc: 0.85152841
Epoch 50 of 120 took 1.667s
train Loss: 0.43982231 Acc: 0.86654031
val Loss: 0.57803600 Acc: 0.82969433
Epoch 51 of 120 took 1.621s
train Loss: 0.42758939 Acc: 0.87156653
val Loss: 0.48039442 Acc: 0.85152841
Epoch 52 of 120 took 1.626s
train Loss: 0.41768273 Acc: 0.87319785
val Loss: 0.49014123 Acc: 0.85589522
Epoch 53 of 120 took 1.622s
train Loss: 0.41749911 Acc: 0.87469691
val Loss: 0.49119068 Acc: 0.84279478
Epoch 00054: reducing learning rate of group 0 to 2.0000e-03.
Epoch 54 of 120 took 1.668s
train Loss: 0.39101925 Acc: 0.88175124
val Loss: 0.44342842 Acc: 0.86899567
Epoch 55 of 120 took 1.623s
train Loss: 0.38323560 Acc: 0.8828094
val Loss: 0.43575093 Acc: 0.86899567
Epoch 56 of 120 took 1.623s
train Loss: 0.37932596 Acc: 0.88426435
val Loss: 0.43713082 Acc: 0.8777293
Epoch 57 of 120 took 1.624s
train Loss: 0.37262628 Acc: 0.88532251
val Loss: 0.42791017 Acc: 0.87336248
Epoch 58 of 120 took 1.629s
train Loss: 0.37624790 Acc: 0.88554299
val Loss: 0.43850732 Acc: 0.86462885
Epoch 59 of 120 took 1.668s
train Loss: 0.37699452 Acc: 0.88563114
val Loss: 0.41861917 Acc: 0.87336248
Epoch 60 of 120 took 1.629s
train Loss: 0.36630652 Acc: 0.88796794
val Loss: 0.40240280 Acc: 0.88209611
Epoch 61 of 120 took 1.632s
train Loss: 0.36867339 Acc: 0.88743883
val Loss: 0.39513986 Acc: 0.87336248
Epoch 62 of 120 took 1.675s
train Loss: 0.36732422 Acc: 0.88880563
val Loss: 0.41972847 Acc: 0.87336248
Epoch 63 of 120 took 1.623s
train Loss: 0.36537547 Acc: 0.88942289
val Loss: 0.40170464 Acc: 0.87336248
Epoch 64 of 120 took 1.625s
train Loss: 0.36372755 Acc: 0.8876152
val Loss: 0.43533812 Acc: 0.86899567
Epoch 65 of 120 took 1.625s
train Loss: 0.36293030 Acc: 0.88810021
val Loss: 0.41690066 Acc: 0.86462885
Epoch 66 of 120 took 1.623s
train Loss: 0.36085823 Acc: 0.88990784
val Loss: 0.40304475 Acc: 0.8777293
Epoch 67 of 120 took 1.673s
train Loss: 0.36142305 Acc: 0.88845289
val Loss: 0.40586696 Acc: 0.86899567
Epoch 00068: reducing learning rate of group 0 to 4.0000e-04.
Epoch 68 of 120 took 1.628s
train Loss: 0.35467411 Acc: 0.89211237
val Loss: 0.38955694 Acc: 0.87336248
Epoch 69 of 120 took 1.633s
train Loss: 0.35938227 Acc: 0.88964331
val Loss: 0.40725363 Acc: 0.8777293
Epoch 70 of 120 took 1.628s
train Loss: 0.35399544 Acc: 0.89153922
val Loss: 0.41338714 Acc: 0.8777293
Epoch 71 of 120 took 1.673s
train Loss: 0.35839794 Acc: 0.89043695
val Loss: 0.40538254 Acc: 0.8777293
Epoch 72 of 120 took 1.630s
train Loss: 0.35967391 Acc: 0.89030468
val Loss: 0.40941782 Acc: 0.88209611
Epoch 73 of 120 took 1.629s
train Loss: 0.35559301 Acc: 0.89030468
val Loss: 0.40892709 Acc: 0.8777293
Epoch 74 of 120 took 1.628s
train Loss: 0.35264376 Acc: 0.89180374
val Loss: 0.39235237 Acc: 0.88209611
Epoch 00075: reducing learning rate of group 0 to 8.0000e-05.
Epoch 75 of 120 took 1.673s
train Loss: 0.35289610 Acc: 0.89220053
val Loss: 0.39130652 Acc: 0.8777293
Epoch 76 of 120 took 1.628s
train Loss: 0.35343580 Acc: 0.88981968
val Loss: 0.39434726 Acc: 0.88209611
Epoch 77 of 120 took 1.629s
train Loss: 0.35456550 Acc: 0.89008421
val Loss: 0.39731149 Acc: 0.88209611
Epoch 78 of 120 took 1.629s
train Loss: 0.35409937 Acc: 0.88955516
val Loss: 0.39186877 Acc: 0.8777293
Epoch 79 of 120 took 1.673s
train Loss: 0.35024715 Acc: 0.88937879
val Loss: 0.39893347 Acc: 0.88209611
Epoch 80 of 120 took 1.629s

Training complete in 2m 11s
Best val loss: 0.389557
ACCURACY TEST_0 FINAL : 79.402 %
TOP-3 ACCURACY TEST_0 FINAL : 89.033 %
22830
(22830, 12, 10, 7)
train Loss: 2.06425202 Acc: 0.60354793
val Loss: 1.28631897 Acc: 0.60869563
Epoch 1 of 120 took 1.772s
train Loss: 1.20412798 Acc: 0.64134908
val Loss: 1.09292543 Acc: 0.673913
Epoch 2 of 120 took 1.599s
train Loss: 1.06375255 Acc: 0.67971969
val Loss: 0.94661208 Acc: 0.70434779
Epoch 3 of 120 took 1.679s
train Loss: 0.93798118 Acc: 0.71664476
val Loss: 0.77492556 Acc: 0.7521739
Epoch 4 of 120 took 1.645s
train Loss: 0.83807826 Acc: 0.74656153
val Loss: 0.71354383 Acc: 0.76956517
Epoch 5 of 120 took 1.647s
train Loss: 0.76285293 Acc: 0.76916337
val Loss: 0.64225729 Acc: 0.82173908
Epoch 6 of 120 took 1.647s
train Loss: 0.71467968 Acc: 0.78366184
val Loss: 0.55455959 Acc: 0.81304342
Epoch 7 of 120 took 1.691s
train Loss: 0.66175465 Acc: 0.79842311
val Loss: 0.51794477 Acc: 0.83043474
Epoch 8 of 120 took 1.648s
train Loss: 0.62226711 Acc: 0.809286
val Loss: 0.46077821 Acc: 0.86521733
Epoch 9 of 120 took 1.646s
train Loss: 0.59090857 Acc: 0.81914145
val Loss: 0.43650618 Acc: 0.85652173
Epoch 10 of 120 took 1.645s
train Loss: 0.56786595 Acc: 0.82444149
val Loss: 0.40089845 Acc: 0.86086953
Epoch 11 of 120 took 1.690s
train Loss: 0.53830511 Acc: 0.83188784
val Loss: 0.37606225 Acc: 0.87391299
Epoch 12 of 120 took 1.646s
train Loss: 0.52655061 Acc: 0.84016645
val Loss: 0.38235949 Acc: 0.86956519
Epoch 13 of 120 took 1.641s
train Loss: 0.50787194 Acc: 0.84231275
val Loss: 0.35621482 Acc: 0.87826085
Epoch 14 of 120 took 1.646s
train Loss: 0.49067247 Acc: 0.84905827
val Loss: 0.36200361 Acc: 0.89565212
Epoch 15 of 120 took 1.686s
train Loss: 0.46485898 Acc: 0.85632938
val Loss: 0.36261895 Acc: 0.88695645
Epoch 16 of 120 took 1.641s
train Loss: 0.45833311 Acc: 0.85716164
val Loss: 0.36095538 Acc: 0.86956519
Epoch 17 of 120 took 1.641s
train Loss: 0.44935987 Acc: 0.85992116
val Loss: 0.30543962 Acc: 0.90434778
Epoch 18 of 120 took 1.644s
train Loss: 0.43459372 Acc: 0.8636443
val Loss: 0.29127771 Acc: 0.90434778
Epoch 19 of 120 took 1.690s
train Loss: 0.42052695 Acc: 0.86671048
val Loss: 0.27879228 Acc: 0.91739124
Epoch 20 of 120 took 1.644s
train Loss: 0.41251308 Acc: 0.87126589
val Loss: 0.27706010 Acc: 0.91739124
Epoch 21 of 120 took 1.647s
train Loss: 0.39889835 Acc: 0.87437582
val Loss: 0.29525396 Acc: 0.90434778
Epoch 22 of 120 took 1.639s
train Loss: 0.39572287 Acc: 0.87301797
val Loss: 0.26706314 Acc: 0.91304344
Epoch 23 of 120 took 1.691s
train Loss: 0.38049953 Acc: 0.88024527
val Loss: 0.23977961 Acc: 0.93478256
Epoch 24 of 120 took 1.645s
train Loss: 0.37425811 Acc: 0.88212878
val Loss: 0.27766316 Acc: 0.89999998
Epoch 25 of 120 took 1.641s
train Loss: 0.36249741 Acc: 0.8879106
val Loss: 0.27534269 Acc: 0.91304344
Epoch 26 of 120 took 1.640s
train Loss: 0.36152880 Acc: 0.88664037
val Loss: 0.24604818 Acc: 0.93478256
Epoch 27 of 120 took 1.640s
train Loss: 0.36183021 Acc: 0.88681561
val Loss: 0.24457621 Acc: 0.9260869
Epoch 28 of 120 took 1.634s
train Loss: 0.35214364 Acc: 0.89053875
val Loss: 0.26452155 Acc: 0.91304344
Epoch 29 of 120 took 1.623s
train Loss: 0.34659900 Acc: 0.89194041
val Loss: 0.25988436 Acc: 0.9217391
Epoch 00030: reducing learning rate of group 0 to 2.0000e-03.
Epoch 30 of 120 took 1.670s
train Loss: 0.32002011 Acc: 0.90056944
val Loss: 0.23773264 Acc: 0.9260869
Epoch 31 of 120 took 1.630s
train Loss: 0.31333085 Acc: 0.90008759
val Loss: 0.22938553 Acc: 0.9260869
Epoch 32 of 120 took 1.630s
train Loss: 0.31043958 Acc: 0.90179586
val Loss: 0.23501959 Acc: 0.93913037
Epoch 33 of 120 took 1.625s
train Loss: 0.30534151 Acc: 0.90499341
val Loss: 0.22862847 Acc: 0.93478256
Epoch 34 of 120 took 1.677s
train Loss: 0.30329224 Acc: 0.90530002
val Loss: 0.23044414 Acc: 0.93043476
Epoch 35 of 120 took 1.627s
train Loss: 0.30465694 Acc: 0.9052124
val Loss: 0.22201627 Acc: 0.93913037
Epoch 36 of 120 took 1.630s
train Loss: 0.29142389 Acc: 0.90876037
val Loss: 0.22916034 Acc: 0.93478256
Epoch 37 of 120 took 1.672s
train Loss: 0.29771255 Acc: 0.90591323
val Loss: 0.21747206 Acc: 0.93913037
Epoch 38 of 120 took 1.634s
train Loss: 0.29348139 Acc: 0.90744632
val Loss: 0.21778496 Acc: 0.94347823
Epoch 39 of 120 took 1.627s
train Loss: 0.29257597 Acc: 0.90617609
val Loss: 0.20958686 Acc: 0.95217389
Epoch 40 of 120 took 1.677s
train Loss: 0.29052631 Acc: 0.90902323
val Loss: 0.22248642 Acc: 0.9260869
Epoch 41 of 120 took 1.626s
train Loss: 0.28705552 Acc: 0.90968025
val Loss: 0.21726016 Acc: 0.93478256
Epoch 42 of 120 took 1.628s
train Loss: 0.29085066 Acc: 0.90718353
val Loss: 0.23435081 Acc: 0.93478256
Epoch 43 of 120 took 1.631s
train Loss: 0.28867844 Acc: 0.9110381
val Loss: 0.21952526 Acc: 0.93478256
Epoch 44 of 120 took 1.683s
train Loss: 0.28568976 Acc: 0.91081911
val Loss: 0.20466217 Acc: 0.94782603
Epoch 45 of 120 took 1.651s
train Loss: 0.28738043 Acc: 0.90950501
val Loss: 0.21094616 Acc: 0.93478256
Epoch 46 of 120 took 1.642s
train Loss: 0.28558027 Acc: 0.9116075
val Loss: 0.21551450 Acc: 0.94782603
Epoch 47 of 120 took 1.642s
train Loss: 0.28417186 Acc: 0.91173893
val Loss: 0.21002916 Acc: 0.94782603
Epoch 48 of 120 took 1.686s
train Loss: 0.28324589 Acc: 0.91195792
val Loss: 0.21477492 Acc: 0.94782603
Epoch 49 of 120 took 1.641s
train Loss: 0.28061498 Acc: 0.91081911
val Loss: 0.21487656 Acc: 0.93913037
Epoch 50 of 120 took 1.639s
train Loss: 0.28023504 Acc: 0.91060007
val Loss: 0.22277648 Acc: 0.94347823
Epoch 00051: reducing learning rate of group 0 to 4.0000e-04.
Epoch 51 of 120 took 1.684s
train Loss: 0.27316262 Acc: 0.91476125
val Loss: 0.20436249 Acc: 0.94782603
Epoch 52 of 120 took 1.645s
train Loss: 0.26979321 Acc: 0.91462988
val Loss: 0.21138222 Acc: 0.94782603
Epoch 53 of 120 took 1.640s
train Loss: 0.27231965 Acc: 0.91432327
val Loss: 0.20932445 Acc: 0.95217389
Epoch 54 of 120 took 1.640s
train Loss: 0.26970093 Acc: 0.91392905
val Loss: 0.20123262 Acc: 0.95217389
Epoch 55 of 120 took 1.689s
train Loss: 0.26631412 Acc: 0.91629434
val Loss: 0.20383520 Acc: 0.95217389
Epoch 56 of 120 took 1.641s
train Loss: 0.26833600 Acc: 0.91441083
val Loss: 0.20484692 Acc: 0.95217389
Epoch 57 of 120 took 1.639s
train Loss: 0.26984866 Acc: 0.91410422
val Loss: 0.21137435 Acc: 0.95217389
Epoch 58 of 120 took 1.686s
train Loss: 0.27606878 Acc: 0.9140166
val Loss: 0.20714848 Acc: 0.95217389
Epoch 59 of 120 took 1.640s
train Loss: 0.26817436 Acc: 0.91541827
val Loss: 0.20456451 Acc: 0.94782603
Epoch 60 of 120 took 1.640s
train Loss: 0.26148123 Acc: 0.91804641
val Loss: 0.20514450 Acc: 0.95652169
Epoch 00061: reducing learning rate of group 0 to 8.0000e-05.
Epoch 61 of 120 took 1.641s
train Loss: 0.26893598 Acc: 0.91467369
val Loss: 0.20383395 Acc: 0.95217389
Epoch 62 of 120 took 1.641s
train Loss: 0.27395426 Acc: 0.91537452
val Loss: 0.19745197 Acc: 0.95217389
Epoch 63 of 120 took 1.645s
train Loss: 0.26291211 Acc: 0.91633815
val Loss: 0.20008533 Acc: 0.95652169
Epoch 64 of 120 took 1.678s
train Loss: 0.26786845 Acc: 0.91690755
val Loss: 0.20299108 Acc: 0.94347823
Epoch 65 of 120 took 1.624s
train Loss: 0.26523804 Acc: 0.91467369
val Loss: 0.20058317 Acc: 0.95217389
Epoch 66 of 120 took 1.624s
train Loss: 0.26393243 Acc: 0.91773981
val Loss: 0.19729689 Acc: 0.95652169
Epoch 67 of 120 took 1.629s
train Loss: 0.26883917 Acc: 0.91642576
val Loss: 0.20060239 Acc: 0.94782603
Epoch 68 of 120 took 1.626s
train Loss: 0.26491922 Acc: 0.91629434
val Loss: 0.20534584 Acc: 0.95217389
Epoch 69 of 120 took 1.671s
train Loss: 0.26621747 Acc: 0.9155497
val Loss: 0.20061503 Acc: 0.95217389
Epoch 70 of 120 took 1.626s
train Loss: 0.27182146 Acc: 0.91362244
val Loss: 0.19937044 Acc: 0.95652169
Epoch 71 of 120 took 1.626s
train Loss: 0.26042310 Acc: 0.91804641
val Loss: 0.20375919 Acc: 0.95217389
Epoch 72 of 120 took 1.625s
train Loss: 0.26712688 Acc: 0.9161191
val Loss: 0.20080462 Acc: 0.94782603
Epoch 00073: reducing learning rate of group 0 to 1.6000e-05.
Epoch 73 of 120 took 1.625s
train Loss: 0.26490544 Acc: 0.9158563
val Loss: 0.19970116 Acc: 0.95217389
Epoch 74 of 120 took 1.626s
train Loss: 0.27065592 Acc: 0.91349101
val Loss: 0.19988506 Acc: 0.95217389
Epoch 75 of 120 took 1.624s
train Loss: 0.26344880 Acc: 0.91909766
val Loss: 0.20069088 Acc: 0.95652169
Epoch 76 of 120 took 1.625s
train Loss: 0.27308094 Acc: 0.91541827
val Loss: 0.20444826 Acc: 0.95217389
Epoch 77 of 120 took 1.671s
train Loss: 0.27272464 Acc: 0.91524309
val Loss: 0.19977184 Acc: 0.95652169
Epoch 78 of 120 took 1.626s

Training complete in 2m 9s
Best val loss: 0.197297
ACCURACY TEST_0 FINAL : 86.521 %
TOP-3 ACCURACY TEST_0 FINAL : 94.283 %
22768
(22768, 12, 10, 7)
train Loss: 1.55068559 Acc: 0.64098734
val Loss: 1.18507809 Acc: 0.6419214
Epoch 1 of 120 took 1.801s
train Loss: 0.98831265 Acc: 0.70853829
val Loss: 0.86104781 Acc: 0.73799127
Epoch 2 of 120 took 1.636s
train Loss: 0.79438940 Acc: 0.76387912
val Loss: 0.73985550 Acc: 0.79475981
Epoch 3 of 120 took 1.631s
train Loss: 0.70517809 Acc: 0.78452212
val Loss: 0.65713894 Acc: 0.80786026
Epoch 4 of 120 took 1.629s
train Loss: 0.66367381 Acc: 0.79291111
val Loss: 0.60157093 Acc: 0.83842796
Epoch 5 of 120 took 1.628s
train Loss: 0.61625789 Acc: 0.80670238
val Loss: 0.56321976 Acc: 0.83842796
Epoch 6 of 120 took 1.630s
train Loss: 0.58536972 Acc: 0.81763875
val Loss: 0.51738088 Acc: 0.83842796
Epoch 7 of 120 took 1.634s
train Loss: 0.55871063 Acc: 0.82334858
val Loss: 0.49786645 Acc: 0.84716159
Epoch 8 of 120 took 1.637s
train Loss: 0.53863991 Acc: 0.83261597
val Loss: 0.48614209 Acc: 0.85152841
Epoch 9 of 120 took 1.632s
train Loss: 0.52065034 Acc: 0.83775473
val Loss: 0.43675959 Acc: 0.86899567
Epoch 10 of 120 took 1.680s
train Loss: 0.49607853 Acc: 0.84377193
val Loss: 0.44641577 Acc: 0.86462885
Epoch 11 of 120 took 1.629s
train Loss: 0.48008055 Acc: 0.84741741
val Loss: 0.43011339 Acc: 0.86899567
Epoch 12 of 120 took 1.636s
train Loss: 0.46584155 Acc: 0.85189742
val Loss: 0.43156946 Acc: 0.86026204
Epoch 13 of 120 took 1.674s
train Loss: 0.46448259 Acc: 0.85238051
val Loss: 0.42057818 Acc: 0.86899567
Epoch 14 of 120 took 1.633s
train Loss: 0.45067897 Acc: 0.8593201
val Loss: 0.38730711 Acc: 0.86899567
Epoch 15 of 120 took 1.633s
train Loss: 0.43361097 Acc: 0.86138439
val Loss: 0.38407638 Acc: 0.87336248
Epoch 16 of 120 took 1.633s
train Loss: 0.42714611 Acc: 0.8655569
val Loss: 0.39258047 Acc: 0.87336248
Epoch 17 of 120 took 1.674s
train Loss: 0.41438734 Acc: 0.86643535
val Loss: 0.35804297 Acc: 0.86026204
Epoch 18 of 120 took 1.637s
train Loss: 0.40016596 Acc: 0.87091529
val Loss: 0.35256018 Acc: 0.88209611
Epoch 19 of 120 took 1.642s
train Loss: 0.40083314 Acc: 0.87355059
val Loss: 0.36091267 Acc: 0.87336248
Epoch 20 of 120 took 1.636s
train Loss: 0.39994449 Acc: 0.87341881
val Loss: 0.33030010 Acc: 0.8777293
Epoch 21 of 120 took 1.644s
train Loss: 0.39001215 Acc: 0.87680078
val Loss: 0.34097760 Acc: 0.87336248
Epoch 22 of 120 took 1.638s
train Loss: 0.37026651 Acc: 0.88088542
val Loss: 0.33771646 Acc: 0.88646287
Epoch 23 of 120 took 1.681s
train Loss: 0.37174714 Acc: 0.88079762
val Loss: 0.33749311 Acc: 0.8777293
Epoch 24 of 120 took 1.636s
train Loss: 0.36477530 Acc: 0.88264227
val Loss: 0.29639315 Acc: 0.8951965
Epoch 25 of 120 took 1.643s
train Loss: 0.35707242 Acc: 0.88584852
val Loss: 0.32597161 Acc: 0.88646287
Epoch 26 of 120 took 1.682s
train Loss: 0.34786223 Acc: 0.889494
val Loss: 0.30710979 Acc: 0.88209611
Epoch 27 of 120 took 1.636s
train Loss: 0.34482097 Acc: 0.88672698
val Loss: 0.33094291 Acc: 0.86899567
Epoch 28 of 120 took 1.638s
train Loss: 0.34987835 Acc: 0.88852775
val Loss: 0.29330328 Acc: 0.90829694
Epoch 29 of 120 took 1.642s
train Loss: 0.33703859 Acc: 0.89243674
val Loss: 0.31667811 Acc: 0.89082968
Epoch 30 of 120 took 1.638s
train Loss: 0.33337905 Acc: 0.89362264
val Loss: 0.28999639 Acc: 0.88209611
Epoch 31 of 120 took 1.688s
train Loss: 0.32626329 Acc: 0.89529163
val Loss: 0.26402175 Acc: 0.91266376
Epoch 32 of 120 took 1.643s
train Loss: 0.32464631 Acc: 0.89419359
val Loss: 0.27554952 Acc: 0.90393013
Epoch 33 of 120 took 1.639s
train Loss: 0.31966469 Acc: 0.89735591
val Loss: 0.28236269 Acc: 0.90829694
Epoch 34 of 120 took 1.682s
train Loss: 0.31781416 Acc: 0.89805865
val Loss: 0.27929497 Acc: 0.91266376
Epoch 35 of 120 took 1.636s
train Loss: 0.31720203 Acc: 0.89858574
val Loss: 0.28909219 Acc: 0.90829694
Epoch 36 of 120 took 1.636s
train Loss: 0.31202350 Acc: 0.89792693
val Loss: 0.28788551 Acc: 0.90393013
Epoch 37 of 120 took 1.637s
train Loss: 0.31193744 Acc: 0.9002108
val Loss: 0.27827463 Acc: 0.90393013
Epoch 00038: reducing learning rate of group 0 to 2.0000e-03.
Epoch 38 of 120 took 1.681s
train Loss: 0.28838608 Acc: 0.90811664
val Loss: 0.25504003 Acc: 0.91703057
Epoch 39 of 120 took 1.644s
train Loss: 0.27679986 Acc: 0.9104445
val Loss: 0.24859599 Acc: 0.9257642
Epoch 40 of 120 took 1.642s
train Loss: 0.27213702 Acc: 0.91149861
val Loss: 0.24961960 Acc: 0.91703057
Epoch 41 of 120 took 1.636s
train Loss: 0.26850006 Acc: 0.91413385
val Loss: 0.23803733 Acc: 0.92139739
Epoch 42 of 120 took 1.687s
train Loss: 0.26728157 Acc: 0.91220134
val Loss: 0.25207166 Acc: 0.90829694
Epoch 43 of 120 took 1.636s
train Loss: 0.26735573 Acc: 0.91553932
val Loss: 0.24003900 Acc: 0.92139739
Epoch 44 of 120 took 1.635s
train Loss: 0.26556798 Acc: 0.91417778
val Loss: 0.24281368 Acc: 0.91266376
Epoch 45 of 120 took 1.637s
train Loss: 0.27044752 Acc: 0.91325545
val Loss: 0.23533569 Acc: 0.9257642
Epoch 46 of 120 took 1.643s
train Loss: 0.26272436 Acc: 0.91488051
val Loss: 0.23948754 Acc: 0.91703057
Epoch 47 of 120 took 1.682s
train Loss: 0.26133874 Acc: 0.91360682
val Loss: 0.24373963 Acc: 0.91703057
Epoch 48 of 120 took 1.636s
train Loss: 0.25728158 Acc: 0.91628599
val Loss: 0.24363703 Acc: 0.92139739
Epoch 49 of 120 took 1.635s
train Loss: 0.26468364 Acc: 0.91373855
val Loss: 0.22229982 Acc: 0.92139739
Epoch 50 of 120 took 1.641s
train Loss: 0.25958915 Acc: 0.91523188
val Loss: 0.22361723 Acc: 0.92139739
Epoch 51 of 120 took 1.682s
train Loss: 0.26406583 Acc: 0.91294801
val Loss: 0.22676837 Acc: 0.91703057
Epoch 52 of 120 took 1.636s
train Loss: 0.25842967 Acc: 0.91799891
val Loss: 0.22355783 Acc: 0.91703057
Epoch 53 of 120 took 1.636s
train Loss: 0.25326405 Acc: 0.91742796
val Loss: 0.22773532 Acc: 0.92139739
Epoch 54 of 120 took 1.638s
train Loss: 0.25717169 Acc: 0.91474879
val Loss: 0.21829133 Acc: 0.9257642
Epoch 55 of 120 took 1.687s
train Loss: 0.25203476 Acc: 0.91865778
val Loss: 0.21769880 Acc: 0.93449783
Epoch 56 of 120 took 1.643s
train Loss: 0.25375576 Acc: 0.91799891
val Loss: 0.22537573 Acc: 0.9257642
Epoch 57 of 120 took 1.638s
train Loss: 0.25430197 Acc: 0.91654956
val Loss: 0.20813138 Acc: 0.92139739
Epoch 58 of 120 took 1.645s
train Loss: 0.25187959 Acc: 0.91641778
val Loss: 0.21381017 Acc: 0.9257642
Epoch 59 of 120 took 1.680s
train Loss: 0.25030811 Acc: 0.91769147
val Loss: 0.21635720 Acc: 0.93449783
Epoch 60 of 120 took 1.636s
train Loss: 0.25009767 Acc: 0.91892129
val Loss: 0.21941726 Acc: 0.93013102
Epoch 61 of 120 took 1.636s
train Loss: 0.24782832 Acc: 0.91690093
val Loss: 0.21467536 Acc: 0.93013102
Epoch 62 of 120 took 1.635s
train Loss: 0.24726703 Acc: 0.91883343
val Loss: 0.21675365 Acc: 0.93013102
Epoch 63 of 120 took 1.680s
train Loss: 0.24416311 Acc: 0.92032677
val Loss: 0.21082733 Acc: 0.9257642
Epoch 00064: reducing learning rate of group 0 to 4.0000e-04.
Epoch 64 of 120 took 1.634s
train Loss: 0.24643338 Acc: 0.9191848
val Loss: 0.21154759 Acc: 0.93449783
Epoch 65 of 120 took 1.637s
train Loss: 0.24262063 Acc: 0.92116129
val Loss: 0.21533961 Acc: 0.93449783
Epoch 66 of 120 took 1.636s
train Loss: 0.24248564 Acc: 0.92059028
val Loss: 0.21115990 Acc: 0.93013102
Epoch 67 of 120 took 1.680s
train Loss: 0.23699034 Acc: 0.92296207
val Loss: 0.21335446 Acc: 0.9257642
Epoch 68 of 120 took 1.637s
train Loss: 0.24131265 Acc: 0.92072207
val Loss: 0.21416326 Acc: 0.93013102
Epoch 69 of 120 took 1.635s

Training complete in 1m 54s
Best val loss: 0.208131
ACCURACY TEST_0 FINAL : 86.232 %
TOP-3 ACCURACY TEST_0 FINAL : 94.569 %
22868
(22868, 12, 10, 7)
train Loss: 1.49662055 Acc: 0.64937907
val Loss: 0.97547718 Acc: 0.70434779
Epoch 1 of 120 took 1.822s
train Loss: 0.93698507 Acc: 0.73176491
val Loss: 0.75680646 Acc: 0.76956517
Epoch 2 of 120 took 1.650s
train Loss: 0.78334589 Acc: 0.77453208
val Loss: 0.66314654 Acc: 0.78695649
Epoch 3 of 120 took 1.644s
train Loss: 0.69441902 Acc: 0.79705268
val Loss: 0.58564508 Acc: 0.79565215
Epoch 4 of 120 took 1.644s
train Loss: 0.62944317 Acc: 0.81122094
val Loss: 0.51366745 Acc: 0.8391304
Epoch 5 of 120 took 1.690s
train Loss: 0.58615081 Acc: 0.82464582
val Loss: 0.46578590 Acc: 0.85217386
Epoch 6 of 120 took 1.645s
train Loss: 0.54892774 Acc: 0.83404762
val Loss: 0.48627012 Acc: 0.84782606
Epoch 7 of 120 took 1.638s
train Loss: 0.52694874 Acc: 0.83837676
val Loss: 0.44960856 Acc: 0.86521733
Epoch 8 of 120 took 1.643s
train Loss: 0.49502810 Acc: 0.84799719
val Loss: 0.41592434 Acc: 0.86521733
Epoch 9 of 120 took 1.688s
train Loss: 0.48153223 Acc: 0.8528949
val Loss: 0.32557573 Acc: 0.88260865
Epoch 10 of 120 took 1.643s
train Loss: 0.45518576 Acc: 0.86015391
val Loss: 0.34085294 Acc: 0.89130431
Epoch 11 of 120 took 1.637s
train Loss: 0.45491726 Acc: 0.86150956
val Loss: 0.31324744 Acc: 0.89130431
Epoch 12 of 120 took 1.644s
train Loss: 0.42927011 Acc: 0.86636347
val Loss: 0.30467254 Acc: 0.89565212
Epoch 13 of 120 took 1.690s
train Loss: 0.41131087 Acc: 0.87200457
val Loss: 0.27117936 Acc: 0.90869564
Epoch 14 of 120 took 1.643s
train Loss: 0.39869965 Acc: 0.87410355
val Loss: 0.26868974 Acc: 0.9260869
Epoch 15 of 120 took 1.645s
train Loss: 0.40121195 Acc: 0.87362254
val Loss: 0.32515157 Acc: 0.89130431
Epoch 16 of 120 took 1.638s
train Loss: 0.39304083 Acc: 0.87729579
val Loss: 0.26522263 Acc: 0.91304344
Epoch 17 of 120 took 1.689s
train Loss: 0.38725465 Acc: 0.87965715
val Loss: 0.29450672 Acc: 0.89565212
Epoch 18 of 120 took 1.636s
train Loss: 0.38049921 Acc: 0.87690222
val Loss: 0.26800379 Acc: 0.90434778
Epoch 19 of 120 took 1.621s
train Loss: 0.36958800 Acc: 0.88363653
val Loss: 0.26450687 Acc: 0.91304344
Epoch 20 of 120 took 1.672s
train Loss: 0.35411750 Acc: 0.88695997
val Loss: 0.23652525 Acc: 0.91739124
Epoch 21 of 120 took 1.628s
train Loss: 0.34288672 Acc: 0.89041454
val Loss: 0.21603467 Acc: 0.9260869
Epoch 22 of 120 took 1.627s
train Loss: 0.34426399 Acc: 0.89028341
val Loss: 0.22169412 Acc: 0.93478256
Epoch 23 of 120 took 1.622s
train Loss: 0.33114563 Acc: 0.89400035
val Loss: 0.20460219 Acc: 0.93043476
Epoch 24 of 120 took 1.628s
train Loss: 0.32580857 Acc: 0.89714885
val Loss: 0.20869929 Acc: 0.9217391
Epoch 25 of 120 took 1.667s
train Loss: 0.32004738 Acc: 0.89819837
val Loss: 0.20346386 Acc: 0.93478256
Epoch 26 of 120 took 1.627s
train Loss: 0.31918696 Acc: 0.89601189
val Loss: 0.21812157 Acc: 0.93478256
Epoch 27 of 120 took 1.624s
train Loss: 0.30559270 Acc: 0.90134686
val Loss: 0.23805114 Acc: 0.9260869
Epoch 28 of 120 took 1.624s
train Loss: 0.30531776 Acc: 0.90117198
val Loss: 0.22601696 Acc: 0.9217391
Epoch 29 of 120 took 1.667s
train Loss: 0.30058346 Acc: 0.90305233
val Loss: 0.20569164 Acc: 0.93478256
Epoch 30 of 120 took 1.623s
train Loss: 0.29977066 Acc: 0.90392691
val Loss: 0.17227049 Acc: 0.94347823
Epoch 31 of 120 took 1.629s
train Loss: 0.29913488 Acc: 0.90488893
val Loss: 0.21288527 Acc: 0.93043476
Epoch 32 of 120 took 1.624s
train Loss: 0.29179293 Acc: 0.90917438
val Loss: 0.21285727 Acc: 0.9260869
Epoch 33 of 120 took 1.672s
train Loss: 0.29077771 Acc: 0.90471405
val Loss: 0.16525392 Acc: 0.93913037
Epoch 34 of 120 took 1.630s
train Loss: 0.27982639 Acc: 0.90983033
val Loss: 0.17144437 Acc: 0.93478256
Epoch 35 of 120 took 1.627s
train Loss: 0.28492242 Acc: 0.9102239
val Loss: 0.15569044 Acc: 0.96086955
Epoch 36 of 120 took 1.631s
train Loss: 0.27744904 Acc: 0.90974289
val Loss: 0.16854675 Acc: 0.96086955
Epoch 37 of 120 took 1.672s
train Loss: 0.27746219 Acc: 0.91280395
val Loss: 0.14896213 Acc: 0.94782603
Epoch 38 of 120 took 1.634s
train Loss: 0.27036643 Acc: 0.9146843
val Loss: 0.19459963 Acc: 0.94782603
Epoch 39 of 120 took 1.626s
train Loss: 0.26210422 Acc: 0.91547143
val Loss: 0.17338103 Acc: 0.94347823
Epoch 40 of 120 took 1.672s
train Loss: 0.26303177 Acc: 0.9163897
val Loss: 0.15537169 Acc: 0.96086955
Epoch 41 of 120 took 1.625s
train Loss: 0.26205938 Acc: 0.91429073
val Loss: 0.16888280 Acc: 0.95217389
Epoch 42 of 120 took 1.625s
train Loss: 0.27006460 Acc: 0.91481549
val Loss: 0.18660393 Acc: 0.94782603
Epoch 43 of 120 took 1.672s
train Loss: 0.25837158 Acc: 0.91722059
val Loss: 0.16094773 Acc: 0.95652169
Epoch 00044: reducing learning rate of group 0 to 2.0000e-03.
Epoch 44 of 120 took 1.626s
train Loss: 0.24507574 Acc: 0.92071891
val Loss: 0.13329737 Acc: 0.95652169
Epoch 45 of 120 took 1.632s
train Loss: 0.22632382 Acc: 0.92622882
val Loss: 0.13692564 Acc: 0.95652169
Epoch 46 of 120 took 1.628s
train Loss: 0.22499830 Acc: 0.92894
val Loss: 0.13187322 Acc: 0.95652169
Epoch 47 of 120 took 1.677s
train Loss: 0.22074531 Acc: 0.92854643
val Loss: 0.12528251 Acc: 0.95652169
Epoch 48 of 120 took 1.632s
train Loss: 0.21717677 Acc: 0.93020815
val Loss: 0.12557032 Acc: 0.96521735
Epoch 49 of 120 took 1.624s
train Loss: 0.21913858 Acc: 0.92911494
val Loss: 0.12321937 Acc: 0.95652169
Epoch 50 of 120 took 1.630s
train Loss: 0.21828323 Acc: 0.92907119
val Loss: 0.12459068 Acc: 0.96086955
Epoch 51 of 120 took 1.671s
train Loss: 0.21809509 Acc: 0.9296397
val Loss: 0.12236978 Acc: 0.96086955
Epoch 52 of 120 took 1.641s
train Loss: 0.21224757 Acc: 0.93077666
val Loss: 0.12902376 Acc: 0.96086955
Epoch 53 of 120 took 1.633s
train Loss: 0.21322162 Acc: 0.93055803
val Loss: 0.12027546 Acc: 0.96086955
Epoch 54 of 120 took 1.632s
train Loss: 0.21132850 Acc: 0.93186986
val Loss: 0.12514259 Acc: 0.95652169
Epoch 55 of 120 took 1.627s
train Loss: 0.21365393 Acc: 0.93095154
val Loss: 0.11819383 Acc: 0.95652169
Epoch 56 of 120 took 1.677s
train Loss: 0.20985141 Acc: 0.93147629
val Loss: 0.11062617 Acc: 0.96086955
Epoch 57 of 120 took 1.635s
train Loss: 0.20800119 Acc: 0.93366277
val Loss: 0.11794463 Acc: 0.96521735
Epoch 58 of 120 took 1.626s
train Loss: 0.20970719 Acc: 0.93348783
val Loss: 0.11141132 Acc: 0.96521735
Epoch 59 of 120 took 1.627s
train Loss: 0.21220486 Acc: 0.93169498
val Loss: 0.11583312 Acc: 0.96086955
Epoch 60 of 120 took 1.672s
train Loss: 0.20896761 Acc: 0.93283194
val Loss: 0.12718853 Acc: 0.96086955
Epoch 61 of 120 took 1.625s
train Loss: 0.20845463 Acc: 0.93305057
val Loss: 0.12621097 Acc: 0.96086955
Epoch 62 of 120 took 1.670s
train Loss: 0.20997881 Acc: 0.93340039
val Loss: 0.13290130 Acc: 0.95652169
Epoch 00063: reducing learning rate of group 0 to 4.0000e-04.
Epoch 63 of 120 took 1.624s
train Loss: 0.20597116 Acc: 0.93099529
val Loss: 0.12295889 Acc: 0.95652169
Epoch 64 of 120 took 1.623s
train Loss: 0.20335600 Acc: 0.93541193
val Loss: 0.12088280 Acc: 0.96086955
Epoch 65 of 120 took 1.624s
train Loss: 0.20179346 Acc: 0.93410009
val Loss: 0.12284379 Acc: 0.95652169
Epoch 66 of 120 took 1.624s
train Loss: 0.20474074 Acc: 0.93287563
val Loss: 0.12229359 Acc: 0.96086955
Epoch 67 of 120 took 1.624s
train Loss: 0.20441946 Acc: 0.93191361
val Loss: 0.11521337 Acc: 0.96086955
Epoch 68 of 120 took 1.626s

Training complete in 1m 52s
Best val loss: 0.110626
ACCURACY TEST_0 FINAL : 86.759 %
TOP-3 ACCURACY TEST_0 FINAL : 95.824 %
22710
(22710, 12, 10, 7)
train Loss: 1.99978999 Acc: 0.58639365
val Loss: 1.11303983 Acc: 0.66812229
Epoch 1 of 120 took 1.786s
train Loss: 1.19706941 Acc: 0.66111845
val Loss: 0.97400840 Acc: 0.69868994
Epoch 2 of 120 took 1.592s
train Loss: 1.04479907 Acc: 0.69577283
val Loss: 0.88625838 Acc: 0.7161572
Epoch 3 of 120 took 1.628s
train Loss: 0.95626866 Acc: 0.71611625
val Loss: 0.79378128 Acc: 0.7467249
Epoch 4 of 120 took 1.673s
train Loss: 0.88180736 Acc: 0.73857331
val Loss: 0.75335587 Acc: 0.76419216
Epoch 5 of 120 took 1.628s
train Loss: 0.82519622 Acc: 0.75204754
val Loss: 0.72058378 Acc: 0.76419216
Epoch 6 of 120 took 1.628s
train Loss: 0.78734934 Acc: 0.76054603
val Loss: 0.70558946 Acc: 0.75109172
Epoch 7 of 120 took 1.629s
train Loss: 0.74871222 Acc: 0.77173054
val Loss: 0.67039630 Acc: 0.76855898
Epoch 8 of 120 took 1.628s
train Loss: 0.72153107 Acc: 0.77714664
val Loss: 0.65816348 Acc: 0.75545853
Epoch 9 of 120 took 1.631s
train Loss: 0.68704993 Acc: 0.78767061
val Loss: 0.62946693 Acc: 0.77292579
Epoch 10 of 120 took 1.638s
train Loss: 0.66478761 Acc: 0.79040074
val Loss: 0.59491286 Acc: 0.78165942
Epoch 11 of 120 took 1.686s
train Loss: 0.64623386 Acc: 0.79665345
val Loss: 0.59132760 Acc: 0.77292579
Epoch 12 of 120 took 1.639s
train Loss: 0.62436744 Acc: 0.80523998
val Loss: 0.56957391 Acc: 0.79912663
Epoch 13 of 120 took 1.639s
train Loss: 0.61096426 Acc: 0.80823427
val Loss: 0.54534905 Acc: 0.79039305
Epoch 14 of 120 took 1.639s
train Loss: 0.59267468 Acc: 0.80889475
val Loss: 0.59358738 Acc: 0.79039305
Epoch 15 of 120 took 1.679s
train Loss: 0.57671962 Acc: 0.81642449
val Loss: 0.54668230 Acc: 0.80349344
Epoch 16 of 120 took 1.634s
train Loss: 0.56691214 Acc: 0.82188463
val Loss: 0.54601078 Acc: 0.79475981
Epoch 17 of 120 took 1.633s
train Loss: 0.55811297 Acc: 0.82228094
val Loss: 0.50921627 Acc: 0.81222707
Epoch 18 of 120 took 1.640s
train Loss: 0.54208806 Acc: 0.82818145
val Loss: 0.51462968 Acc: 0.82969433
Epoch 19 of 120 took 1.679s
train Loss: 0.52620659 Acc: 0.8335095
val Loss: 0.53638185 Acc: 0.83406115
Epoch 20 of 120 took 1.633s
train Loss: 0.52198604 Acc: 0.83399385
val Loss: 0.46304766 Acc: 0.83842796
Epoch 21 of 120 took 1.641s
train Loss: 0.51460279 Acc: 0.83707619
val Loss: 0.46689825 Acc: 0.83406115
Epoch 22 of 120 took 1.675s
train Loss: 0.49998513 Acc: 0.83993834
val Loss: 0.44564170 Acc: 0.83842796
Epoch 23 of 120 took 1.625s
train Loss: 0.49513022 Acc: 0.83888155
val Loss: 0.47278419 Acc: 0.82532752
Epoch 24 of 120 took 1.622s
train Loss: 0.48760773 Acc: 0.84306473
val Loss: 0.47940748 Acc: 0.83406115
Epoch 25 of 120 took 1.621s
train Loss: 0.47433590 Acc: 0.84641129
val Loss: 0.43321210 Acc: 0.82969433
Epoch 26 of 120 took 1.671s
train Loss: 0.47620736 Acc: 0.84808457
val Loss: 0.46694949 Acc: 0.84716159
Epoch 27 of 120 took 1.622s
train Loss: 0.46708491 Acc: 0.85002202
val Loss: 0.42556298 Acc: 0.86462885
Epoch 28 of 120 took 1.630s
train Loss: 0.46119359 Acc: 0.85385293
val Loss: 0.42177479 Acc: 0.84279478
Epoch 29 of 120 took 1.673s
train Loss: 0.44258243 Acc: 0.8560546
val Loss: 0.43586531 Acc: 0.86462885
Epoch 30 of 120 took 1.621s
train Loss: 0.44463959 Acc: 0.85693526
val Loss: 0.39729073 Acc: 0.86026204
Epoch 31 of 120 took 1.627s
train Loss: 0.43070281 Acc: 0.86072218
val Loss: 0.41022043 Acc: 0.87336248
Epoch 32 of 120 took 1.622s
train Loss: 0.42207439 Acc: 0.86468518
val Loss: 0.41080426 Acc: 0.86462885
Epoch 33 of 120 took 1.666s
train Loss: 0.42526295 Acc: 0.85988551
val Loss: 0.41153352 Acc: 0.8777293
Epoch 34 of 120 took 1.622s
train Loss: 0.41497277 Acc: 0.8664465
val Loss: 0.41494574 Acc: 0.86899567
Epoch 35 of 120 took 1.623s
train Loss: 0.41827153 Acc: 0.86371642
val Loss: 0.37941141 Acc: 0.86462885
Epoch 36 of 120 took 1.628s
train Loss: 0.41528858 Acc: 0.86512554
val Loss: 0.40898372 Acc: 0.87336248
Epoch 37 of 120 took 1.622s
train Loss: 0.40987455 Acc: 0.86873627
val Loss: 0.35749930 Acc: 0.86462885
Epoch 38 of 120 took 1.674s
train Loss: 0.41234377 Acc: 0.86869222
val Loss: 0.37001829 Acc: 0.8951965
Epoch 39 of 120 took 1.625s
train Loss: 0.40312802 Acc: 0.87071776
val Loss: 0.33264754 Acc: 0.89082968
Epoch 40 of 120 took 1.629s
train Loss: 0.38705476 Acc: 0.87446058
val Loss: 0.34004742 Acc: 0.89082968
Epoch 41 of 120 took 1.624s
train Loss: 0.38622493 Acc: 0.87485689
val Loss: 0.34985283 Acc: 0.88209611
Epoch 42 of 120 took 1.668s
train Loss: 0.37361894 Acc: 0.87714666
val Loss: 0.33749150 Acc: 0.8777293
Epoch 43 of 120 took 1.623s
train Loss: 0.37426798 Acc: 0.87908411
val Loss: 0.36012247 Acc: 0.89082968
Epoch 44 of 120 took 1.623s
train Loss: 0.37945246 Acc: 0.87886393
val Loss: 0.35976724 Acc: 0.87336248
Epoch 45 of 120 took 1.624s
train Loss: 0.36955705 Acc: 0.87930429
val Loss: 0.31971957 Acc: 0.90829694
Epoch 46 of 120 took 1.628s
train Loss: 0.35806604 Acc: 0.88339937
val Loss: 0.31168722 Acc: 0.8951965
Epoch 47 of 120 took 1.675s
train Loss: 0.35653489 Acc: 0.88392782
val Loss: 0.32695874 Acc: 0.88646287
Epoch 48 of 120 took 1.626s
train Loss: 0.35711868 Acc: 0.88401586
val Loss: 0.34798962 Acc: 0.88209611
Epoch 49 of 120 took 1.624s
train Loss: 0.35459562 Acc: 0.88533688
val Loss: 0.32496639 Acc: 0.89956331
Epoch 50 of 120 took 1.623s
train Loss: 0.37031847 Acc: 0.8797006
val Loss: 0.39916090 Acc: 0.8777293
Epoch 51 of 120 took 1.667s
train Loss: 0.37211534 Acc: 0.88155001
val Loss: 0.36462777 Acc: 0.8777293
Epoch 52 of 120 took 1.622s
train Loss: 0.34629267 Acc: 0.88683403
val Loss: 0.36072077 Acc: 0.89082968
Epoch 00053: reducing learning rate of group 0 to 2.0000e-03.
Epoch 53 of 120 took 1.624s
train Loss: 0.32681523 Acc: 0.89335096
val Loss: 0.31898012 Acc: 0.8951965
Epoch 54 of 120 took 1.624s
train Loss: 0.31574790 Acc: 0.89797449
val Loss: 0.31190561 Acc: 0.8951965
Epoch 55 of 120 took 1.668s
train Loss: 0.31650663 Acc: 0.89621311
val Loss: 0.30596681 Acc: 0.90393013
Epoch 56 of 120 took 1.629s
train Loss: 0.31145668 Acc: 0.89854693
val Loss: 0.29235412 Acc: 0.91266376
Epoch 57 of 120 took 1.631s
train Loss: 0.30958863 Acc: 0.89682961
val Loss: 0.30223032 Acc: 0.91266376
Epoch 58 of 120 took 1.668s
train Loss: 0.30210438 Acc: 0.90255398
val Loss: 0.30059845 Acc: 0.91266376
Epoch 59 of 120 took 1.624s
train Loss: 0.30381887 Acc: 0.9003523
val Loss: 0.30065006 Acc: 0.92139739
Epoch 60 of 120 took 1.624s
train Loss: 0.30492333 Acc: 0.89964777
val Loss: 0.28562582 Acc: 0.91266376
Epoch 61 of 120 took 1.629s
train Loss: 0.30440263 Acc: 0.90057242
val Loss: 0.28924539 Acc: 0.91703057
Epoch 62 of 120 took 1.623s
train Loss: 0.29752622 Acc: 0.90409511
val Loss: 0.28626666 Acc: 0.90393013
Epoch 63 of 120 took 1.669s
train Loss: 0.29288839 Acc: 0.90396303
val Loss: 0.28607883 Acc: 0.91703057
Epoch 64 of 120 took 1.623s
train Loss: 0.29987959 Acc: 0.89969176
val Loss: 0.28043150 Acc: 0.9257642
Epoch 65 of 120 took 1.629s
train Loss: 0.30055189 Acc: 0.90339059
val Loss: 0.28559523 Acc: 0.92139739
Epoch 66 of 120 took 1.623s
train Loss: 0.29639804 Acc: 0.90546018
val Loss: 0.28248552 Acc: 0.9257642
Epoch 67 of 120 took 1.669s
train Loss: 0.29925798 Acc: 0.90250993
val Loss: 0.29583520 Acc: 0.91703057
Epoch 68 of 120 took 1.623s
train Loss: 0.29519354 Acc: 0.90484369
val Loss: 0.29492146 Acc: 0.91703057
Epoch 69 of 120 took 1.625s
train Loss: 0.28949378 Acc: 0.90603262
val Loss: 0.27880740 Acc: 0.91703057
Epoch 70 of 120 took 1.629s
train Loss: 0.29377139 Acc: 0.90479964
val Loss: 0.26922460 Acc: 0.9257642
Epoch 71 of 120 took 1.628s
train Loss: 0.29276298 Acc: 0.90524
val Loss: 0.27196130 Acc: 0.92139739
Epoch 72 of 120 took 1.670s
train Loss: 0.29033737 Acc: 0.90554821
val Loss: 0.27110534 Acc: 0.91266376
Epoch 73 of 120 took 1.625s
train Loss: 0.29082699 Acc: 0.90568036
val Loss: 0.27385315 Acc: 0.91703057
Epoch 74 of 120 took 1.627s
train Loss: 0.28859885 Acc: 0.90585649
val Loss: 0.27409060 Acc: 0.92139739
Epoch 75 of 120 took 1.628s
train Loss: 0.29663145 Acc: 0.90162927
val Loss: 0.26702910 Acc: 0.90829694
Epoch 76 of 120 took 1.677s
train Loss: 0.29112528 Acc: 0.90431529
val Loss: 0.26685048 Acc: 0.91266376
Epoch 77 of 120 took 1.634s
train Loss: 0.29140896 Acc: 0.90449142
val Loss: 0.27588224 Acc: 0.92139739
Epoch 78 of 120 took 1.626s
train Loss: 0.29142289 Acc: 0.90537208
val Loss: 0.27750279 Acc: 0.91266376
Epoch 79 of 120 took 1.628s
train Loss: 0.28848443 Acc: 0.90581244
val Loss: 0.25993211 Acc: 0.91266376
Epoch 80 of 120 took 1.635s
train Loss: 0.28780239 Acc: 0.90863055
val Loss: 0.25280125 Acc: 0.92139739
Epoch 81 of 120 took 1.677s
train Loss: 0.28976261 Acc: 0.90444738
val Loss: 0.26514061 Acc: 0.90829694
Epoch 82 of 120 took 1.622s
train Loss: 0.28056958 Acc: 0.90849847
val Loss: 0.26617579 Acc: 0.92139739
Epoch 83 of 120 took 1.621s
train Loss: 0.28634206 Acc: 0.90594453
val Loss: 0.25801676 Acc: 0.92139739
Epoch 84 of 120 took 1.623s
train Loss: 0.28554259 Acc: 0.90695733
val Loss: 0.27391353 Acc: 0.91703057
Epoch 85 of 120 took 1.623s
train Loss: 0.27945136 Acc: 0.90951127
val Loss: 0.25925201 Acc: 0.91266376
Epoch 86 of 120 took 1.666s
train Loss: 0.28106595 Acc: 0.90827829
val Loss: 0.26678606 Acc: 0.91703057
Epoch 00087: reducing learning rate of group 0 to 4.0000e-04.
Epoch 87 of 120 took 1.621s
train Loss: 0.27787067 Acc: 0.90929109
val Loss: 0.25631939 Acc: 0.92139739
Epoch 88 of 120 took 1.622s
train Loss: 0.27428939 Acc: 0.91087627
val Loss: 0.26168219 Acc: 0.91703057
Epoch 89 of 120 took 1.668s
train Loss: 0.27507128 Acc: 0.91162485
val Loss: 0.26129915 Acc: 0.91266376
Epoch 90 of 120 took 1.623s
train Loss: 0.26844145 Acc: 0.91171294
val Loss: 0.25976842 Acc: 0.9257642
Epoch 91 of 120 took 1.624s
train Loss: 0.27380550 Acc: 0.90924704
val Loss: 0.25760623 Acc: 0.91703057
Epoch 92 of 120 took 1.624s

Training complete in 2m 31s
Best val loss: 0.252801
ACCURACY TEST_0 FINAL : 81.393 %
TOP-3 ACCURACY TEST_0 FINAL : 93.211 %
22684
(22684, 12, 10, 7)
train Loss: 1.28949826 Acc: 0.65976018
val Loss: 0.91249290 Acc: 0.7161572
Epoch 1 of 120 took 1.829s
train Loss: 0.85635694 Acc: 0.74016929
val Loss: 0.75852666 Acc: 0.75545853
Epoch 2 of 120 took 1.590s
train Loss: 0.73437928 Acc: 0.77186561
val Loss: 0.71213591 Acc: 0.79912663
Epoch 3 of 120 took 1.631s
train Loss: 0.64948161 Acc: 0.79373127
val Loss: 0.63294823 Acc: 0.79039305
Epoch 4 of 120 took 1.632s
train Loss: 0.60065724 Acc: 0.80598658
val Loss: 0.59786309 Acc: 0.80349344
Epoch 5 of 120 took 1.630s
train Loss: 0.55423808 Acc: 0.82097512
val Loss: 0.51198028 Acc: 0.83842796
Epoch 6 of 120 took 1.632s
train Loss: 0.53070263 Acc: 0.82754362
val Loss: 0.50625650 Acc: 0.82969433
Epoch 7 of 120 took 1.634s
train Loss: 0.50948165 Acc: 0.83856463
val Loss: 0.47236843 Acc: 0.86462885
Epoch 8 of 120 took 1.632s
train Loss: 0.48366371 Acc: 0.84314936
val Loss: 0.50577274 Acc: 0.84279478
Epoch 9 of 120 took 1.671s
train Loss: 0.46246667 Acc: 0.8496297
val Loss: 0.45010083 Acc: 0.85589522
Epoch 10 of 120 took 1.634s
train Loss: 0.44703741 Acc: 0.85289192
val Loss: 0.44580627 Acc: 0.86462885
Epoch 11 of 120 took 1.634s
train Loss: 0.44030542 Acc: 0.85615414
val Loss: 0.41853286 Acc: 0.89082968
Epoch 12 of 120 took 1.685s
train Loss: 0.42359661 Acc: 0.86034209
val Loss: 0.43611386 Acc: 0.86026204
Epoch 13 of 120 took 1.636s
train Loss: 0.40857677 Acc: 0.8647505
val Loss: 0.42528878 Acc: 0.87336248
Epoch 14 of 120 took 1.636s
train Loss: 0.40107808 Acc: 0.86554402
val Loss: 0.38045204 Acc: 0.8777293
Epoch 15 of 120 took 1.639s
train Loss: 0.38617047 Acc: 0.87070179
val Loss: 0.40112858 Acc: 0.88646287
Epoch 16 of 120 took 1.665s
train Loss: 0.38837345 Acc: 0.86968791
val Loss: 0.37514971 Acc: 0.90393013
Epoch 17 of 120 took 1.627s
train Loss: 0.37812642 Acc: 0.87352318
val Loss: 0.35870285 Acc: 0.88209611
Epoch 18 of 120 took 1.627s
train Loss: 0.37096316 Acc: 0.87449306
val Loss: 0.35027325 Acc: 0.89082968
Epoch 19 of 120 took 1.627s
train Loss: 0.36571481 Acc: 0.87731439
val Loss: 0.33697693 Acc: 0.8951965
Epoch 20 of 120 took 1.671s
train Loss: 0.35402709 Acc: 0.88132602
val Loss: 0.34919840 Acc: 0.89956331
Epoch 21 of 120 took 1.623s
train Loss: 0.34717198 Acc: 0.88251632
val Loss: 0.32692679 Acc: 0.89082968
Epoch 22 of 120 took 1.626s
train Loss: 0.34627796 Acc: 0.88256037
val Loss: 0.36050856 Acc: 0.8777293
Epoch 23 of 120 took 1.622s
train Loss: 0.33604771 Acc: 0.88546991
val Loss: 0.33466602 Acc: 0.8951965
Epoch 24 of 120 took 1.622s
train Loss: 0.33692630 Acc: 0.88833541
val Loss: 0.34073087 Acc: 0.8777293
Epoch 25 of 120 took 1.668s
train Loss: 0.33181321 Acc: 0.88877624
val Loss: 0.32885365 Acc: 0.89956331
Epoch 26 of 120 took 1.623s
train Loss: 0.32019752 Acc: 0.89186209
val Loss: 0.30374429 Acc: 0.88209611
Epoch 27 of 120 took 1.628s
train Loss: 0.31268619 Acc: 0.89393407
val Loss: 0.30963786 Acc: 0.87336248
Epoch 28 of 120 took 1.671s
train Loss: 0.32000704 Acc: 0.89115673
val Loss: 0.28951955 Acc: 0.8951965
Epoch 29 of 120 took 1.632s
train Loss: 0.31971779 Acc: 0.89036328
val Loss: 0.28994417 Acc: 0.90393013
Epoch 30 of 120 took 1.623s
train Loss: 0.30989555 Acc: 0.89380181
val Loss: 0.31442751 Acc: 0.90829694
Epoch 31 of 120 took 1.623s
train Loss: 0.30610355 Acc: 0.89688766
val Loss: 0.30464558 Acc: 0.89956331
Epoch 32 of 120 took 1.667s
train Loss: 0.30052593 Acc: 0.89807796
val Loss: 0.31334321 Acc: 0.90393013
Epoch 33 of 120 took 1.623s
train Loss: 0.29884482 Acc: 0.89816612
val Loss: 0.31323857 Acc: 0.89956331
Epoch 34 of 120 took 1.622s
train Loss: 0.29041919 Acc: 0.90098751
val Loss: 0.27723990 Acc: 0.8951965
Epoch 35 of 120 took 1.629s
train Loss: 0.29333749 Acc: 0.90195733
val Loss: 0.32299786 Acc: 0.89956331
Epoch 36 of 120 took 1.675s
train Loss: 0.29218921 Acc: 0.90275085
val Loss: 0.31886060 Acc: 0.89082968
Epoch 37 of 120 took 1.628s
train Loss: 0.28717832 Acc: 0.90226591
val Loss: 0.29613047 Acc: 0.90393013
Epoch 38 of 120 took 1.628s
train Loss: 0.28247545 Acc: 0.90451419
val Loss: 0.26609849 Acc: 0.92139739
Epoch 39 of 120 took 1.633s
train Loss: 0.27337395 Acc: 0.90751189
val Loss: 0.28602535 Acc: 0.90393013
Epoch 40 of 120 took 1.673s
train Loss: 0.27347757 Acc: 0.907556
val Loss: 0.28919963 Acc: 0.89956331
Epoch 41 of 120 took 1.627s
train Loss: 0.27215366 Acc: 0.9081291
val Loss: 0.26695252 Acc: 0.92139739
Epoch 42 of 120 took 1.628s
train Loss: 0.26781602 Acc: 0.90896666
val Loss: 0.30371146 Acc: 0.90393013
Epoch 43 of 120 took 1.626s
train Loss: 0.26523429 Acc: 0.9118762
val Loss: 0.34009177 Acc: 0.89082968
Epoch 44 of 120 took 1.672s
train Loss: 0.25699163 Acc: 0.91324282
val Loss: 0.26540757 Acc: 0.90393013
Epoch 45 of 120 took 1.632s
train Loss: 0.25858085 Acc: 0.91258156
val Loss: 0.25701674 Acc: 0.90829694
Epoch 46 of 120 took 1.633s
train Loss: 0.25460340 Acc: 0.91346323
val Loss: 0.30460530 Acc: 0.91266376
Epoch 47 of 120 took 1.627s
train Loss: 0.26024099 Acc: 0.91028917
val Loss: 0.25472243 Acc: 0.90829694
Epoch 48 of 120 took 1.644s
train Loss: 0.25451849 Acc: 0.91425675
val Loss: 0.22965913 Acc: 0.91703057
Epoch 49 of 120 took 1.639s
train Loss: 0.24605442 Acc: 0.91575557
val Loss: 0.29190095 Acc: 0.91703057
Epoch 50 of 120 took 1.673s
train Loss: 0.25002542 Acc: 0.91535884
val Loss: 0.24604744 Acc: 0.92139739
Epoch 51 of 120 took 1.627s
train Loss: 0.24510393 Acc: 0.91738671
val Loss: 0.23742376 Acc: 0.93449783
Epoch 52 of 120 took 1.627s
train Loss: 0.24278887 Acc: 0.91795981
val Loss: 0.23050960 Acc: 0.93449783
Epoch 53 of 120 took 1.672s
train Loss: 0.23741280 Acc: 0.92025214
val Loss: 0.22096611 Acc: 0.93013102
Epoch 54 of 120 took 1.633s
train Loss: 0.23948283 Acc: 0.91972315
val Loss: 0.25362177 Acc: 0.9257642
Epoch 55 of 120 took 1.628s
train Loss: 0.23421193 Acc: 0.92073709
val Loss: 0.27855937 Acc: 0.91703057
Epoch 56 of 120 took 1.628s
train Loss: 0.23668980 Acc: 0.92113382
val Loss: 0.25291999 Acc: 0.93449783
Epoch 57 of 120 took 1.671s
train Loss: 0.23253988 Acc: 0.9214865
val Loss: 0.26867619 Acc: 0.91703057
Epoch 58 of 120 took 1.628s
train Loss: 0.23004347 Acc: 0.92139834
val Loss: 0.25521201 Acc: 0.91703057
Epoch 59 of 120 took 1.625s
train Loss: 0.22648282 Acc: 0.9221037
val Loss: 0.22419273 Acc: 0.92139739
Epoch 00060: reducing learning rate of group 0 to 2.0000e-03.
Epoch 60 of 120 took 1.626s
train Loss: 0.22027558 Acc: 0.92664433
val Loss: 0.21910440 Acc: 0.93449783
Epoch 61 of 120 took 1.677s
train Loss: 0.20345732 Acc: 0.93122905
val Loss: 0.22201236 Acc: 0.93013102
Epoch 62 of 120 took 1.627s
train Loss: 0.20232658 Acc: 0.92946571
val Loss: 0.20495642 Acc: 0.93449783
Epoch 63 of 120 took 1.628s
train Loss: 0.19934205 Acc: 0.9305678
val Loss: 0.19864507 Acc: 0.93013102
Epoch 64 of 120 took 1.627s
train Loss: 0.20077390 Acc: 0.93118495
val Loss: 0.20674186 Acc: 0.93013102
Epoch 65 of 120 took 1.622s
train Loss: 0.19437304 Acc: 0.93290424
val Loss: 0.19343558 Acc: 0.94323146
Epoch 66 of 120 took 1.671s
train Loss: 0.20036477 Acc: 0.93246341
val Loss: 0.21400965 Acc: 0.9257642
Epoch 67 of 120 took 1.621s
train Loss: 0.20044182 Acc: 0.93268383
val Loss: 0.20411686 Acc: 0.93013102
Epoch 68 of 120 took 1.622s
train Loss: 0.19641567 Acc: 0.93488801
val Loss: 0.21104697 Acc: 0.93013102
Epoch 69 of 120 took 1.622s
train Loss: 0.19384521 Acc: 0.93405044
val Loss: 0.21191712 Acc: 0.92139739
Epoch 70 of 120 took 1.621s
train Loss: 0.19570563 Acc: 0.93440312
val Loss: 0.19718956 Acc: 0.93449783
Epoch 71 of 120 took 1.669s
train Loss: 0.19356049 Acc: 0.93277198
val Loss: 0.22157169 Acc: 0.93013102
Epoch 00072: reducing learning rate of group 0 to 4.0000e-04.
Epoch 72 of 120 took 1.622s
train Loss: 0.19204147 Acc: 0.93484396
val Loss: 0.20736160 Acc: 0.93449783
Epoch 73 of 120 took 1.624s
train Loss: 0.19212796 Acc: 0.93316877
val Loss: 0.21099369 Acc: 0.93013102
Epoch 74 of 120 took 1.670s
train Loss: 0.18919604 Acc: 0.93466759
val Loss: 0.20658859 Acc: 0.93013102
Epoch 75 of 120 took 1.624s
train Loss: 0.18741043 Acc: 0.93515253
val Loss: 0.19829250 Acc: 0.93886465
Epoch 76 of 120 took 1.624s
train Loss: 0.19078041 Acc: 0.93325692
val Loss: 0.20028346 Acc: 0.93886465
Epoch 77 of 120 took 1.623s

Training complete in 2m 6s
Best val loss: 0.193436
ACCURACY TEST_0 FINAL : 84.254 %
TOP-3 ACCURACY TEST_0 FINAL : 94.803 %
22726
(22726, 12, 10, 7)
train Loss: 2.33630136 Acc: 0.60991812
val Loss: 1.26419361 Acc: 0.59388649
Epoch 1 of 120 took 1.841s
train Loss: 1.08912298 Acc: 0.66778135
val Loss: 0.97776491 Acc: 0.68558955
Epoch 2 of 120 took 1.623s
train Loss: 0.92229136 Acc: 0.71565604
val Loss: 0.81399339 Acc: 0.72925764
Epoch 3 of 120 took 1.641s
train Loss: 0.82058339 Acc: 0.74333364
val Loss: 0.69761823 Acc: 0.77292579
Epoch 4 of 120 took 1.686s
train Loss: 0.74955523 Acc: 0.76471883
val Loss: 0.64207618 Acc: 0.80349344
Epoch 5 of 120 took 1.640s
train Loss: 0.68804738 Acc: 0.78306782
val Loss: 0.58929565 Acc: 0.80349344
Epoch 6 of 120 took 1.640s
train Loss: 0.64875303 Acc: 0.79305637
val Loss: 0.55951757 Acc: 0.8209607
Epoch 7 of 120 took 1.641s
train Loss: 0.62016056 Acc: 0.8024289
val Loss: 0.53019215 Acc: 0.8209607
Epoch 8 of 120 took 1.641s
train Loss: 0.57676967 Acc: 0.81936985
val Loss: 0.49028362 Acc: 0.8209607
Epoch 9 of 120 took 1.640s
train Loss: 0.54898795 Acc: 0.82601422
val Loss: 0.46675107 Acc: 0.84716159
Epoch 10 of 120 took 1.640s
train Loss: 0.52606565 Acc: 0.8338027
val Loss: 0.45999098 Acc: 0.85152841
Epoch 11 of 120 took 1.628s
train Loss: 0.51012947 Acc: 0.84049106
val Loss: 0.43402369 Acc: 0.85589522
Epoch 12 of 120 took 1.669s
train Loss: 0.48095031 Acc: 0.84665138
val Loss: 0.43151650 Acc: 0.86462885
Epoch 13 of 120 took 1.628s
train Loss: 0.47061052 Acc: 0.85087562
val Loss: 0.42010916 Acc: 0.86026204
Epoch 14 of 120 took 1.628s
train Loss: 0.46150876 Acc: 0.85457182
val Loss: 0.39013617 Acc: 0.86462885
Epoch 15 of 120 took 1.630s
train Loss: 0.44191900 Acc: 0.86319631
val Loss: 0.38992218 Acc: 0.86899567
Epoch 16 of 120 took 1.674s
train Loss: 0.42735120 Acc: 0.86473638
val Loss: 0.35473070 Acc: 0.87336248
Epoch 17 of 120 took 1.629s
train Loss: 0.41571226 Acc: 0.86940068
val Loss: 0.42408683 Acc: 0.86462885
Epoch 18 of 120 took 1.623s
train Loss: 0.40588757 Acc: 0.87107277
val Loss: 0.36752945 Acc: 0.87336248
Epoch 19 of 120 took 1.668s
train Loss: 0.39908730 Acc: 0.8720848
val Loss: 0.35071421 Acc: 0.88209611
Epoch 20 of 120 took 1.629s
train Loss: 0.39043020 Acc: 0.87996125
val Loss: 0.36553185 Acc: 0.88646287
Epoch 21 of 120 took 1.624s
train Loss: 0.37664595 Acc: 0.8820734
val Loss: 0.34948475 Acc: 0.8777293
Epoch 22 of 120 took 1.671s
train Loss: 0.37342789 Acc: 0.8808853
val Loss: 0.35789511 Acc: 0.86462885
Epoch 23 of 120 took 1.624s
train Loss: 0.36231600 Acc: 0.88502157
val Loss: 0.33905430 Acc: 0.88209611
Epoch 24 of 120 took 1.633s
train Loss: 0.35279006 Acc: 0.88634163
val Loss: 0.32230646 Acc: 0.88646287
Epoch 25 of 120 took 1.676s
train Loss: 0.35242256 Acc: 0.88924581
val Loss: 0.34978371 Acc: 0.8777293
Epoch 26 of 120 took 1.624s
train Loss: 0.34181169 Acc: 0.89223796
val Loss: 0.32460528 Acc: 0.8951965
Epoch 27 of 120 took 1.624s
train Loss: 0.33277273 Acc: 0.89285398
val Loss: 0.32772389 Acc: 0.8951965
Epoch 28 of 120 took 1.624s
train Loss: 0.33359174 Acc: 0.8954941
val Loss: 0.31354976 Acc: 0.8951965
Epoch 29 of 120 took 1.629s
train Loss: 0.32654989 Acc: 0.89655018
val Loss: 0.30677213 Acc: 0.88646287
Epoch 30 of 120 took 1.675s
train Loss: 0.31090819 Acc: 0.90090644
val Loss: 0.27745631 Acc: 0.90829694
Epoch 31 of 120 took 1.630s
train Loss: 0.31016373 Acc: 0.90200651
val Loss: 0.27652301 Acc: 0.91266376
Epoch 32 of 120 took 1.640s
train Loss: 0.30828663 Acc: 0.8999384
val Loss: 0.29744842 Acc: 0.90393013
Epoch 33 of 120 took 1.632s
train Loss: 0.29600501 Acc: 0.90376657
val Loss: 0.31698767 Acc: 0.88209611
Epoch 34 of 120 took 1.668s
train Loss: 0.29751026 Acc: 0.90323853
val Loss: 0.29093501 Acc: 0.8951965
Epoch 35 of 120 took 1.623s
train Loss: 0.30818368 Acc: 0.90266651
val Loss: 0.27933431 Acc: 0.90829694
Epoch 36 of 120 took 1.625s
train Loss: 0.30128556 Acc: 0.9050867
val Loss: 0.27344368 Acc: 0.90829694
Epoch 37 of 120 took 1.628s
train Loss: 0.28889582 Acc: 0.90755081
val Loss: 0.24194227 Acc: 0.92139739
Epoch 38 of 120 took 1.629s
train Loss: 0.28437966 Acc: 0.90891486
val Loss: 0.25303912 Acc: 0.91703057
Epoch 39 of 120 took 1.669s
train Loss: 0.28461084 Acc: 0.9087829
val Loss: 0.22256783 Acc: 0.93886465
Epoch 40 of 120 took 1.629s
train Loss: 0.27557516 Acc: 0.91010296
val Loss: 0.22866912 Acc: 0.92139739
Epoch 41 of 120 took 1.625s
train Loss: 0.27515005 Acc: 0.91190708
val Loss: 0.24111666 Acc: 0.9257642
Epoch 42 of 120 took 1.622s
train Loss: 0.27174166 Acc: 0.91252309
val Loss: 0.26851668 Acc: 0.91266376
Epoch 43 of 120 took 1.666s
train Loss: 0.27117803 Acc: 0.91195107
val Loss: 0.27435732 Acc: 0.93013102
Epoch 44 of 120 took 1.620s
train Loss: 0.26084468 Acc: 0.91652733
val Loss: 0.27466677 Acc: 0.91703057
Epoch 45 of 120 took 1.622s
train Loss: 0.26432155 Acc: 0.91331512
val Loss: 0.24559790 Acc: 0.91703057
Epoch 00046: reducing learning rate of group 0 to 2.0000e-03.
Epoch 46 of 120 took 1.668s
train Loss: 0.24565012 Acc: 0.91916746
val Loss: 0.20583520 Acc: 0.93886465
Epoch 47 of 120 took 1.628s
train Loss: 0.23644596 Acc: 0.92343569
val Loss: 0.20382111 Acc: 0.93886465
Epoch 48 of 120 took 1.629s
train Loss: 0.23313280 Acc: 0.92440373
val Loss: 0.20087774 Acc: 0.93449783
Epoch 49 of 120 took 1.629s
train Loss: 0.22971422 Acc: 0.92413974
val Loss: 0.20676705 Acc: 0.93886465
Epoch 50 of 120 took 1.668s
train Loss: 0.22696052 Acc: 0.92488778
val Loss: 0.22361133 Acc: 0.92139739
Epoch 51 of 120 took 1.624s
train Loss: 0.23116962 Acc: 0.92418373
val Loss: 0.21201021 Acc: 0.93013102
Epoch 52 of 120 took 1.622s
train Loss: 0.22021070 Acc: 0.92814398
val Loss: 0.21242798 Acc: 0.9257642
Epoch 53 of 120 took 1.623s
train Loss: 0.22131659 Acc: 0.9275279
val Loss: 0.20798902 Acc: 0.93449783
Epoch 54 of 120 took 1.621s
train Loss: 0.22536003 Acc: 0.92655987
val Loss: 0.20293812 Acc: 0.93449783
Epoch 00055: reducing learning rate of group 0 to 4.0000e-04.
Epoch 55 of 120 took 1.668s
train Loss: 0.22591337 Acc: 0.92682385
val Loss: 0.19897570 Acc: 0.93886465
Epoch 56 of 120 took 1.626s
train Loss: 0.22066776 Acc: 0.92642784
val Loss: 0.19937615 Acc: 0.93013102
Epoch 57 of 120 took 1.622s
train Loss: 0.21601210 Acc: 0.92743993
val Loss: 0.19724704 Acc: 0.93449783
Epoch 58 of 120 took 1.628s
train Loss: 0.21851201 Acc: 0.92743993
val Loss: 0.19998134 Acc: 0.93449783
Epoch 59 of 120 took 1.623s
train Loss: 0.21909999 Acc: 0.92677987
val Loss: 0.19863936 Acc: 0.93013102
Epoch 60 of 120 took 1.668s
train Loss: 0.21921830 Acc: 0.92862797
val Loss: 0.20255892 Acc: 0.93449783
Epoch 61 of 120 took 1.625s
train Loss: 0.21997211 Acc: 0.928936
val Loss: 0.20217947 Acc: 0.93449783
Epoch 62 of 120 took 1.624s
train Loss: 0.21551878 Acc: 0.92831999
val Loss: 0.20514421 Acc: 0.93449783
Epoch 63 of 120 took 1.624s
train Loss: 0.21608776 Acc: 0.92897999
val Loss: 0.20055721 Acc: 0.93013102
Epoch 00064: reducing learning rate of group 0 to 8.0000e-05.
Epoch 64 of 120 took 1.669s
train Loss: 0.21852158 Acc: 0.92717588
val Loss: 0.19600976 Acc: 0.93013102
Epoch 65 of 120 took 1.629s
train Loss: 0.21516021 Acc: 0.93008006
val Loss: 0.20030147 Acc: 0.93449783
Epoch 66 of 120 took 1.626s
train Loss: 0.21338419 Acc: 0.92990404
val Loss: 0.19767439 Acc: 0.93449783
Epoch 67 of 120 took 1.625s
train Loss: 0.21338427 Acc: 0.92897999
val Loss: 0.19579114 Acc: 0.93449783
Epoch 68 of 120 took 1.672s
train Loss: 0.21798070 Acc: 0.92827594
val Loss: 0.19359264 Acc: 0.93013102
Epoch 69 of 120 took 1.630s
train Loss: 0.22210215 Acc: 0.92660385
val Loss: 0.20740872 Acc: 0.93449783
Epoch 70 of 120 took 1.623s
train Loss: 0.21780995 Acc: 0.92743993
val Loss: 0.19864440 Acc: 0.93013102
Epoch 71 of 120 took 1.625s
train Loss: 0.21644710 Acc: 0.92915601
val Loss: 0.20356644 Acc: 0.93449783
Epoch 72 of 120 took 1.625s
train Loss: 0.22145284 Acc: 0.9273079
val Loss: 0.19438776 Acc: 0.93886465
Epoch 73 of 120 took 1.668s
train Loss: 0.21757971 Acc: 0.93008006
val Loss: 0.19872705 Acc: 0.93013102
Epoch 74 of 120 took 1.626s
train Loss: 0.22254869 Acc: 0.92726392
val Loss: 0.20206228 Acc: 0.93013102
Epoch 00075: reducing learning rate of group 0 to 1.6000e-05.
Epoch 75 of 120 took 1.624s
train Loss: 0.21649408 Acc: 0.92990404
val Loss: 0.20037409 Acc: 0.93449783
Epoch 76 of 120 took 1.625s
train Loss: 0.21514624 Acc: 0.93030006
val Loss: 0.19976622 Acc: 0.93449783
Epoch 77 of 120 took 1.669s
train Loss: 0.21608118 Acc: 0.92933202
val Loss: 0.20134700 Acc: 0.93449783
Epoch 78 of 120 took 1.626s
train Loss: 0.21468246 Acc: 0.92827594
val Loss: 0.19487568 Acc: 0.93449783
Epoch 79 of 120 took 1.624s
train Loss: 0.21986321 Acc: 0.92827594
val Loss: 0.19832337 Acc: 0.93449783
Epoch 80 of 120 took 1.622s

Training complete in 2m 11s
Best val loss: 0.193593
ACCURACY TEST_0 FINAL : 86.901 %
TOP-3 ACCURACY TEST_0 FINAL : 94.684 %
22817
(22817, 12, 10, 7)
train Loss: 1.27393727 Acc: 0.71210063
val Loss: 0.79031919 Acc: 0.74347824
Epoch 1 of 120 took 1.851s
train Loss: 0.78794357 Acc: 0.7655257
val Loss: 0.64211296 Acc: 0.81739128
Epoch 2 of 120 took 1.591s
train Loss: 0.67165648 Acc: 0.79458296
val Loss: 0.57738405 Acc: 0.82608694
Epoch 3 of 120 took 1.624s
train Loss: 0.61362435 Acc: 0.81215757
val Loss: 0.55371445 Acc: 0.82608694
Epoch 4 of 120 took 1.627s
train Loss: 0.56827375 Acc: 0.82451677
val Loss: 0.50251798 Acc: 0.8347826
Epoch 5 of 120 took 1.673s
train Loss: 0.52975471 Acc: 0.83582413
val Loss: 0.49195988 Acc: 0.8391304
Epoch 6 of 120 took 1.628s
train Loss: 0.50438103 Acc: 0.8412587
val Loss: 0.47723128 Acc: 0.85652173
Epoch 7 of 120 took 1.628s
train Loss: 0.47438162 Acc: 0.84892845
val Loss: 0.46289477 Acc: 0.84782606
Epoch 8 of 120 took 1.627s
train Loss: 0.45048917 Acc: 0.85852653
val Loss: 0.45136339 Acc: 0.86086953
Epoch 9 of 120 took 1.673s
train Loss: 0.44632811 Acc: 0.85681731
val Loss: 0.41925751 Acc: 0.85217386
Epoch 10 of 120 took 1.629s
train Loss: 0.42910392 Acc: 0.86422402
val Loss: 0.43362957 Acc: 0.85652173
Epoch 11 of 120 took 1.622s
train Loss: 0.41561355 Acc: 0.86768639
val Loss: 0.40040764 Acc: 0.86956519
Epoch 12 of 120 took 1.628s
train Loss: 0.40234398 Acc: 0.86908883
val Loss: 0.41107339 Acc: 0.86521733
Epoch 13 of 120 took 1.667s
train Loss: 0.38863948 Acc: 0.87377834
val Loss: 0.38051037 Acc: 0.86956519
Epoch 14 of 120 took 1.628s
train Loss: 0.37681882 Acc: 0.87671471
val Loss: 0.37346113 Acc: 0.87391299
Epoch 15 of 120 took 1.628s
train Loss: 0.37348255 Acc: 0.87842399
val Loss: 0.36108165 Acc: 0.87391299
Epoch 16 of 120 took 1.628s
train Loss: 0.36262099 Acc: 0.88114125
val Loss: 0.34580665 Acc: 0.88260865
Epoch 17 of 120 took 1.676s
train Loss: 0.35386175 Acc: 0.88420916
val Loss: 0.35229865 Acc: 0.86521733
Epoch 18 of 120 took 1.630s
train Loss: 0.34971423 Acc: 0.88727701
val Loss: 0.37537465 Acc: 0.87391299
Epoch 19 of 120 took 1.629s
train Loss: 0.33616342 Acc: 0.89038873
val Loss: 0.34412642 Acc: 0.88260865
Epoch 20 of 120 took 1.634s
train Loss: 0.33072747 Acc: 0.88942456
val Loss: 0.32957541 Acc: 0.89130431
Epoch 21 of 120 took 1.679s
train Loss: 0.32068002 Acc: 0.89284307
val Loss: 0.34110249 Acc: 0.88695645
Epoch 22 of 120 took 1.628s
train Loss: 0.32540424 Acc: 0.89165974
val Loss: 0.32012950 Acc: 0.89565212
Epoch 23 of 120 took 1.634s
train Loss: 0.31914570 Acc: 0.89586711
val Loss: 0.29336964 Acc: 0.90434778
Epoch 24 of 120 took 1.637s
train Loss: 0.31433761 Acc: 0.89683127
val Loss: 0.29509039 Acc: 0.89999998
Epoch 25 of 120 took 1.630s
train Loss: 0.30838059 Acc: 0.89880353
val Loss: 0.35462981 Acc: 0.87391299
Epoch 26 of 120 took 1.674s
train Loss: 0.34627870 Acc: 0.88789058
val Loss: 0.31487983 Acc: 0.86956519
Epoch 27 of 120 took 1.630s
train Loss: 0.30980506 Acc: 0.89919794
val Loss: 0.29308685 Acc: 0.89565212
Epoch 28 of 120 took 1.680s
train Loss: 0.30718063 Acc: 0.90090722
val Loss: 0.28441976 Acc: 0.89130431
Epoch 29 of 120 took 1.628s
train Loss: 0.29722583 Acc: 0.89998686
val Loss: 0.30254695 Acc: 0.88260865
Epoch 30 of 120 took 1.620s
train Loss: 0.28884370 Acc: 0.90485162
val Loss: 0.29294851 Acc: 0.91304344
Epoch 31 of 120 took 1.620s
train Loss: 0.28526994 Acc: 0.90511459
val Loss: 0.28266262 Acc: 0.89999998
Epoch 32 of 120 took 1.672s
train Loss: 0.28940146 Acc: 0.90353686
val Loss: 0.26513671 Acc: 0.89999998
Epoch 33 of 120 took 1.626s
train Loss: 0.27994145 Acc: 0.90642941
val Loss: 0.24600328 Acc: 0.89999998
Epoch 34 of 120 took 1.626s
train Loss: 0.26930954 Acc: 0.90976024
val Loss: 0.29236708 Acc: 0.87826085
Epoch 35 of 120 took 1.621s
train Loss: 0.27068428 Acc: 0.90910286
val Loss: 0.25862722 Acc: 0.90434778
Epoch 36 of 120 took 1.665s
train Loss: 0.26617062 Acc: 0.91243368
val Loss: 0.27467859 Acc: 0.90434778
Epoch 37 of 120 took 1.620s
train Loss: 0.26323561 Acc: 0.91396767
val Loss: 0.27234705 Acc: 0.89999998
Epoch 38 of 120 took 1.619s
train Loss: 0.25675622 Acc: 0.91331023
val Loss: 0.24829157 Acc: 0.89565212
Epoch 39 of 120 took 1.638s
train Loss: 0.25954303 Acc: 0.91409916
val Loss: 0.25972438 Acc: 0.89130431
Epoch 00040: reducing learning rate of group 0 to 2.0000e-03.
Epoch 40 of 120 took 1.621s
train Loss: 0.24872812 Acc: 0.91585219
val Loss: 0.23633239 Acc: 0.90434778
Epoch 41 of 120 took 1.625s
train Loss: 0.23283843 Acc: 0.92124295
val Loss: 0.23762591 Acc: 0.90434778
Epoch 42 of 120 took 1.665s
train Loss: 0.23208329 Acc: 0.9225139
val Loss: 0.23146417 Acc: 0.90434778
Epoch 43 of 120 took 1.624s
train Loss: 0.22793348 Acc: 0.92308366
val Loss: 0.23495674 Acc: 0.90869564
Epoch 44 of 120 took 1.620s
train Loss: 0.23087005 Acc: 0.92325896
val Loss: 0.22406826 Acc: 0.90434778
Epoch 45 of 120 took 1.627s
train Loss: 0.22497012 Acc: 0.92312747
val Loss: 0.22373449 Acc: 0.91304344
Epoch 46 of 120 took 1.677s
train Loss: 0.22444518 Acc: 0.92501205
val Loss: 0.22837263 Acc: 0.9217391
Epoch 47 of 120 took 1.620s
train Loss: 0.22207392 Acc: 0.92584473
val Loss: 0.22421051 Acc: 0.90869564
Epoch 48 of 120 took 1.619s
train Loss: 0.22349650 Acc: 0.92417932
val Loss: 0.21849636 Acc: 0.91304344
Epoch 49 of 120 took 1.626s
train Loss: 0.22110196 Acc: 0.92685276
val Loss: 0.22703894 Acc: 0.90869564
Epoch 50 of 120 took 1.665s
train Loss: 0.22596194 Acc: 0.92527503
val Loss: 0.22890093 Acc: 0.91304344
Epoch 51 of 120 took 1.623s
train Loss: 0.21976186 Acc: 0.92566943
val Loss: 0.21779695 Acc: 0.90869564
Epoch 52 of 120 took 1.628s
train Loss: 0.21676558 Acc: 0.92742252
val Loss: 0.22372004 Acc: 0.91739124
Epoch 53 of 120 took 1.622s
train Loss: 0.21621242 Acc: 0.92821139
val Loss: 0.23106973 Acc: 0.91304344
Epoch 54 of 120 took 1.622s
train Loss: 0.22027359 Acc: 0.9273349
val Loss: 0.22216361 Acc: 0.91739124
Epoch 55 of 120 took 1.662s
train Loss: 0.21602738 Acc: 0.92843056
val Loss: 0.21626508 Acc: 0.90434778
Epoch 56 of 120 took 1.627s
train Loss: 0.21840762 Acc: 0.92878115
val Loss: 0.22175596 Acc: 0.91739124
Epoch 57 of 120 took 1.621s
train Loss: 0.21977262 Acc: 0.92540652
val Loss: 0.21353970 Acc: 0.9217391
Epoch 58 of 120 took 1.626s
train Loss: 0.21597539 Acc: 0.92864966
val Loss: 0.20705053 Acc: 0.91739124
Epoch 59 of 120 took 1.630s
train Loss: 0.22070971 Acc: 0.92737871
val Loss: 0.21300733 Acc: 0.91304344
Epoch 60 of 120 took 1.667s
train Loss: 0.21672328 Acc: 0.92851818
val Loss: 0.21796605 Acc: 0.91739124
Epoch 61 of 120 took 1.623s
train Loss: 0.21127283 Acc: 0.92943859
val Loss: 0.21703359 Acc: 0.9217391
Epoch 62 of 120 took 1.668s
train Loss: 0.21563560 Acc: 0.92878115
val Loss: 0.22032498 Acc: 0.91304344
Epoch 63 of 120 took 1.621s
train Loss: 0.21122758 Acc: 0.9314546
val Loss: 0.21709670 Acc: 0.91304344
Epoch 64 of 120 took 1.622s
train Loss: 0.20867147 Acc: 0.9314546
val Loss: 0.22327434 Acc: 0.91304344
Epoch 00065: reducing learning rate of group 0 to 4.0000e-04.
Epoch 65 of 120 took 1.621s
train Loss: 0.20751149 Acc: 0.93084103
val Loss: 0.21671495 Acc: 0.91304344
Epoch 66 of 120 took 1.622s
train Loss: 0.20540109 Acc: 0.93141079
val Loss: 0.22018020 Acc: 0.91304344
Epoch 67 of 120 took 1.622s
train Loss: 0.20414551 Acc: 0.93158609
val Loss: 0.21842565 Acc: 0.91739124
Epoch 68 of 120 took 1.622s
train Loss: 0.20255161 Acc: 0.93224347
val Loss: 0.21469808 Acc: 0.91739124
Epoch 69 of 120 took 1.633s
train Loss: 0.20848784 Acc: 0.93219966
val Loss: 0.21273075 Acc: 0.91739124
Epoch 70 of 120 took 1.678s

Training complete in 1m 55s
Best val loss: 0.207051
ACCURACY TEST_0 FINAL : 86.712 %
TOP-3 ACCURACY TEST_0 FINAL : 95.055 %
22598
(22598, 12, 10, 7)
train Loss: 1.87445570 Acc: 0.60531908
val Loss: 1.12934501 Acc: 0.68859649
Epoch 1 of 120 took 1.643s
train Loss: 1.24965786 Acc: 0.65072131
val Loss: 0.93671049 Acc: 0.71929824
Epoch 2 of 120 took 1.637s
train Loss: 1.10267513 Acc: 0.68483937
val Loss: 0.85165232 Acc: 0.74561405
Epoch 3 of 120 took 1.638s
train Loss: 1.00777929 Acc: 0.71377999
val Loss: 0.76660324 Acc: 0.75877196
Epoch 4 of 120 took 1.682s
train Loss: 0.94304030 Acc: 0.72674572
val Loss: 0.71404577 Acc: 0.78947371
Epoch 5 of 120 took 1.637s
train Loss: 0.90384307 Acc: 0.73922473
val Loss: 0.67615254 Acc: 0.78947371
Epoch 6 of 120 took 1.637s
train Loss: 0.85700637 Acc: 0.75320828
val Loss: 0.65280629 Acc: 0.82456142
Epoch 7 of 120 took 1.637s
train Loss: 0.81794101 Acc: 0.76276666
val Loss: 0.60965632 Acc: 0.80263156
Epoch 8 of 120 took 1.684s
train Loss: 0.79336627 Acc: 0.76745731
val Loss: 0.59275477 Acc: 0.82894737
Epoch 9 of 120 took 1.637s
train Loss: 0.76469399 Acc: 0.7714842
val Loss: 0.58185155 Acc: 0.83333331
Epoch 10 of 120 took 1.640s
train Loss: 0.75591591 Acc: 0.77555537
val Loss: 0.59373155 Acc: 0.82894737
Epoch 11 of 120 took 1.633s
train Loss: 0.72342320 Acc: 0.78383046
val Loss: 0.54315613 Acc: 0.84210527
Epoch 12 of 120 took 1.669s
train Loss: 0.70621019 Acc: 0.78776884
val Loss: 0.52264151 Acc: 0.85526317
Epoch 13 of 120 took 1.623s
train Loss: 0.68537023 Acc: 0.79409683
val Loss: 0.52629130 Acc: 0.84210527
Epoch 14 of 120 took 1.620s
train Loss: 0.67442917 Acc: 0.79701746
val Loss: 0.51561025 Acc: 0.85964912
Epoch 15 of 120 took 1.624s
train Loss: 0.66763682 Acc: 0.79905301
val Loss: 0.49063272 Acc: 0.85087723
Epoch 16 of 120 took 1.625s
train Loss: 0.65299679 Acc: 0.80462873
val Loss: 0.50212250 Acc: 0.85964912
Epoch 17 of 120 took 1.664s
train Loss: 0.62711856 Acc: 0.80586779
val Loss: 0.47447353 Acc: 0.85526317
Epoch 18 of 120 took 1.628s
train Loss: 0.62309304 Acc: 0.80993897
val Loss: 0.49573509 Acc: 0.83771932
Epoch 19 of 120 took 1.620s
train Loss: 0.60826563 Acc: 0.81414288
val Loss: 0.47786732 Acc: 0.84649122
Epoch 20 of 120 took 1.623s
train Loss: 0.60725915 Acc: 0.81533766
val Loss: 0.45119038 Acc: 0.86842108
Epoch 21 of 120 took 1.671s
train Loss: 0.58667939 Acc: 0.81675375
val Loss: 0.42367531 Acc: 0.87719297
Epoch 22 of 120 took 1.626s
train Loss: 0.57673347 Acc: 0.82215244
val Loss: 0.46466736 Acc: 0.86842108
Epoch 23 of 120 took 1.621s
train Loss: 0.57411854 Acc: 0.82494026
val Loss: 0.43950126 Acc: 0.86403507
Epoch 24 of 120 took 1.619s
train Loss: 0.56280035 Acc: 0.82308173
val Loss: 0.41526788 Acc: 0.86842108
Epoch 25 of 120 took 1.672s
train Loss: 0.56224892 Acc: 0.82578105
val Loss: 0.41935332 Acc: 0.86842108
Epoch 26 of 120 took 1.622s
train Loss: 0.55223330 Acc: 0.82702011
val Loss: 0.45051026 Acc: 0.84649122
Epoch 27 of 120 took 1.622s
train Loss: 0.55956589 Acc: 0.82679886
val Loss: 0.43264660 Acc: 0.85964912
Epoch 28 of 120 took 1.622s
train Loss: 0.53814242 Acc: 0.83188778
val Loss: 0.41602010 Acc: 0.88157898
Epoch 29 of 120 took 1.666s
train Loss: 0.53385373 Acc: 0.83215332
val Loss: 0.41362698 Acc: 0.86842108
Epoch 30 of 120 took 1.627s
train Loss: 0.52446976 Acc: 0.83569342
val Loss: 0.41904654 Acc: 0.86403507
Epoch 31 of 120 took 1.622s
train Loss: 0.51322062 Acc: 0.83595896
val Loss: 0.42390661 Acc: 0.86403507
Epoch 32 of 120 took 1.623s
train Loss: 0.51417923 Acc: 0.83587044
val Loss: 0.44456512 Acc: 0.85526317
Epoch 33 of 120 took 1.666s
train Loss: 0.51339933 Acc: 0.83848131
val Loss: 0.43822240 Acc: 0.85964912
Epoch 34 of 120 took 1.620s
train Loss: 0.50546752 Acc: 0.84060538
val Loss: 0.41349839 Acc: 0.86842108
Epoch 35 of 120 took 1.627s
train Loss: 0.48972078 Acc: 0.84418976
val Loss: 0.42958950 Acc: 0.85964912
Epoch 36 of 120 took 1.621s
train Loss: 0.50000470 Acc: 0.83879107
val Loss: 0.43817302 Acc: 0.85964912
Epoch 37 of 120 took 1.667s
train Loss: 0.49140233 Acc: 0.84383577
val Loss: 0.40365997 Acc: 0.86403507
Epoch 38 of 120 took 1.628s
train Loss: 0.50694711 Acc: 0.8407824
val Loss: 0.46239664 Acc: 0.85964912
Epoch 39 of 120 took 1.621s
train Loss: 0.48370678 Acc: 0.8458271
val Loss: 0.45351213 Acc: 0.85526317
Epoch 40 of 120 took 1.622s
train Loss: 0.49782289 Acc: 0.84224272
val Loss: 0.44301012 Acc: 0.85526317
Epoch 41 of 120 took 1.667s
train Loss: 0.48638336 Acc: 0.84600407
val Loss: 0.45915087 Acc: 0.84210527
Epoch 42 of 120 took 1.621s
train Loss: 0.47455919 Acc: 0.84888047
val Loss: 0.43281449 Acc: 0.87280703
Epoch 43 of 120 took 1.620s
train Loss: 0.48961454 Acc: 0.84542882
val Loss: 0.45144015 Acc: 0.85526317
Epoch 00044: reducing learning rate of group 0 to 2.0000e-03.
Epoch 44 of 120 took 1.621s
train Loss: 0.47008571 Acc: 0.85060626
val Loss: 0.41772140 Acc: 0.86842108
Epoch 45 of 120 took 1.667s
train Loss: 0.45296139 Acc: 0.85569519
val Loss: 0.42424755 Acc: 0.85526317
Epoch 46 of 120 took 1.621s
train Loss: 0.44774657 Acc: 0.85419065
val Loss: 0.39812924 Acc: 0.86403507
Epoch 47 of 120 took 1.626s
train Loss: 0.44270476 Acc: 0.85587221
val Loss: 0.40576410 Acc: 0.86842108
Epoch 48 of 120 took 1.622s
train Loss: 0.44129076 Acc: 0.85777503
val Loss: 0.39535258 Acc: 0.86842108
Epoch 49 of 120 took 1.626s
train Loss: 0.43374081 Acc: 0.8609612
val Loss: 0.41207850 Acc: 0.86842108
Epoch 50 of 120 took 1.668s
train Loss: 0.43965645 Acc: 0.86047441
val Loss: 0.39596589 Acc: 0.86403507
Epoch 51 of 120 took 1.621s
train Loss: 0.43660741 Acc: 0.85764229
val Loss: 0.39880693 Acc: 0.86842108
Epoch 52 of 120 took 1.621s
train Loss: 0.42944573 Acc: 0.86352777
val Loss: 0.40506017 Acc: 0.85526317
Epoch 53 of 120 took 1.666s
train Loss: 0.42542586 Acc: 0.86180192
val Loss: 0.42250666 Acc: 0.85526317
Epoch 54 of 120 took 1.623s
train Loss: 0.42539416 Acc: 0.86423582
val Loss: 0.41438256 Acc: 0.86403507
Epoch 00055: reducing learning rate of group 0 to 4.0000e-04.
Epoch 55 of 120 took 1.621s
train Loss: 0.41905014 Acc: 0.86361629
val Loss: 0.41001392 Acc: 0.86842108
Epoch 56 of 120 took 1.620s
train Loss: 0.42471709 Acc: 0.86352777
val Loss: 0.39533847 Acc: 0.86842108
Epoch 57 of 120 took 1.671s
train Loss: 0.42650832 Acc: 0.8586601
val Loss: 0.40343018 Acc: 0.86403507
Epoch 58 of 120 took 1.623s
train Loss: 0.42146185 Acc: 0.86193472
val Loss: 0.40903066 Acc: 0.85964912
Epoch 59 of 120 took 1.619s
train Loss: 0.41877225 Acc: 0.86352777
val Loss: 0.39231340 Acc: 0.86403507
Epoch 60 of 120 took 1.625s
train Loss: 0.41841706 Acc: 0.86361629
val Loss: 0.40989346 Acc: 0.85964912
Epoch 61 of 120 took 1.686s
train Loss: 0.42273936 Acc: 0.86215597
val Loss: 0.40094300 Acc: 0.86842108
Epoch 62 of 120 took 1.733s
train Loss: 0.41673221 Acc: 0.86547482
val Loss: 0.40666348 Acc: 0.86842108
Epoch 63 of 120 took 1.684s
train Loss: 0.41792351 Acc: 0.86295247
val Loss: 0.40371546 Acc: 0.85964912
Epoch 64 of 120 took 1.686s
train Loss: 0.41679015 Acc: 0.8650766
val Loss: 0.39958496 Acc: 0.86842108
Epoch 65 of 120 took 1.689s
train Loss: 0.41864823 Acc: 0.86410302
val Loss: 0.39820387 Acc: 0.86842108
Epoch 00066: reducing learning rate of group 0 to 8.0000e-05.
Epoch 66 of 120 took 1.737s
train Loss: 0.41721023 Acc: 0.8663156
val Loss: 0.40743407 Acc: 0.86842108
Epoch 67 of 120 took 1.691s
train Loss: 0.41472758 Acc: 0.86401457
val Loss: 0.40569850 Acc: 0.86842108
Epoch 68 of 120 took 1.689s
train Loss: 0.41657314 Acc: 0.86653686
val Loss: 0.39509423 Acc: 0.86842108
Epoch 69 of 120 took 1.694s
train Loss: 0.41507740 Acc: 0.86560762
val Loss: 0.39338535 Acc: 0.86403507
Epoch 70 of 120 took 1.742s
train Loss: 0.41315876 Acc: 0.86405879
val Loss: 0.40147316 Acc: 0.86842108
Epoch 71 of 120 took 1.697s

Training complete in 1m 57s
Best val loss: 0.392313
ACCURACY TEST_0 FINAL : 78.197 %
TOP-3 ACCURACY TEST_0 FINAL : 92.305 %
AVERAGE ACCURACY TEST 0 83.524
AVERAGE TOP-3 ACCURACY TEST 0 93.746
[85.62434417628542, 84.38885932233458, 88.72740163062744, 80.61973849185026, 76.85704274702172, 78.7735020207345, 85.32531824611033, 86.9381279746166, 84.37722419928825, 83.44230429404489, 83.02447552447552, 84.20682377769961, 86.60823838737949, 80.72816383686329, 79.33039647577093, 85.71680169073618, 85.49859550561797, 78.59180035650624, 79.40181591596938, 86.52097902097903, 86.23150565709312, 86.75945753033548, 81.39289482940556, 84.25428719902996, 86.9006254343294, 86.71242520239352, 78.19747013352072]
[95.57537600559637, 93.95068298740465, 97.07550514002126, 91.38456027225506, 91.71338472319552, 89.9666139518538, 95.82743988684582, 95.31112286268288, 95.05338078291815, 94.15091005478, 93.74125874125875, 94.2842068237777, 95.88080631025416, 91.2655347453177, 92.51101321585904, 95.03346248679112, 94.46980337078652, 90.17825311942958, 89.03329179277195, 94.28321678321679, 94.56919060052219, 95.82441113490364, 93.21139641224059, 94.8033951151914, 94.68380820013898, 95.05455825413587, 92.30498945888966]
ACCURACY FINAL TEST 0:  [[85.62434417628542, 84.38885932233458, 88.72740163062744, 80.61973849185026, 76.85704274702172, 78.7735020207345, 85.32531824611033, 86.9381279746166, 84.37722419928825, 83.44230429404489, 83.02447552447552, 84.20682377769961, 86.60823838737949, 80.72816383686329, 79.33039647577093, 85.71680169073618, 85.49859550561797, 78.59180035650624, 79.40181591596938, 86.52097902097903, 86.23150565709312, 86.75945753033548, 81.39289482940556, 84.25428719902996, 86.9006254343294, 86.71242520239352, 78.19747013352072]]
ACCURACY FINAL TEST 0:  83.52409702151924
/home/yanshuo/anaconda3/envs/diversify/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/home/yanshuo/anaconda3/envs/diversify/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
